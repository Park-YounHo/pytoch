{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHiExH1WoviQPY7RmIhzCy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Park-YounHo/pytoch/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KBldrDeALYMu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "import glob\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bO3IhfP3LYMv"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KSArD3r5LYMv"
      },
      "outputs": [],
      "source": [
        "vocab_dir = \"./vocab/\"\n",
        "if not os.path.exists(vocab_dir):\n",
        "    os.mkdir(vocab_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GpI28Ws2LYMw"
      },
      "outputs": [],
      "source": [
        "weights_dir = \"./weights/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.mkdir(weights_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kdkr7l4QLYMw",
        "outputId": "bdfe7a2e-fddc-4cff-e56a-89cb2a0c6959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./vocab/bert-base-uncased-vocab.txt',\n",
              " <http.client.HTTPMessage at 0x7fa21fc143d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "save_path=\"./vocab/bert-base-uncased-vocab.txt\"\n",
        "url = \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\"\n",
        "urllib.request.urlretrieve(url, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UpB6Ck90LYMx"
      },
      "outputs": [],
      "source": [
        "save_path = \"./weights/bert-base-uncased.tar.gz\"\n",
        "url = \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "archive_file = \"./weights/bert-base-uncased.tar.gz\" \n",
        "tar = tarfile.open(archive_file, 'r:gz')\n",
        "tar.extractall('./weights/')\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yyjS4bmxLYMy"
      },
      "outputs": [],
      "source": [
        "target_dir_path=\"./data/\"\n",
        "\n",
        "if not os.path.exists(target_dir_path):\n",
        "    os.mkdir(target_dir_path)\n",
        "    \n",
        "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "save_path = \"./data/aclImdb_v1.tar.gz\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "tar = tarfile.open('./data/aclImdb_v1.tar.gz')\n",
        "tar.extractall('./data/')\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5AWKaKkpLYMz"
      },
      "outputs": [],
      "source": [
        "target_dir_path=\"./data/aclImdb/\"\n",
        "\n",
        "if os.path.exists(target_dir_path):\n",
        "  \n",
        "    f=open('./data/IMDb_train.tsv','w')\n",
        "\n",
        "    path = './data/aclImdb/train/pos/'\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            \n",
        "            text = text.replace('\\t', \" \")\n",
        "            \n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/train/neg/'\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            \n",
        "            text = text.replace('\\t', \" \")\n",
        "            \n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    \n",
        "    f=open('./data/IMDb_test.tsv','w')\n",
        "\n",
        "    path = './data/aclImdb/test/pos/'\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            \n",
        "            text = text.replace('\\t', \" \")\n",
        "        \n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/test/neg/'\n",
        "\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            \n",
        "            \n",
        "            text = text.replace('\\t', \" \")\n",
        "            \n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Vj3vn_QXMkfV"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oZ92_W8SMkfW",
        "outputId": "ac16de2b-55c1-48ba-bda6-a793e2f77bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "config_file = \"./weights/bert_config.json\"\n",
        "\n",
        "json_file = open(config_file, 'r')\n",
        "config = json.load(json_file)\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p6TJLbjnMkfW",
        "outputId": "1db6c981-d56b-4098-aef1-999c932f70bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "config['hidden_size']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install attrdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36VWjePSV4I",
        "outputId": "078af66c-ec64-4e0c-9700-8122ab98ea43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0jMCnt6WMkfX",
        "outputId": "0ae37330-efed-4184-f91f-371e7f69b469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from attrdict import AttrDict\n",
        "\n",
        "config = AttrDict(config)\n",
        "config.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QSeTNtu_MkfX"
      },
      "outputs": [],
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, eps=1e-12):\n",
        "        super(BertLayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.beta = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "        return self.gamma * x + self.beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ABQ88-k9MkfY"
      },
      "outputs": [],
      "source": [
        "class BertEmbeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(\n",
        "            config.vocab_size, config.hidden_size, padding_idx=0)\n",
        "\n",
        "        self.position_embeddings = nn.Embedding(\n",
        "            config.max_position_embeddings, config.hidden_size)\n",
        "\n",
        "        self.token_type_embeddings = nn.Embedding(\n",
        "            config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "        # Dropout　'hidden_dropout_prob': 0.1\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(\n",
        "            seq_length, dtype=torch.long, device=input_ids.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "\n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
        "\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xWcJlyaTMkfZ"
      },
      "outputs": [],
      "source": [
        "class BertLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertLayer, self).__init__()\n",
        "\n",
        "        self.attention = BertAttention(config)\n",
        "\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, attention_show_flg=False):\n",
        "\n",
        "        if attention_show_flg == True:\n",
        "            attention_output, attention_probs = self.attention(\n",
        "                hidden_states, attention_mask, attention_show_flg)\n",
        "            intermediate_output = self.intermediate(attention_output)\n",
        "            layer_output = self.output(intermediate_output, attention_output)\n",
        "            return layer_output, attention_probs\n",
        "\n",
        "        elif attention_show_flg == False:\n",
        "            attention_output = self.attention(\n",
        "                hidden_states, attention_mask, attention_show_flg)\n",
        "            intermediate_output = self.intermediate(attention_output)\n",
        "            layer_output = self.output(intermediate_output, attention_output)\n",
        "\n",
        "            return layer_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I2U_la7LMkfZ"
      },
      "outputs": [],
      "source": [
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertAttention, self).__init__()\n",
        "        self.selfattn = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask, attention_show_flg=False):\n",
        "        if attention_show_flg == True:\n",
        "            self_output, attention_probs = self.selfattn(input_tensor, attention_mask, attention_show_flg)\n",
        "            attention_output = self.output(self_output, input_tensor)\n",
        "            return attention_output, attention_probs\n",
        "        \n",
        "        elif attention_show_flg == False:\n",
        "            self_output = self.selfattn(input_tensor, attention_mask, attention_show_flg)\n",
        "            attention_output = self.output(self_output, input_tensor)\n",
        "            return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "glzekIwlMkfZ"
      },
      "outputs": [],
      "source": [
        "class BertSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfAttention, self).__init__()\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "\n",
        "        self.attention_head_size = int(\n",
        "            config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * \\\n",
        "            self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[\n",
        "            :-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, attention_show_flg=False):\n",
        "\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / \\\n",
        "            math.sqrt(self.attention_head_size)\n",
        "\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[\n",
        "            :-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "        if attention_show_flg == True:\n",
        "            return context_layer, attention_probs\n",
        "        elif attention_show_flg == False:\n",
        "            return context_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "O_lrqr87Mkfa"
      },
      "outputs": [],
      "source": [
        "class BertSelfOutput(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfOutput, self).__init__()\n",
        "\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_VTGZyWXMkfa"
      },
      "outputs": [],
      "source": [
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertIntermediate, self).__init__()\n",
        "        \n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        \n",
        "        self.intermediate_act_fn = gelu\n",
        "            \n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AICW0_qwMkfa"
      },
      "outputs": [],
      "source": [
        "class BertOutput(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertOutput, self).__init__()\n",
        "\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZQF3aTVJMkfb"
      },
      "outputs": [],
      "source": [
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertEncoder, self).__init__()\n",
        "\n",
        "        self.layer = nn.ModuleList([BertLayer(config)\n",
        "                                    for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True, attention_show_flg=False):\n",
        "\n",
        "        all_encoder_layers = []\n",
        "\n",
        "        for layer_module in self.layer:\n",
        "\n",
        "            if attention_show_flg == True:\n",
        "                hidden_states, attention_probs = layer_module(\n",
        "                    hidden_states, attention_mask, attention_show_flg)\n",
        "            elif attention_show_flg == False:\n",
        "                hidden_states = layer_module(\n",
        "                    hidden_states, attention_mask, attention_show_flg)\n",
        "\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append(hidden_states)\n",
        "\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append(hidden_states)\n",
        "\n",
        "        if attention_show_flg == True:\n",
        "            return all_encoder_layers, attention_probs\n",
        "        elif attention_show_flg == False:\n",
        "            return all_encoder_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rkNuFeRPMkfb"
      },
      "outputs": [],
      "source": [
        "class BertPooler(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertPooler, self).__init__()\n",
        "\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "\n",
        "        return pooled_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Mfp4IcsqMkfb",
        "outputId": "ee05d8aa-0599-4930-dc30-5fef2eea40de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 단어 ID열의 텐서 크기:  torch.Size([2, 5])\n",
            "입력 마스크의 텐서 크기:  torch.Size([2, 5])\n",
            "입력 문장 ID의 텐서 크기:  torch.Size([2, 5])\n",
            "확장된 마스크의 텐서 크기:  torch.Size([2, 1, 1, 5])\n",
            "BertEmbeddings의 출력 텐서 크기:  torch.Size([2, 5, 768])\n",
            "BertEncoder 최후 층의 출력 텐서 크기:  torch.Size([2, 5, 768])\n",
            "BertPooler의 출력 텐서 크기:  torch.Size([2, 768])\n"
          ]
        }
      ],
      "source": [
        "input_ids = torch.LongTensor([[31, 51, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
        "print(\"입력 단어 ID열의 텐서 크기: \", input_ids.shape)\n",
        "\n",
        "attention_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])\n",
        "print(\"입력 마스크의 텐서 크기: \", attention_mask.shape)\n",
        "\n",
        "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
        "print(\"입력 문장 ID의 텐서 크기: \", token_type_ids.shape)\n",
        "\n",
        "\n",
        "embeddings = BertEmbeddings(config)\n",
        "encoder = BertEncoder(config)\n",
        "pooler = BertPooler(config)\n",
        "\n",
        "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
        "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "print(\"확장된 마스크의 텐서 크기: \", extended_attention_mask.shape)\n",
        "\n",
        "out1 = embeddings(input_ids, token_type_ids)\n",
        "print(\"BertEmbeddings의 출력 텐서 크기: \", out1.shape)\n",
        "\n",
        "out2 = encoder(out1, extended_attention_mask)\n",
        "print(\"BertEncoder 최후 층의 출력 텐서 크기: \", out2[0].shape)\n",
        "\n",
        "out3 = pooler(out2[-1])\n",
        "print(\"BertPooler의 출력 텐서 크기: \", out3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Z0i1i5KhMkfc"
      },
      "outputs": [],
      "source": [
        "class BertModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertModel, self).__init__()\n",
        "\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True, attention_show_flg=False):\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=torch.float32)\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
        "\n",
        "        if attention_show_flg == True:\n",
        "\n",
        "            encoded_layers, attention_probs = self.encoder(embedding_output,\n",
        "                                                           extended_attention_mask,\n",
        "                                                           output_all_encoded_layers, attention_show_flg)\n",
        "\n",
        "        elif attention_show_flg == False:\n",
        "            encoded_layers = self.encoder(embedding_output,\n",
        "                                          extended_attention_mask,\n",
        "                                          output_all_encoded_layers, attention_show_flg)\n",
        "\n",
        "        pooled_output = self.pooler(encoded_layers[-1])\n",
        "\n",
        "        if not output_all_encoded_layers:\n",
        "            encoded_layers = encoded_layers[-1]\n",
        "\n",
        "        if attention_show_flg == True:\n",
        "            return encoded_layers, pooled_output, attention_probs\n",
        "        elif attention_show_flg == False:\n",
        "            return encoded_layers, pooled_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Jf5nTwu9Mkfc",
        "outputId": "7b8ce249-8d1a-4214-b1f6-c84dffea9982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_layers의 텐서 크기:  torch.Size([2, 5, 768])\n",
            "pooled_output의 텐서 크기:  torch.Size([2, 768])\n",
            "attention_probs의 텐서 크기:  torch.Size([2, 12, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "input_ids = torch.LongTensor([[31, 51, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
        "attention_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])\n",
        "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
        "\n",
        "net = BertModel(config)\n",
        "\n",
        "encoded_layers, pooled_output, attention_probs = net(\n",
        "    input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False, attention_show_flg=True)\n",
        "\n",
        "print(\"encoded_layers의 텐서 크기: \", encoded_layers.shape)\n",
        "print(\"pooled_output의 텐서 크기: \", pooled_output.shape)\n",
        "print(\"attention_probs의 텐서 크기: \", attention_probs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Z_ncxmQSMkfc",
        "outputId": "c1bae8a6-4fb6-4eb8-d130-f9be2ad956c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "cls.predictions.bias\n",
            "cls.predictions.transform.dense.weight\n",
            "cls.predictions.transform.dense.bias\n",
            "cls.predictions.transform.LayerNorm.gamma\n",
            "cls.predictions.transform.LayerNorm.beta\n",
            "cls.predictions.decoder.weight\n",
            "cls.seq_relationship.weight\n",
            "cls.seq_relationship.bias\n"
          ]
        }
      ],
      "source": [
        "weights_path = \"./weights/pytorch_model.bin\"\n",
        "loaded_state_dict = torch.load(weights_path)\n",
        "\n",
        "for s in loaded_state_dict.keys():\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rrBHInBEMkfd",
        "outputId": "08c5503a-9653-4b95-f15f-c305363d2af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.word_embeddings.weight\n",
            "embeddings.position_embeddings.weight\n",
            "embeddings.token_type_embeddings.weight\n",
            "embeddings.LayerNorm.gamma\n",
            "embeddings.LayerNorm.beta\n",
            "encoder.layer.0.attention.selfattn.query.weight\n",
            "encoder.layer.0.attention.selfattn.query.bias\n",
            "encoder.layer.0.attention.selfattn.key.weight\n",
            "encoder.layer.0.attention.selfattn.key.bias\n",
            "encoder.layer.0.attention.selfattn.value.weight\n",
            "encoder.layer.0.attention.selfattn.value.bias\n",
            "encoder.layer.0.attention.output.dense.weight\n",
            "encoder.layer.0.attention.output.dense.bias\n",
            "encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "encoder.layer.0.attention.output.LayerNorm.beta\n",
            "encoder.layer.0.intermediate.dense.weight\n",
            "encoder.layer.0.intermediate.dense.bias\n",
            "encoder.layer.0.output.dense.weight\n",
            "encoder.layer.0.output.dense.bias\n",
            "encoder.layer.0.output.LayerNorm.gamma\n",
            "encoder.layer.0.output.LayerNorm.beta\n",
            "encoder.layer.1.attention.selfattn.query.weight\n",
            "encoder.layer.1.attention.selfattn.query.bias\n",
            "encoder.layer.1.attention.selfattn.key.weight\n",
            "encoder.layer.1.attention.selfattn.key.bias\n",
            "encoder.layer.1.attention.selfattn.value.weight\n",
            "encoder.layer.1.attention.selfattn.value.bias\n",
            "encoder.layer.1.attention.output.dense.weight\n",
            "encoder.layer.1.attention.output.dense.bias\n",
            "encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "encoder.layer.1.attention.output.LayerNorm.beta\n",
            "encoder.layer.1.intermediate.dense.weight\n",
            "encoder.layer.1.intermediate.dense.bias\n",
            "encoder.layer.1.output.dense.weight\n",
            "encoder.layer.1.output.dense.bias\n",
            "encoder.layer.1.output.LayerNorm.gamma\n",
            "encoder.layer.1.output.LayerNorm.beta\n",
            "encoder.layer.2.attention.selfattn.query.weight\n",
            "encoder.layer.2.attention.selfattn.query.bias\n",
            "encoder.layer.2.attention.selfattn.key.weight\n",
            "encoder.layer.2.attention.selfattn.key.bias\n",
            "encoder.layer.2.attention.selfattn.value.weight\n",
            "encoder.layer.2.attention.selfattn.value.bias\n",
            "encoder.layer.2.attention.output.dense.weight\n",
            "encoder.layer.2.attention.output.dense.bias\n",
            "encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "encoder.layer.2.attention.output.LayerNorm.beta\n",
            "encoder.layer.2.intermediate.dense.weight\n",
            "encoder.layer.2.intermediate.dense.bias\n",
            "encoder.layer.2.output.dense.weight\n",
            "encoder.layer.2.output.dense.bias\n",
            "encoder.layer.2.output.LayerNorm.gamma\n",
            "encoder.layer.2.output.LayerNorm.beta\n",
            "encoder.layer.3.attention.selfattn.query.weight\n",
            "encoder.layer.3.attention.selfattn.query.bias\n",
            "encoder.layer.3.attention.selfattn.key.weight\n",
            "encoder.layer.3.attention.selfattn.key.bias\n",
            "encoder.layer.3.attention.selfattn.value.weight\n",
            "encoder.layer.3.attention.selfattn.value.bias\n",
            "encoder.layer.3.attention.output.dense.weight\n",
            "encoder.layer.3.attention.output.dense.bias\n",
            "encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "encoder.layer.3.attention.output.LayerNorm.beta\n",
            "encoder.layer.3.intermediate.dense.weight\n",
            "encoder.layer.3.intermediate.dense.bias\n",
            "encoder.layer.3.output.dense.weight\n",
            "encoder.layer.3.output.dense.bias\n",
            "encoder.layer.3.output.LayerNorm.gamma\n",
            "encoder.layer.3.output.LayerNorm.beta\n",
            "encoder.layer.4.attention.selfattn.query.weight\n",
            "encoder.layer.4.attention.selfattn.query.bias\n",
            "encoder.layer.4.attention.selfattn.key.weight\n",
            "encoder.layer.4.attention.selfattn.key.bias\n",
            "encoder.layer.4.attention.selfattn.value.weight\n",
            "encoder.layer.4.attention.selfattn.value.bias\n",
            "encoder.layer.4.attention.output.dense.weight\n",
            "encoder.layer.4.attention.output.dense.bias\n",
            "encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "encoder.layer.4.attention.output.LayerNorm.beta\n",
            "encoder.layer.4.intermediate.dense.weight\n",
            "encoder.layer.4.intermediate.dense.bias\n",
            "encoder.layer.4.output.dense.weight\n",
            "encoder.layer.4.output.dense.bias\n",
            "encoder.layer.4.output.LayerNorm.gamma\n",
            "encoder.layer.4.output.LayerNorm.beta\n",
            "encoder.layer.5.attention.selfattn.query.weight\n",
            "encoder.layer.5.attention.selfattn.query.bias\n",
            "encoder.layer.5.attention.selfattn.key.weight\n",
            "encoder.layer.5.attention.selfattn.key.bias\n",
            "encoder.layer.5.attention.selfattn.value.weight\n",
            "encoder.layer.5.attention.selfattn.value.bias\n",
            "encoder.layer.5.attention.output.dense.weight\n",
            "encoder.layer.5.attention.output.dense.bias\n",
            "encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "encoder.layer.5.attention.output.LayerNorm.beta\n",
            "encoder.layer.5.intermediate.dense.weight\n",
            "encoder.layer.5.intermediate.dense.bias\n",
            "encoder.layer.5.output.dense.weight\n",
            "encoder.layer.5.output.dense.bias\n",
            "encoder.layer.5.output.LayerNorm.gamma\n",
            "encoder.layer.5.output.LayerNorm.beta\n",
            "encoder.layer.6.attention.selfattn.query.weight\n",
            "encoder.layer.6.attention.selfattn.query.bias\n",
            "encoder.layer.6.attention.selfattn.key.weight\n",
            "encoder.layer.6.attention.selfattn.key.bias\n",
            "encoder.layer.6.attention.selfattn.value.weight\n",
            "encoder.layer.6.attention.selfattn.value.bias\n",
            "encoder.layer.6.attention.output.dense.weight\n",
            "encoder.layer.6.attention.output.dense.bias\n",
            "encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "encoder.layer.6.attention.output.LayerNorm.beta\n",
            "encoder.layer.6.intermediate.dense.weight\n",
            "encoder.layer.6.intermediate.dense.bias\n",
            "encoder.layer.6.output.dense.weight\n",
            "encoder.layer.6.output.dense.bias\n",
            "encoder.layer.6.output.LayerNorm.gamma\n",
            "encoder.layer.6.output.LayerNorm.beta\n",
            "encoder.layer.7.attention.selfattn.query.weight\n",
            "encoder.layer.7.attention.selfattn.query.bias\n",
            "encoder.layer.7.attention.selfattn.key.weight\n",
            "encoder.layer.7.attention.selfattn.key.bias\n",
            "encoder.layer.7.attention.selfattn.value.weight\n",
            "encoder.layer.7.attention.selfattn.value.bias\n",
            "encoder.layer.7.attention.output.dense.weight\n",
            "encoder.layer.7.attention.output.dense.bias\n",
            "encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "encoder.layer.7.attention.output.LayerNorm.beta\n",
            "encoder.layer.7.intermediate.dense.weight\n",
            "encoder.layer.7.intermediate.dense.bias\n",
            "encoder.layer.7.output.dense.weight\n",
            "encoder.layer.7.output.dense.bias\n",
            "encoder.layer.7.output.LayerNorm.gamma\n",
            "encoder.layer.7.output.LayerNorm.beta\n",
            "encoder.layer.8.attention.selfattn.query.weight\n",
            "encoder.layer.8.attention.selfattn.query.bias\n",
            "encoder.layer.8.attention.selfattn.key.weight\n",
            "encoder.layer.8.attention.selfattn.key.bias\n",
            "encoder.layer.8.attention.selfattn.value.weight\n",
            "encoder.layer.8.attention.selfattn.value.bias\n",
            "encoder.layer.8.attention.output.dense.weight\n",
            "encoder.layer.8.attention.output.dense.bias\n",
            "encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "encoder.layer.8.attention.output.LayerNorm.beta\n",
            "encoder.layer.8.intermediate.dense.weight\n",
            "encoder.layer.8.intermediate.dense.bias\n",
            "encoder.layer.8.output.dense.weight\n",
            "encoder.layer.8.output.dense.bias\n",
            "encoder.layer.8.output.LayerNorm.gamma\n",
            "encoder.layer.8.output.LayerNorm.beta\n",
            "encoder.layer.9.attention.selfattn.query.weight\n",
            "encoder.layer.9.attention.selfattn.query.bias\n",
            "encoder.layer.9.attention.selfattn.key.weight\n",
            "encoder.layer.9.attention.selfattn.key.bias\n",
            "encoder.layer.9.attention.selfattn.value.weight\n",
            "encoder.layer.9.attention.selfattn.value.bias\n",
            "encoder.layer.9.attention.output.dense.weight\n",
            "encoder.layer.9.attention.output.dense.bias\n",
            "encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "encoder.layer.9.attention.output.LayerNorm.beta\n",
            "encoder.layer.9.intermediate.dense.weight\n",
            "encoder.layer.9.intermediate.dense.bias\n",
            "encoder.layer.9.output.dense.weight\n",
            "encoder.layer.9.output.dense.bias\n",
            "encoder.layer.9.output.LayerNorm.gamma\n",
            "encoder.layer.9.output.LayerNorm.beta\n",
            "encoder.layer.10.attention.selfattn.query.weight\n",
            "encoder.layer.10.attention.selfattn.query.bias\n",
            "encoder.layer.10.attention.selfattn.key.weight\n",
            "encoder.layer.10.attention.selfattn.key.bias\n",
            "encoder.layer.10.attention.selfattn.value.weight\n",
            "encoder.layer.10.attention.selfattn.value.bias\n",
            "encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "encoder.layer.10.attention.output.LayerNorm.beta\n",
            "encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias\n",
            "encoder.layer.10.output.LayerNorm.gamma\n",
            "encoder.layer.10.output.LayerNorm.beta\n",
            "encoder.layer.11.attention.selfattn.query.weight\n",
            "encoder.layer.11.attention.selfattn.query.bias\n",
            "encoder.layer.11.attention.selfattn.key.weight\n",
            "encoder.layer.11.attention.selfattn.key.bias\n",
            "encoder.layer.11.attention.selfattn.value.weight\n",
            "encoder.layer.11.attention.selfattn.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "encoder.layer.11.attention.output.LayerNorm.beta\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.gamma\n",
            "encoder.layer.11.output.LayerNorm.beta\n",
            "pooler.dense.weight\n",
            "pooler.dense.bias\n"
          ]
        }
      ],
      "source": [
        "net = BertModel(config)\n",
        "net.eval()\n",
        "\n",
        "param_names = []\n",
        "\n",
        "for name, param in net.named_parameters():\n",
        "    print(name)\n",
        "    param_names.append(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Hz7bTkL7Mkfd",
        "outputId": "d9689440-c3d4-4331-8ebf-ba4c4b305732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight→pooler.dense.weight\n",
            "bert.pooler.dense.bias→pooler.dense.bias\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "new_state_dict = net.state_dict().copy()\n",
        "\n",
        "for index, (key_name, value) in enumerate(loaded_state_dict.items()):\n",
        "    name = param_names[index]  \n",
        "    new_state_dict[name] = value \n",
        "    print(str(key_name)+\"→\"+str(name))\n",
        "\n",
        "    if index+1 >= len(param_names):\n",
        "        break\n",
        "\n",
        "net.load_state_dict(new_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ORtdWAWuMkfd"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    vocab = collections.OrderedDict()\n",
        "    ids_to_tokens = collections.OrderedDict()\n",
        "    index = 0\n",
        "\n",
        "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
        "        while True:\n",
        "            token = reader.readline()\n",
        "            if not token:\n",
        "                break\n",
        "            token = token.strip()\n",
        "\n",
        "            vocab[token] = index\n",
        "            ids_to_tokens[index] = token\n",
        "            index += 1\n",
        "\n",
        "    return vocab, ids_to_tokens\n",
        "\n",
        "\n",
        "vocab_file = \"./vocab/bert-base-uncased-vocab.txt\"\n",
        "vocab, ids_to_tokens = load_vocab(vocab_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k7xB-rHhMkfd",
        "outputId": "a661176e-3a22-44dc-cc5c-79de57cb9e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('[PAD]', 0),\n",
              "             ('[unused0]', 1),\n",
              "             ('[unused1]', 2),\n",
              "             ('[unused2]', 3),\n",
              "             ('[unused3]', 4),\n",
              "             ('[unused4]', 5),\n",
              "             ('[unused5]', 6),\n",
              "             ('[unused6]', 7),\n",
              "             ('[unused7]', 8),\n",
              "             ('[unused8]', 9),\n",
              "             ('[unused9]', 10),\n",
              "             ('[unused10]', 11),\n",
              "             ('[unused11]', 12),\n",
              "             ('[unused12]', 13),\n",
              "             ('[unused13]', 14),\n",
              "             ('[unused14]', 15),\n",
              "             ('[unused15]', 16),\n",
              "             ('[unused16]', 17),\n",
              "             ('[unused17]', 18),\n",
              "             ('[unused18]', 19),\n",
              "             ('[unused19]', 20),\n",
              "             ('[unused20]', 21),\n",
              "             ('[unused21]', 22),\n",
              "             ('[unused22]', 23),\n",
              "             ('[unused23]', 24),\n",
              "             ('[unused24]', 25),\n",
              "             ('[unused25]', 26),\n",
              "             ('[unused26]', 27),\n",
              "             ('[unused27]', 28),\n",
              "             ('[unused28]', 29),\n",
              "             ('[unused29]', 30),\n",
              "             ('[unused30]', 31),\n",
              "             ('[unused31]', 32),\n",
              "             ('[unused32]', 33),\n",
              "             ('[unused33]', 34),\n",
              "             ('[unused34]', 35),\n",
              "             ('[unused35]', 36),\n",
              "             ('[unused36]', 37),\n",
              "             ('[unused37]', 38),\n",
              "             ('[unused38]', 39),\n",
              "             ('[unused39]', 40),\n",
              "             ('[unused40]', 41),\n",
              "             ('[unused41]', 42),\n",
              "             ('[unused42]', 43),\n",
              "             ('[unused43]', 44),\n",
              "             ('[unused44]', 45),\n",
              "             ('[unused45]', 46),\n",
              "             ('[unused46]', 47),\n",
              "             ('[unused47]', 48),\n",
              "             ('[unused48]', 49),\n",
              "             ('[unused49]', 50),\n",
              "             ('[unused50]', 51),\n",
              "             ('[unused51]', 52),\n",
              "             ('[unused52]', 53),\n",
              "             ('[unused53]', 54),\n",
              "             ('[unused54]', 55),\n",
              "             ('[unused55]', 56),\n",
              "             ('[unused56]', 57),\n",
              "             ('[unused57]', 58),\n",
              "             ('[unused58]', 59),\n",
              "             ('[unused59]', 60),\n",
              "             ('[unused60]', 61),\n",
              "             ('[unused61]', 62),\n",
              "             ('[unused62]', 63),\n",
              "             ('[unused63]', 64),\n",
              "             ('[unused64]', 65),\n",
              "             ('[unused65]', 66),\n",
              "             ('[unused66]', 67),\n",
              "             ('[unused67]', 68),\n",
              "             ('[unused68]', 69),\n",
              "             ('[unused69]', 70),\n",
              "             ('[unused70]', 71),\n",
              "             ('[unused71]', 72),\n",
              "             ('[unused72]', 73),\n",
              "             ('[unused73]', 74),\n",
              "             ('[unused74]', 75),\n",
              "             ('[unused75]', 76),\n",
              "             ('[unused76]', 77),\n",
              "             ('[unused77]', 78),\n",
              "             ('[unused78]', 79),\n",
              "             ('[unused79]', 80),\n",
              "             ('[unused80]', 81),\n",
              "             ('[unused81]', 82),\n",
              "             ('[unused82]', 83),\n",
              "             ('[unused83]', 84),\n",
              "             ('[unused84]', 85),\n",
              "             ('[unused85]', 86),\n",
              "             ('[unused86]', 87),\n",
              "             ('[unused87]', 88),\n",
              "             ('[unused88]', 89),\n",
              "             ('[unused89]', 90),\n",
              "             ('[unused90]', 91),\n",
              "             ('[unused91]', 92),\n",
              "             ('[unused92]', 93),\n",
              "             ('[unused93]', 94),\n",
              "             ('[unused94]', 95),\n",
              "             ('[unused95]', 96),\n",
              "             ('[unused96]', 97),\n",
              "             ('[unused97]', 98),\n",
              "             ('[unused98]', 99),\n",
              "             ('[UNK]', 100),\n",
              "             ('[CLS]', 101),\n",
              "             ('[SEP]', 102),\n",
              "             ('[MASK]', 103),\n",
              "             ('[unused99]', 104),\n",
              "             ('[unused100]', 105),\n",
              "             ('[unused101]', 106),\n",
              "             ('[unused102]', 107),\n",
              "             ('[unused103]', 108),\n",
              "             ('[unused104]', 109),\n",
              "             ('[unused105]', 110),\n",
              "             ('[unused106]', 111),\n",
              "             ('[unused107]', 112),\n",
              "             ('[unused108]', 113),\n",
              "             ('[unused109]', 114),\n",
              "             ('[unused110]', 115),\n",
              "             ('[unused111]', 116),\n",
              "             ('[unused112]', 117),\n",
              "             ('[unused113]', 118),\n",
              "             ('[unused114]', 119),\n",
              "             ('[unused115]', 120),\n",
              "             ('[unused116]', 121),\n",
              "             ('[unused117]', 122),\n",
              "             ('[unused118]', 123),\n",
              "             ('[unused119]', 124),\n",
              "             ('[unused120]', 125),\n",
              "             ('[unused121]', 126),\n",
              "             ('[unused122]', 127),\n",
              "             ('[unused123]', 128),\n",
              "             ('[unused124]', 129),\n",
              "             ('[unused125]', 130),\n",
              "             ('[unused126]', 131),\n",
              "             ('[unused127]', 132),\n",
              "             ('[unused128]', 133),\n",
              "             ('[unused129]', 134),\n",
              "             ('[unused130]', 135),\n",
              "             ('[unused131]', 136),\n",
              "             ('[unused132]', 137),\n",
              "             ('[unused133]', 138),\n",
              "             ('[unused134]', 139),\n",
              "             ('[unused135]', 140),\n",
              "             ('[unused136]', 141),\n",
              "             ('[unused137]', 142),\n",
              "             ('[unused138]', 143),\n",
              "             ('[unused139]', 144),\n",
              "             ('[unused140]', 145),\n",
              "             ('[unused141]', 146),\n",
              "             ('[unused142]', 147),\n",
              "             ('[unused143]', 148),\n",
              "             ('[unused144]', 149),\n",
              "             ('[unused145]', 150),\n",
              "             ('[unused146]', 151),\n",
              "             ('[unused147]', 152),\n",
              "             ('[unused148]', 153),\n",
              "             ('[unused149]', 154),\n",
              "             ('[unused150]', 155),\n",
              "             ('[unused151]', 156),\n",
              "             ('[unused152]', 157),\n",
              "             ('[unused153]', 158),\n",
              "             ('[unused154]', 159),\n",
              "             ('[unused155]', 160),\n",
              "             ('[unused156]', 161),\n",
              "             ('[unused157]', 162),\n",
              "             ('[unused158]', 163),\n",
              "             ('[unused159]', 164),\n",
              "             ('[unused160]', 165),\n",
              "             ('[unused161]', 166),\n",
              "             ('[unused162]', 167),\n",
              "             ('[unused163]', 168),\n",
              "             ('[unused164]', 169),\n",
              "             ('[unused165]', 170),\n",
              "             ('[unused166]', 171),\n",
              "             ('[unused167]', 172),\n",
              "             ('[unused168]', 173),\n",
              "             ('[unused169]', 174),\n",
              "             ('[unused170]', 175),\n",
              "             ('[unused171]', 176),\n",
              "             ('[unused172]', 177),\n",
              "             ('[unused173]', 178),\n",
              "             ('[unused174]', 179),\n",
              "             ('[unused175]', 180),\n",
              "             ('[unused176]', 181),\n",
              "             ('[unused177]', 182),\n",
              "             ('[unused178]', 183),\n",
              "             ('[unused179]', 184),\n",
              "             ('[unused180]', 185),\n",
              "             ('[unused181]', 186),\n",
              "             ('[unused182]', 187),\n",
              "             ('[unused183]', 188),\n",
              "             ('[unused184]', 189),\n",
              "             ('[unused185]', 190),\n",
              "             ('[unused186]', 191),\n",
              "             ('[unused187]', 192),\n",
              "             ('[unused188]', 193),\n",
              "             ('[unused189]', 194),\n",
              "             ('[unused190]', 195),\n",
              "             ('[unused191]', 196),\n",
              "             ('[unused192]', 197),\n",
              "             ('[unused193]', 198),\n",
              "             ('[unused194]', 199),\n",
              "             ('[unused195]', 200),\n",
              "             ('[unused196]', 201),\n",
              "             ('[unused197]', 202),\n",
              "             ('[unused198]', 203),\n",
              "             ('[unused199]', 204),\n",
              "             ('[unused200]', 205),\n",
              "             ('[unused201]', 206),\n",
              "             ('[unused202]', 207),\n",
              "             ('[unused203]', 208),\n",
              "             ('[unused204]', 209),\n",
              "             ('[unused205]', 210),\n",
              "             ('[unused206]', 211),\n",
              "             ('[unused207]', 212),\n",
              "             ('[unused208]', 213),\n",
              "             ('[unused209]', 214),\n",
              "             ('[unused210]', 215),\n",
              "             ('[unused211]', 216),\n",
              "             ('[unused212]', 217),\n",
              "             ('[unused213]', 218),\n",
              "             ('[unused214]', 219),\n",
              "             ('[unused215]', 220),\n",
              "             ('[unused216]', 221),\n",
              "             ('[unused217]', 222),\n",
              "             ('[unused218]', 223),\n",
              "             ('[unused219]', 224),\n",
              "             ('[unused220]', 225),\n",
              "             ('[unused221]', 226),\n",
              "             ('[unused222]', 227),\n",
              "             ('[unused223]', 228),\n",
              "             ('[unused224]', 229),\n",
              "             ('[unused225]', 230),\n",
              "             ('[unused226]', 231),\n",
              "             ('[unused227]', 232),\n",
              "             ('[unused228]', 233),\n",
              "             ('[unused229]', 234),\n",
              "             ('[unused230]', 235),\n",
              "             ('[unused231]', 236),\n",
              "             ('[unused232]', 237),\n",
              "             ('[unused233]', 238),\n",
              "             ('[unused234]', 239),\n",
              "             ('[unused235]', 240),\n",
              "             ('[unused236]', 241),\n",
              "             ('[unused237]', 242),\n",
              "             ('[unused238]', 243),\n",
              "             ('[unused239]', 244),\n",
              "             ('[unused240]', 245),\n",
              "             ('[unused241]', 246),\n",
              "             ('[unused242]', 247),\n",
              "             ('[unused243]', 248),\n",
              "             ('[unused244]', 249),\n",
              "             ('[unused245]', 250),\n",
              "             ('[unused246]', 251),\n",
              "             ('[unused247]', 252),\n",
              "             ('[unused248]', 253),\n",
              "             ('[unused249]', 254),\n",
              "             ('[unused250]', 255),\n",
              "             ('[unused251]', 256),\n",
              "             ('[unused252]', 257),\n",
              "             ('[unused253]', 258),\n",
              "             ('[unused254]', 259),\n",
              "             ('[unused255]', 260),\n",
              "             ('[unused256]', 261),\n",
              "             ('[unused257]', 262),\n",
              "             ('[unused258]', 263),\n",
              "             ('[unused259]', 264),\n",
              "             ('[unused260]', 265),\n",
              "             ('[unused261]', 266),\n",
              "             ('[unused262]', 267),\n",
              "             ('[unused263]', 268),\n",
              "             ('[unused264]', 269),\n",
              "             ('[unused265]', 270),\n",
              "             ('[unused266]', 271),\n",
              "             ('[unused267]', 272),\n",
              "             ('[unused268]', 273),\n",
              "             ('[unused269]', 274),\n",
              "             ('[unused270]', 275),\n",
              "             ('[unused271]', 276),\n",
              "             ('[unused272]', 277),\n",
              "             ('[unused273]', 278),\n",
              "             ('[unused274]', 279),\n",
              "             ('[unused275]', 280),\n",
              "             ('[unused276]', 281),\n",
              "             ('[unused277]', 282),\n",
              "             ('[unused278]', 283),\n",
              "             ('[unused279]', 284),\n",
              "             ('[unused280]', 285),\n",
              "             ('[unused281]', 286),\n",
              "             ('[unused282]', 287),\n",
              "             ('[unused283]', 288),\n",
              "             ('[unused284]', 289),\n",
              "             ('[unused285]', 290),\n",
              "             ('[unused286]', 291),\n",
              "             ('[unused287]', 292),\n",
              "             ('[unused288]', 293),\n",
              "             ('[unused289]', 294),\n",
              "             ('[unused290]', 295),\n",
              "             ('[unused291]', 296),\n",
              "             ('[unused292]', 297),\n",
              "             ('[unused293]', 298),\n",
              "             ('[unused294]', 299),\n",
              "             ('[unused295]', 300),\n",
              "             ('[unused296]', 301),\n",
              "             ('[unused297]', 302),\n",
              "             ('[unused298]', 303),\n",
              "             ('[unused299]', 304),\n",
              "             ('[unused300]', 305),\n",
              "             ('[unused301]', 306),\n",
              "             ('[unused302]', 307),\n",
              "             ('[unused303]', 308),\n",
              "             ('[unused304]', 309),\n",
              "             ('[unused305]', 310),\n",
              "             ('[unused306]', 311),\n",
              "             ('[unused307]', 312),\n",
              "             ('[unused308]', 313),\n",
              "             ('[unused309]', 314),\n",
              "             ('[unused310]', 315),\n",
              "             ('[unused311]', 316),\n",
              "             ('[unused312]', 317),\n",
              "             ('[unused313]', 318),\n",
              "             ('[unused314]', 319),\n",
              "             ('[unused315]', 320),\n",
              "             ('[unused316]', 321),\n",
              "             ('[unused317]', 322),\n",
              "             ('[unused318]', 323),\n",
              "             ('[unused319]', 324),\n",
              "             ('[unused320]', 325),\n",
              "             ('[unused321]', 326),\n",
              "             ('[unused322]', 327),\n",
              "             ('[unused323]', 328),\n",
              "             ('[unused324]', 329),\n",
              "             ('[unused325]', 330),\n",
              "             ('[unused326]', 331),\n",
              "             ('[unused327]', 332),\n",
              "             ('[unused328]', 333),\n",
              "             ('[unused329]', 334),\n",
              "             ('[unused330]', 335),\n",
              "             ('[unused331]', 336),\n",
              "             ('[unused332]', 337),\n",
              "             ('[unused333]', 338),\n",
              "             ('[unused334]', 339),\n",
              "             ('[unused335]', 340),\n",
              "             ('[unused336]', 341),\n",
              "             ('[unused337]', 342),\n",
              "             ('[unused338]', 343),\n",
              "             ('[unused339]', 344),\n",
              "             ('[unused340]', 345),\n",
              "             ('[unused341]', 346),\n",
              "             ('[unused342]', 347),\n",
              "             ('[unused343]', 348),\n",
              "             ('[unused344]', 349),\n",
              "             ('[unused345]', 350),\n",
              "             ('[unused346]', 351),\n",
              "             ('[unused347]', 352),\n",
              "             ('[unused348]', 353),\n",
              "             ('[unused349]', 354),\n",
              "             ('[unused350]', 355),\n",
              "             ('[unused351]', 356),\n",
              "             ('[unused352]', 357),\n",
              "             ('[unused353]', 358),\n",
              "             ('[unused354]', 359),\n",
              "             ('[unused355]', 360),\n",
              "             ('[unused356]', 361),\n",
              "             ('[unused357]', 362),\n",
              "             ('[unused358]', 363),\n",
              "             ('[unused359]', 364),\n",
              "             ('[unused360]', 365),\n",
              "             ('[unused361]', 366),\n",
              "             ('[unused362]', 367),\n",
              "             ('[unused363]', 368),\n",
              "             ('[unused364]', 369),\n",
              "             ('[unused365]', 370),\n",
              "             ('[unused366]', 371),\n",
              "             ('[unused367]', 372),\n",
              "             ('[unused368]', 373),\n",
              "             ('[unused369]', 374),\n",
              "             ('[unused370]', 375),\n",
              "             ('[unused371]', 376),\n",
              "             ('[unused372]', 377),\n",
              "             ('[unused373]', 378),\n",
              "             ('[unused374]', 379),\n",
              "             ('[unused375]', 380),\n",
              "             ('[unused376]', 381),\n",
              "             ('[unused377]', 382),\n",
              "             ('[unused378]', 383),\n",
              "             ('[unused379]', 384),\n",
              "             ('[unused380]', 385),\n",
              "             ('[unused381]', 386),\n",
              "             ('[unused382]', 387),\n",
              "             ('[unused383]', 388),\n",
              "             ('[unused384]', 389),\n",
              "             ('[unused385]', 390),\n",
              "             ('[unused386]', 391),\n",
              "             ('[unused387]', 392),\n",
              "             ('[unused388]', 393),\n",
              "             ('[unused389]', 394),\n",
              "             ('[unused390]', 395),\n",
              "             ('[unused391]', 396),\n",
              "             ('[unused392]', 397),\n",
              "             ('[unused393]', 398),\n",
              "             ('[unused394]', 399),\n",
              "             ('[unused395]', 400),\n",
              "             ('[unused396]', 401),\n",
              "             ('[unused397]', 402),\n",
              "             ('[unused398]', 403),\n",
              "             ('[unused399]', 404),\n",
              "             ('[unused400]', 405),\n",
              "             ('[unused401]', 406),\n",
              "             ('[unused402]', 407),\n",
              "             ('[unused403]', 408),\n",
              "             ('[unused404]', 409),\n",
              "             ('[unused405]', 410),\n",
              "             ('[unused406]', 411),\n",
              "             ('[unused407]', 412),\n",
              "             ('[unused408]', 413),\n",
              "             ('[unused409]', 414),\n",
              "             ('[unused410]', 415),\n",
              "             ('[unused411]', 416),\n",
              "             ('[unused412]', 417),\n",
              "             ('[unused413]', 418),\n",
              "             ('[unused414]', 419),\n",
              "             ('[unused415]', 420),\n",
              "             ('[unused416]', 421),\n",
              "             ('[unused417]', 422),\n",
              "             ('[unused418]', 423),\n",
              "             ('[unused419]', 424),\n",
              "             ('[unused420]', 425),\n",
              "             ('[unused421]', 426),\n",
              "             ('[unused422]', 427),\n",
              "             ('[unused423]', 428),\n",
              "             ('[unused424]', 429),\n",
              "             ('[unused425]', 430),\n",
              "             ('[unused426]', 431),\n",
              "             ('[unused427]', 432),\n",
              "             ('[unused428]', 433),\n",
              "             ('[unused429]', 434),\n",
              "             ('[unused430]', 435),\n",
              "             ('[unused431]', 436),\n",
              "             ('[unused432]', 437),\n",
              "             ('[unused433]', 438),\n",
              "             ('[unused434]', 439),\n",
              "             ('[unused435]', 440),\n",
              "             ('[unused436]', 441),\n",
              "             ('[unused437]', 442),\n",
              "             ('[unused438]', 443),\n",
              "             ('[unused439]', 444),\n",
              "             ('[unused440]', 445),\n",
              "             ('[unused441]', 446),\n",
              "             ('[unused442]', 447),\n",
              "             ('[unused443]', 448),\n",
              "             ('[unused444]', 449),\n",
              "             ('[unused445]', 450),\n",
              "             ('[unused446]', 451),\n",
              "             ('[unused447]', 452),\n",
              "             ('[unused448]', 453),\n",
              "             ('[unused449]', 454),\n",
              "             ('[unused450]', 455),\n",
              "             ('[unused451]', 456),\n",
              "             ('[unused452]', 457),\n",
              "             ('[unused453]', 458),\n",
              "             ('[unused454]', 459),\n",
              "             ('[unused455]', 460),\n",
              "             ('[unused456]', 461),\n",
              "             ('[unused457]', 462),\n",
              "             ('[unused458]', 463),\n",
              "             ('[unused459]', 464),\n",
              "             ('[unused460]', 465),\n",
              "             ('[unused461]', 466),\n",
              "             ('[unused462]', 467),\n",
              "             ('[unused463]', 468),\n",
              "             ('[unused464]', 469),\n",
              "             ('[unused465]', 470),\n",
              "             ('[unused466]', 471),\n",
              "             ('[unused467]', 472),\n",
              "             ('[unused468]', 473),\n",
              "             ('[unused469]', 474),\n",
              "             ('[unused470]', 475),\n",
              "             ('[unused471]', 476),\n",
              "             ('[unused472]', 477),\n",
              "             ('[unused473]', 478),\n",
              "             ('[unused474]', 479),\n",
              "             ('[unused475]', 480),\n",
              "             ('[unused476]', 481),\n",
              "             ('[unused477]', 482),\n",
              "             ('[unused478]', 483),\n",
              "             ('[unused479]', 484),\n",
              "             ('[unused480]', 485),\n",
              "             ('[unused481]', 486),\n",
              "             ('[unused482]', 487),\n",
              "             ('[unused483]', 488),\n",
              "             ('[unused484]', 489),\n",
              "             ('[unused485]', 490),\n",
              "             ('[unused486]', 491),\n",
              "             ('[unused487]', 492),\n",
              "             ('[unused488]', 493),\n",
              "             ('[unused489]', 494),\n",
              "             ('[unused490]', 495),\n",
              "             ('[unused491]', 496),\n",
              "             ('[unused492]', 497),\n",
              "             ('[unused493]', 498),\n",
              "             ('[unused494]', 499),\n",
              "             ('[unused495]', 500),\n",
              "             ('[unused496]', 501),\n",
              "             ('[unused497]', 502),\n",
              "             ('[unused498]', 503),\n",
              "             ('[unused499]', 504),\n",
              "             ('[unused500]', 505),\n",
              "             ('[unused501]', 506),\n",
              "             ('[unused502]', 507),\n",
              "             ('[unused503]', 508),\n",
              "             ('[unused504]', 509),\n",
              "             ('[unused505]', 510),\n",
              "             ('[unused506]', 511),\n",
              "             ('[unused507]', 512),\n",
              "             ('[unused508]', 513),\n",
              "             ('[unused509]', 514),\n",
              "             ('[unused510]', 515),\n",
              "             ('[unused511]', 516),\n",
              "             ('[unused512]', 517),\n",
              "             ('[unused513]', 518),\n",
              "             ('[unused514]', 519),\n",
              "             ('[unused515]', 520),\n",
              "             ('[unused516]', 521),\n",
              "             ('[unused517]', 522),\n",
              "             ('[unused518]', 523),\n",
              "             ('[unused519]', 524),\n",
              "             ('[unused520]', 525),\n",
              "             ('[unused521]', 526),\n",
              "             ('[unused522]', 527),\n",
              "             ('[unused523]', 528),\n",
              "             ('[unused524]', 529),\n",
              "             ('[unused525]', 530),\n",
              "             ('[unused526]', 531),\n",
              "             ('[unused527]', 532),\n",
              "             ('[unused528]', 533),\n",
              "             ('[unused529]', 534),\n",
              "             ('[unused530]', 535),\n",
              "             ('[unused531]', 536),\n",
              "             ('[unused532]', 537),\n",
              "             ('[unused533]', 538),\n",
              "             ('[unused534]', 539),\n",
              "             ('[unused535]', 540),\n",
              "             ('[unused536]', 541),\n",
              "             ('[unused537]', 542),\n",
              "             ('[unused538]', 543),\n",
              "             ('[unused539]', 544),\n",
              "             ('[unused540]', 545),\n",
              "             ('[unused541]', 546),\n",
              "             ('[unused542]', 547),\n",
              "             ('[unused543]', 548),\n",
              "             ('[unused544]', 549),\n",
              "             ('[unused545]', 550),\n",
              "             ('[unused546]', 551),\n",
              "             ('[unused547]', 552),\n",
              "             ('[unused548]', 553),\n",
              "             ('[unused549]', 554),\n",
              "             ('[unused550]', 555),\n",
              "             ('[unused551]', 556),\n",
              "             ('[unused552]', 557),\n",
              "             ('[unused553]', 558),\n",
              "             ('[unused554]', 559),\n",
              "             ('[unused555]', 560),\n",
              "             ('[unused556]', 561),\n",
              "             ('[unused557]', 562),\n",
              "             ('[unused558]', 563),\n",
              "             ('[unused559]', 564),\n",
              "             ('[unused560]', 565),\n",
              "             ('[unused561]', 566),\n",
              "             ('[unused562]', 567),\n",
              "             ('[unused563]', 568),\n",
              "             ('[unused564]', 569),\n",
              "             ('[unused565]', 570),\n",
              "             ('[unused566]', 571),\n",
              "             ('[unused567]', 572),\n",
              "             ('[unused568]', 573),\n",
              "             ('[unused569]', 574),\n",
              "             ('[unused570]', 575),\n",
              "             ('[unused571]', 576),\n",
              "             ('[unused572]', 577),\n",
              "             ('[unused573]', 578),\n",
              "             ('[unused574]', 579),\n",
              "             ('[unused575]', 580),\n",
              "             ('[unused576]', 581),\n",
              "             ('[unused577]', 582),\n",
              "             ('[unused578]', 583),\n",
              "             ('[unused579]', 584),\n",
              "             ('[unused580]', 585),\n",
              "             ('[unused581]', 586),\n",
              "             ('[unused582]', 587),\n",
              "             ('[unused583]', 588),\n",
              "             ('[unused584]', 589),\n",
              "             ('[unused585]', 590),\n",
              "             ('[unused586]', 591),\n",
              "             ('[unused587]', 592),\n",
              "             ('[unused588]', 593),\n",
              "             ('[unused589]', 594),\n",
              "             ('[unused590]', 595),\n",
              "             ('[unused591]', 596),\n",
              "             ('[unused592]', 597),\n",
              "             ('[unused593]', 598),\n",
              "             ('[unused594]', 599),\n",
              "             ('[unused595]', 600),\n",
              "             ('[unused596]', 601),\n",
              "             ('[unused597]', 602),\n",
              "             ('[unused598]', 603),\n",
              "             ('[unused599]', 604),\n",
              "             ('[unused600]', 605),\n",
              "             ('[unused601]', 606),\n",
              "             ('[unused602]', 607),\n",
              "             ('[unused603]', 608),\n",
              "             ('[unused604]', 609),\n",
              "             ('[unused605]', 610),\n",
              "             ('[unused606]', 611),\n",
              "             ('[unused607]', 612),\n",
              "             ('[unused608]', 613),\n",
              "             ('[unused609]', 614),\n",
              "             ('[unused610]', 615),\n",
              "             ('[unused611]', 616),\n",
              "             ('[unused612]', 617),\n",
              "             ('[unused613]', 618),\n",
              "             ('[unused614]', 619),\n",
              "             ('[unused615]', 620),\n",
              "             ('[unused616]', 621),\n",
              "             ('[unused617]', 622),\n",
              "             ('[unused618]', 623),\n",
              "             ('[unused619]', 624),\n",
              "             ('[unused620]', 625),\n",
              "             ('[unused621]', 626),\n",
              "             ('[unused622]', 627),\n",
              "             ('[unused623]', 628),\n",
              "             ('[unused624]', 629),\n",
              "             ('[unused625]', 630),\n",
              "             ('[unused626]', 631),\n",
              "             ('[unused627]', 632),\n",
              "             ('[unused628]', 633),\n",
              "             ('[unused629]', 634),\n",
              "             ('[unused630]', 635),\n",
              "             ('[unused631]', 636),\n",
              "             ('[unused632]', 637),\n",
              "             ('[unused633]', 638),\n",
              "             ('[unused634]', 639),\n",
              "             ('[unused635]', 640),\n",
              "             ('[unused636]', 641),\n",
              "             ('[unused637]', 642),\n",
              "             ('[unused638]', 643),\n",
              "             ('[unused639]', 644),\n",
              "             ('[unused640]', 645),\n",
              "             ('[unused641]', 646),\n",
              "             ('[unused642]', 647),\n",
              "             ('[unused643]', 648),\n",
              "             ('[unused644]', 649),\n",
              "             ('[unused645]', 650),\n",
              "             ('[unused646]', 651),\n",
              "             ('[unused647]', 652),\n",
              "             ('[unused648]', 653),\n",
              "             ('[unused649]', 654),\n",
              "             ('[unused650]', 655),\n",
              "             ('[unused651]', 656),\n",
              "             ('[unused652]', 657),\n",
              "             ('[unused653]', 658),\n",
              "             ('[unused654]', 659),\n",
              "             ('[unused655]', 660),\n",
              "             ('[unused656]', 661),\n",
              "             ('[unused657]', 662),\n",
              "             ('[unused658]', 663),\n",
              "             ('[unused659]', 664),\n",
              "             ('[unused660]', 665),\n",
              "             ('[unused661]', 666),\n",
              "             ('[unused662]', 667),\n",
              "             ('[unused663]', 668),\n",
              "             ('[unused664]', 669),\n",
              "             ('[unused665]', 670),\n",
              "             ('[unused666]', 671),\n",
              "             ('[unused667]', 672),\n",
              "             ('[unused668]', 673),\n",
              "             ('[unused669]', 674),\n",
              "             ('[unused670]', 675),\n",
              "             ('[unused671]', 676),\n",
              "             ('[unused672]', 677),\n",
              "             ('[unused673]', 678),\n",
              "             ('[unused674]', 679),\n",
              "             ('[unused675]', 680),\n",
              "             ('[unused676]', 681),\n",
              "             ('[unused677]', 682),\n",
              "             ('[unused678]', 683),\n",
              "             ('[unused679]', 684),\n",
              "             ('[unused680]', 685),\n",
              "             ('[unused681]', 686),\n",
              "             ('[unused682]', 687),\n",
              "             ('[unused683]', 688),\n",
              "             ('[unused684]', 689),\n",
              "             ('[unused685]', 690),\n",
              "             ('[unused686]', 691),\n",
              "             ('[unused687]', 692),\n",
              "             ('[unused688]', 693),\n",
              "             ('[unused689]', 694),\n",
              "             ('[unused690]', 695),\n",
              "             ('[unused691]', 696),\n",
              "             ('[unused692]', 697),\n",
              "             ('[unused693]', 698),\n",
              "             ('[unused694]', 699),\n",
              "             ('[unused695]', 700),\n",
              "             ('[unused696]', 701),\n",
              "             ('[unused697]', 702),\n",
              "             ('[unused698]', 703),\n",
              "             ('[unused699]', 704),\n",
              "             ('[unused700]', 705),\n",
              "             ('[unused701]', 706),\n",
              "             ('[unused702]', 707),\n",
              "             ('[unused703]', 708),\n",
              "             ('[unused704]', 709),\n",
              "             ('[unused705]', 710),\n",
              "             ('[unused706]', 711),\n",
              "             ('[unused707]', 712),\n",
              "             ('[unused708]', 713),\n",
              "             ('[unused709]', 714),\n",
              "             ('[unused710]', 715),\n",
              "             ('[unused711]', 716),\n",
              "             ('[unused712]', 717),\n",
              "             ('[unused713]', 718),\n",
              "             ('[unused714]', 719),\n",
              "             ('[unused715]', 720),\n",
              "             ('[unused716]', 721),\n",
              "             ('[unused717]', 722),\n",
              "             ('[unused718]', 723),\n",
              "             ('[unused719]', 724),\n",
              "             ('[unused720]', 725),\n",
              "             ('[unused721]', 726),\n",
              "             ('[unused722]', 727),\n",
              "             ('[unused723]', 728),\n",
              "             ('[unused724]', 729),\n",
              "             ('[unused725]', 730),\n",
              "             ('[unused726]', 731),\n",
              "             ('[unused727]', 732),\n",
              "             ('[unused728]', 733),\n",
              "             ('[unused729]', 734),\n",
              "             ('[unused730]', 735),\n",
              "             ('[unused731]', 736),\n",
              "             ('[unused732]', 737),\n",
              "             ('[unused733]', 738),\n",
              "             ('[unused734]', 739),\n",
              "             ('[unused735]', 740),\n",
              "             ('[unused736]', 741),\n",
              "             ('[unused737]', 742),\n",
              "             ('[unused738]', 743),\n",
              "             ('[unused739]', 744),\n",
              "             ('[unused740]', 745),\n",
              "             ('[unused741]', 746),\n",
              "             ('[unused742]', 747),\n",
              "             ('[unused743]', 748),\n",
              "             ('[unused744]', 749),\n",
              "             ('[unused745]', 750),\n",
              "             ('[unused746]', 751),\n",
              "             ('[unused747]', 752),\n",
              "             ('[unused748]', 753),\n",
              "             ('[unused749]', 754),\n",
              "             ('[unused750]', 755),\n",
              "             ('[unused751]', 756),\n",
              "             ('[unused752]', 757),\n",
              "             ('[unused753]', 758),\n",
              "             ('[unused754]', 759),\n",
              "             ('[unused755]', 760),\n",
              "             ('[unused756]', 761),\n",
              "             ('[unused757]', 762),\n",
              "             ('[unused758]', 763),\n",
              "             ('[unused759]', 764),\n",
              "             ('[unused760]', 765),\n",
              "             ('[unused761]', 766),\n",
              "             ('[unused762]', 767),\n",
              "             ('[unused763]', 768),\n",
              "             ('[unused764]', 769),\n",
              "             ('[unused765]', 770),\n",
              "             ('[unused766]', 771),\n",
              "             ('[unused767]', 772),\n",
              "             ('[unused768]', 773),\n",
              "             ('[unused769]', 774),\n",
              "             ('[unused770]', 775),\n",
              "             ('[unused771]', 776),\n",
              "             ('[unused772]', 777),\n",
              "             ('[unused773]', 778),\n",
              "             ('[unused774]', 779),\n",
              "             ('[unused775]', 780),\n",
              "             ('[unused776]', 781),\n",
              "             ('[unused777]', 782),\n",
              "             ('[unused778]', 783),\n",
              "             ('[unused779]', 784),\n",
              "             ('[unused780]', 785),\n",
              "             ('[unused781]', 786),\n",
              "             ('[unused782]', 787),\n",
              "             ('[unused783]', 788),\n",
              "             ('[unused784]', 789),\n",
              "             ('[unused785]', 790),\n",
              "             ('[unused786]', 791),\n",
              "             ('[unused787]', 792),\n",
              "             ('[unused788]', 793),\n",
              "             ('[unused789]', 794),\n",
              "             ('[unused790]', 795),\n",
              "             ('[unused791]', 796),\n",
              "             ('[unused792]', 797),\n",
              "             ('[unused793]', 798),\n",
              "             ('[unused794]', 799),\n",
              "             ('[unused795]', 800),\n",
              "             ('[unused796]', 801),\n",
              "             ('[unused797]', 802),\n",
              "             ('[unused798]', 803),\n",
              "             ('[unused799]', 804),\n",
              "             ('[unused800]', 805),\n",
              "             ('[unused801]', 806),\n",
              "             ('[unused802]', 807),\n",
              "             ('[unused803]', 808),\n",
              "             ('[unused804]', 809),\n",
              "             ('[unused805]', 810),\n",
              "             ('[unused806]', 811),\n",
              "             ('[unused807]', 812),\n",
              "             ('[unused808]', 813),\n",
              "             ('[unused809]', 814),\n",
              "             ('[unused810]', 815),\n",
              "             ('[unused811]', 816),\n",
              "             ('[unused812]', 817),\n",
              "             ('[unused813]', 818),\n",
              "             ('[unused814]', 819),\n",
              "             ('[unused815]', 820),\n",
              "             ('[unused816]', 821),\n",
              "             ('[unused817]', 822),\n",
              "             ('[unused818]', 823),\n",
              "             ('[unused819]', 824),\n",
              "             ('[unused820]', 825),\n",
              "             ('[unused821]', 826),\n",
              "             ('[unused822]', 827),\n",
              "             ('[unused823]', 828),\n",
              "             ('[unused824]', 829),\n",
              "             ('[unused825]', 830),\n",
              "             ('[unused826]', 831),\n",
              "             ('[unused827]', 832),\n",
              "             ('[unused828]', 833),\n",
              "             ('[unused829]', 834),\n",
              "             ('[unused830]', 835),\n",
              "             ('[unused831]', 836),\n",
              "             ('[unused832]', 837),\n",
              "             ('[unused833]', 838),\n",
              "             ('[unused834]', 839),\n",
              "             ('[unused835]', 840),\n",
              "             ('[unused836]', 841),\n",
              "             ('[unused837]', 842),\n",
              "             ('[unused838]', 843),\n",
              "             ('[unused839]', 844),\n",
              "             ('[unused840]', 845),\n",
              "             ('[unused841]', 846),\n",
              "             ('[unused842]', 847),\n",
              "             ('[unused843]', 848),\n",
              "             ('[unused844]', 849),\n",
              "             ('[unused845]', 850),\n",
              "             ('[unused846]', 851),\n",
              "             ('[unused847]', 852),\n",
              "             ('[unused848]', 853),\n",
              "             ('[unused849]', 854),\n",
              "             ('[unused850]', 855),\n",
              "             ('[unused851]', 856),\n",
              "             ('[unused852]', 857),\n",
              "             ('[unused853]', 858),\n",
              "             ('[unused854]', 859),\n",
              "             ('[unused855]', 860),\n",
              "             ('[unused856]', 861),\n",
              "             ('[unused857]', 862),\n",
              "             ('[unused858]', 863),\n",
              "             ('[unused859]', 864),\n",
              "             ('[unused860]', 865),\n",
              "             ('[unused861]', 866),\n",
              "             ('[unused862]', 867),\n",
              "             ('[unused863]', 868),\n",
              "             ('[unused864]', 869),\n",
              "             ('[unused865]', 870),\n",
              "             ('[unused866]', 871),\n",
              "             ('[unused867]', 872),\n",
              "             ('[unused868]', 873),\n",
              "             ('[unused869]', 874),\n",
              "             ('[unused870]', 875),\n",
              "             ('[unused871]', 876),\n",
              "             ('[unused872]', 877),\n",
              "             ('[unused873]', 878),\n",
              "             ('[unused874]', 879),\n",
              "             ('[unused875]', 880),\n",
              "             ('[unused876]', 881),\n",
              "             ('[unused877]', 882),\n",
              "             ('[unused878]', 883),\n",
              "             ('[unused879]', 884),\n",
              "             ('[unused880]', 885),\n",
              "             ('[unused881]', 886),\n",
              "             ('[unused882]', 887),\n",
              "             ('[unused883]', 888),\n",
              "             ('[unused884]', 889),\n",
              "             ('[unused885]', 890),\n",
              "             ('[unused886]', 891),\n",
              "             ('[unused887]', 892),\n",
              "             ('[unused888]', 893),\n",
              "             ('[unused889]', 894),\n",
              "             ('[unused890]', 895),\n",
              "             ('[unused891]', 896),\n",
              "             ('[unused892]', 897),\n",
              "             ('[unused893]', 898),\n",
              "             ('[unused894]', 899),\n",
              "             ('[unused895]', 900),\n",
              "             ('[unused896]', 901),\n",
              "             ('[unused897]', 902),\n",
              "             ('[unused898]', 903),\n",
              "             ('[unused899]', 904),\n",
              "             ('[unused900]', 905),\n",
              "             ('[unused901]', 906),\n",
              "             ('[unused902]', 907),\n",
              "             ('[unused903]', 908),\n",
              "             ('[unused904]', 909),\n",
              "             ('[unused905]', 910),\n",
              "             ('[unused906]', 911),\n",
              "             ('[unused907]', 912),\n",
              "             ('[unused908]', 913),\n",
              "             ('[unused909]', 914),\n",
              "             ('[unused910]', 915),\n",
              "             ('[unused911]', 916),\n",
              "             ('[unused912]', 917),\n",
              "             ('[unused913]', 918),\n",
              "             ('[unused914]', 919),\n",
              "             ('[unused915]', 920),\n",
              "             ('[unused916]', 921),\n",
              "             ('[unused917]', 922),\n",
              "             ('[unused918]', 923),\n",
              "             ('[unused919]', 924),\n",
              "             ('[unused920]', 925),\n",
              "             ('[unused921]', 926),\n",
              "             ('[unused922]', 927),\n",
              "             ('[unused923]', 928),\n",
              "             ('[unused924]', 929),\n",
              "             ('[unused925]', 930),\n",
              "             ('[unused926]', 931),\n",
              "             ('[unused927]', 932),\n",
              "             ('[unused928]', 933),\n",
              "             ('[unused929]', 934),\n",
              "             ('[unused930]', 935),\n",
              "             ('[unused931]', 936),\n",
              "             ('[unused932]', 937),\n",
              "             ('[unused933]', 938),\n",
              "             ('[unused934]', 939),\n",
              "             ('[unused935]', 940),\n",
              "             ('[unused936]', 941),\n",
              "             ('[unused937]', 942),\n",
              "             ('[unused938]', 943),\n",
              "             ('[unused939]', 944),\n",
              "             ('[unused940]', 945),\n",
              "             ('[unused941]', 946),\n",
              "             ('[unused942]', 947),\n",
              "             ('[unused943]', 948),\n",
              "             ('[unused944]', 949),\n",
              "             ('[unused945]', 950),\n",
              "             ('[unused946]', 951),\n",
              "             ('[unused947]', 952),\n",
              "             ('[unused948]', 953),\n",
              "             ('[unused949]', 954),\n",
              "             ('[unused950]', 955),\n",
              "             ('[unused951]', 956),\n",
              "             ('[unused952]', 957),\n",
              "             ('[unused953]', 958),\n",
              "             ('[unused954]', 959),\n",
              "             ('[unused955]', 960),\n",
              "             ('[unused956]', 961),\n",
              "             ('[unused957]', 962),\n",
              "             ('[unused958]', 963),\n",
              "             ('[unused959]', 964),\n",
              "             ('[unused960]', 965),\n",
              "             ('[unused961]', 966),\n",
              "             ('[unused962]', 967),\n",
              "             ('[unused963]', 968),\n",
              "             ('[unused964]', 969),\n",
              "             ('[unused965]', 970),\n",
              "             ('[unused966]', 971),\n",
              "             ('[unused967]', 972),\n",
              "             ('[unused968]', 973),\n",
              "             ('[unused969]', 974),\n",
              "             ('[unused970]', 975),\n",
              "             ('[unused971]', 976),\n",
              "             ('[unused972]', 977),\n",
              "             ('[unused973]', 978),\n",
              "             ('[unused974]', 979),\n",
              "             ('[unused975]', 980),\n",
              "             ('[unused976]', 981),\n",
              "             ('[unused977]', 982),\n",
              "             ('[unused978]', 983),\n",
              "             ('[unused979]', 984),\n",
              "             ('[unused980]', 985),\n",
              "             ('[unused981]', 986),\n",
              "             ('[unused982]', 987),\n",
              "             ('[unused983]', 988),\n",
              "             ('[unused984]', 989),\n",
              "             ('[unused985]', 990),\n",
              "             ('[unused986]', 991),\n",
              "             ('[unused987]', 992),\n",
              "             ('[unused988]', 993),\n",
              "             ('[unused989]', 994),\n",
              "             ('[unused990]', 995),\n",
              "             ('[unused991]', 996),\n",
              "             ('[unused992]', 997),\n",
              "             ('[unused993]', 998),\n",
              "             ('!', 999),\n",
              "             ...])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OnM88SerMkfe",
        "outputId": "d313e213-cd0e-4807-bb05-163923e02272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(0, '[PAD]'),\n",
              "             (1, '[unused0]'),\n",
              "             (2, '[unused1]'),\n",
              "             (3, '[unused2]'),\n",
              "             (4, '[unused3]'),\n",
              "             (5, '[unused4]'),\n",
              "             (6, '[unused5]'),\n",
              "             (7, '[unused6]'),\n",
              "             (8, '[unused7]'),\n",
              "             (9, '[unused8]'),\n",
              "             (10, '[unused9]'),\n",
              "             (11, '[unused10]'),\n",
              "             (12, '[unused11]'),\n",
              "             (13, '[unused12]'),\n",
              "             (14, '[unused13]'),\n",
              "             (15, '[unused14]'),\n",
              "             (16, '[unused15]'),\n",
              "             (17, '[unused16]'),\n",
              "             (18, '[unused17]'),\n",
              "             (19, '[unused18]'),\n",
              "             (20, '[unused19]'),\n",
              "             (21, '[unused20]'),\n",
              "             (22, '[unused21]'),\n",
              "             (23, '[unused22]'),\n",
              "             (24, '[unused23]'),\n",
              "             (25, '[unused24]'),\n",
              "             (26, '[unused25]'),\n",
              "             (27, '[unused26]'),\n",
              "             (28, '[unused27]'),\n",
              "             (29, '[unused28]'),\n",
              "             (30, '[unused29]'),\n",
              "             (31, '[unused30]'),\n",
              "             (32, '[unused31]'),\n",
              "             (33, '[unused32]'),\n",
              "             (34, '[unused33]'),\n",
              "             (35, '[unused34]'),\n",
              "             (36, '[unused35]'),\n",
              "             (37, '[unused36]'),\n",
              "             (38, '[unused37]'),\n",
              "             (39, '[unused38]'),\n",
              "             (40, '[unused39]'),\n",
              "             (41, '[unused40]'),\n",
              "             (42, '[unused41]'),\n",
              "             (43, '[unused42]'),\n",
              "             (44, '[unused43]'),\n",
              "             (45, '[unused44]'),\n",
              "             (46, '[unused45]'),\n",
              "             (47, '[unused46]'),\n",
              "             (48, '[unused47]'),\n",
              "             (49, '[unused48]'),\n",
              "             (50, '[unused49]'),\n",
              "             (51, '[unused50]'),\n",
              "             (52, '[unused51]'),\n",
              "             (53, '[unused52]'),\n",
              "             (54, '[unused53]'),\n",
              "             (55, '[unused54]'),\n",
              "             (56, '[unused55]'),\n",
              "             (57, '[unused56]'),\n",
              "             (58, '[unused57]'),\n",
              "             (59, '[unused58]'),\n",
              "             (60, '[unused59]'),\n",
              "             (61, '[unused60]'),\n",
              "             (62, '[unused61]'),\n",
              "             (63, '[unused62]'),\n",
              "             (64, '[unused63]'),\n",
              "             (65, '[unused64]'),\n",
              "             (66, '[unused65]'),\n",
              "             (67, '[unused66]'),\n",
              "             (68, '[unused67]'),\n",
              "             (69, '[unused68]'),\n",
              "             (70, '[unused69]'),\n",
              "             (71, '[unused70]'),\n",
              "             (72, '[unused71]'),\n",
              "             (73, '[unused72]'),\n",
              "             (74, '[unused73]'),\n",
              "             (75, '[unused74]'),\n",
              "             (76, '[unused75]'),\n",
              "             (77, '[unused76]'),\n",
              "             (78, '[unused77]'),\n",
              "             (79, '[unused78]'),\n",
              "             (80, '[unused79]'),\n",
              "             (81, '[unused80]'),\n",
              "             (82, '[unused81]'),\n",
              "             (83, '[unused82]'),\n",
              "             (84, '[unused83]'),\n",
              "             (85, '[unused84]'),\n",
              "             (86, '[unused85]'),\n",
              "             (87, '[unused86]'),\n",
              "             (88, '[unused87]'),\n",
              "             (89, '[unused88]'),\n",
              "             (90, '[unused89]'),\n",
              "             (91, '[unused90]'),\n",
              "             (92, '[unused91]'),\n",
              "             (93, '[unused92]'),\n",
              "             (94, '[unused93]'),\n",
              "             (95, '[unused94]'),\n",
              "             (96, '[unused95]'),\n",
              "             (97, '[unused96]'),\n",
              "             (98, '[unused97]'),\n",
              "             (99, '[unused98]'),\n",
              "             (100, '[UNK]'),\n",
              "             (101, '[CLS]'),\n",
              "             (102, '[SEP]'),\n",
              "             (103, '[MASK]'),\n",
              "             (104, '[unused99]'),\n",
              "             (105, '[unused100]'),\n",
              "             (106, '[unused101]'),\n",
              "             (107, '[unused102]'),\n",
              "             (108, '[unused103]'),\n",
              "             (109, '[unused104]'),\n",
              "             (110, '[unused105]'),\n",
              "             (111, '[unused106]'),\n",
              "             (112, '[unused107]'),\n",
              "             (113, '[unused108]'),\n",
              "             (114, '[unused109]'),\n",
              "             (115, '[unused110]'),\n",
              "             (116, '[unused111]'),\n",
              "             (117, '[unused112]'),\n",
              "             (118, '[unused113]'),\n",
              "             (119, '[unused114]'),\n",
              "             (120, '[unused115]'),\n",
              "             (121, '[unused116]'),\n",
              "             (122, '[unused117]'),\n",
              "             (123, '[unused118]'),\n",
              "             (124, '[unused119]'),\n",
              "             (125, '[unused120]'),\n",
              "             (126, '[unused121]'),\n",
              "             (127, '[unused122]'),\n",
              "             (128, '[unused123]'),\n",
              "             (129, '[unused124]'),\n",
              "             (130, '[unused125]'),\n",
              "             (131, '[unused126]'),\n",
              "             (132, '[unused127]'),\n",
              "             (133, '[unused128]'),\n",
              "             (134, '[unused129]'),\n",
              "             (135, '[unused130]'),\n",
              "             (136, '[unused131]'),\n",
              "             (137, '[unused132]'),\n",
              "             (138, '[unused133]'),\n",
              "             (139, '[unused134]'),\n",
              "             (140, '[unused135]'),\n",
              "             (141, '[unused136]'),\n",
              "             (142, '[unused137]'),\n",
              "             (143, '[unused138]'),\n",
              "             (144, '[unused139]'),\n",
              "             (145, '[unused140]'),\n",
              "             (146, '[unused141]'),\n",
              "             (147, '[unused142]'),\n",
              "             (148, '[unused143]'),\n",
              "             (149, '[unused144]'),\n",
              "             (150, '[unused145]'),\n",
              "             (151, '[unused146]'),\n",
              "             (152, '[unused147]'),\n",
              "             (153, '[unused148]'),\n",
              "             (154, '[unused149]'),\n",
              "             (155, '[unused150]'),\n",
              "             (156, '[unused151]'),\n",
              "             (157, '[unused152]'),\n",
              "             (158, '[unused153]'),\n",
              "             (159, '[unused154]'),\n",
              "             (160, '[unused155]'),\n",
              "             (161, '[unused156]'),\n",
              "             (162, '[unused157]'),\n",
              "             (163, '[unused158]'),\n",
              "             (164, '[unused159]'),\n",
              "             (165, '[unused160]'),\n",
              "             (166, '[unused161]'),\n",
              "             (167, '[unused162]'),\n",
              "             (168, '[unused163]'),\n",
              "             (169, '[unused164]'),\n",
              "             (170, '[unused165]'),\n",
              "             (171, '[unused166]'),\n",
              "             (172, '[unused167]'),\n",
              "             (173, '[unused168]'),\n",
              "             (174, '[unused169]'),\n",
              "             (175, '[unused170]'),\n",
              "             (176, '[unused171]'),\n",
              "             (177, '[unused172]'),\n",
              "             (178, '[unused173]'),\n",
              "             (179, '[unused174]'),\n",
              "             (180, '[unused175]'),\n",
              "             (181, '[unused176]'),\n",
              "             (182, '[unused177]'),\n",
              "             (183, '[unused178]'),\n",
              "             (184, '[unused179]'),\n",
              "             (185, '[unused180]'),\n",
              "             (186, '[unused181]'),\n",
              "             (187, '[unused182]'),\n",
              "             (188, '[unused183]'),\n",
              "             (189, '[unused184]'),\n",
              "             (190, '[unused185]'),\n",
              "             (191, '[unused186]'),\n",
              "             (192, '[unused187]'),\n",
              "             (193, '[unused188]'),\n",
              "             (194, '[unused189]'),\n",
              "             (195, '[unused190]'),\n",
              "             (196, '[unused191]'),\n",
              "             (197, '[unused192]'),\n",
              "             (198, '[unused193]'),\n",
              "             (199, '[unused194]'),\n",
              "             (200, '[unused195]'),\n",
              "             (201, '[unused196]'),\n",
              "             (202, '[unused197]'),\n",
              "             (203, '[unused198]'),\n",
              "             (204, '[unused199]'),\n",
              "             (205, '[unused200]'),\n",
              "             (206, '[unused201]'),\n",
              "             (207, '[unused202]'),\n",
              "             (208, '[unused203]'),\n",
              "             (209, '[unused204]'),\n",
              "             (210, '[unused205]'),\n",
              "             (211, '[unused206]'),\n",
              "             (212, '[unused207]'),\n",
              "             (213, '[unused208]'),\n",
              "             (214, '[unused209]'),\n",
              "             (215, '[unused210]'),\n",
              "             (216, '[unused211]'),\n",
              "             (217, '[unused212]'),\n",
              "             (218, '[unused213]'),\n",
              "             (219, '[unused214]'),\n",
              "             (220, '[unused215]'),\n",
              "             (221, '[unused216]'),\n",
              "             (222, '[unused217]'),\n",
              "             (223, '[unused218]'),\n",
              "             (224, '[unused219]'),\n",
              "             (225, '[unused220]'),\n",
              "             (226, '[unused221]'),\n",
              "             (227, '[unused222]'),\n",
              "             (228, '[unused223]'),\n",
              "             (229, '[unused224]'),\n",
              "             (230, '[unused225]'),\n",
              "             (231, '[unused226]'),\n",
              "             (232, '[unused227]'),\n",
              "             (233, '[unused228]'),\n",
              "             (234, '[unused229]'),\n",
              "             (235, '[unused230]'),\n",
              "             (236, '[unused231]'),\n",
              "             (237, '[unused232]'),\n",
              "             (238, '[unused233]'),\n",
              "             (239, '[unused234]'),\n",
              "             (240, '[unused235]'),\n",
              "             (241, '[unused236]'),\n",
              "             (242, '[unused237]'),\n",
              "             (243, '[unused238]'),\n",
              "             (244, '[unused239]'),\n",
              "             (245, '[unused240]'),\n",
              "             (246, '[unused241]'),\n",
              "             (247, '[unused242]'),\n",
              "             (248, '[unused243]'),\n",
              "             (249, '[unused244]'),\n",
              "             (250, '[unused245]'),\n",
              "             (251, '[unused246]'),\n",
              "             (252, '[unused247]'),\n",
              "             (253, '[unused248]'),\n",
              "             (254, '[unused249]'),\n",
              "             (255, '[unused250]'),\n",
              "             (256, '[unused251]'),\n",
              "             (257, '[unused252]'),\n",
              "             (258, '[unused253]'),\n",
              "             (259, '[unused254]'),\n",
              "             (260, '[unused255]'),\n",
              "             (261, '[unused256]'),\n",
              "             (262, '[unused257]'),\n",
              "             (263, '[unused258]'),\n",
              "             (264, '[unused259]'),\n",
              "             (265, '[unused260]'),\n",
              "             (266, '[unused261]'),\n",
              "             (267, '[unused262]'),\n",
              "             (268, '[unused263]'),\n",
              "             (269, '[unused264]'),\n",
              "             (270, '[unused265]'),\n",
              "             (271, '[unused266]'),\n",
              "             (272, '[unused267]'),\n",
              "             (273, '[unused268]'),\n",
              "             (274, '[unused269]'),\n",
              "             (275, '[unused270]'),\n",
              "             (276, '[unused271]'),\n",
              "             (277, '[unused272]'),\n",
              "             (278, '[unused273]'),\n",
              "             (279, '[unused274]'),\n",
              "             (280, '[unused275]'),\n",
              "             (281, '[unused276]'),\n",
              "             (282, '[unused277]'),\n",
              "             (283, '[unused278]'),\n",
              "             (284, '[unused279]'),\n",
              "             (285, '[unused280]'),\n",
              "             (286, '[unused281]'),\n",
              "             (287, '[unused282]'),\n",
              "             (288, '[unused283]'),\n",
              "             (289, '[unused284]'),\n",
              "             (290, '[unused285]'),\n",
              "             (291, '[unused286]'),\n",
              "             (292, '[unused287]'),\n",
              "             (293, '[unused288]'),\n",
              "             (294, '[unused289]'),\n",
              "             (295, '[unused290]'),\n",
              "             (296, '[unused291]'),\n",
              "             (297, '[unused292]'),\n",
              "             (298, '[unused293]'),\n",
              "             (299, '[unused294]'),\n",
              "             (300, '[unused295]'),\n",
              "             (301, '[unused296]'),\n",
              "             (302, '[unused297]'),\n",
              "             (303, '[unused298]'),\n",
              "             (304, '[unused299]'),\n",
              "             (305, '[unused300]'),\n",
              "             (306, '[unused301]'),\n",
              "             (307, '[unused302]'),\n",
              "             (308, '[unused303]'),\n",
              "             (309, '[unused304]'),\n",
              "             (310, '[unused305]'),\n",
              "             (311, '[unused306]'),\n",
              "             (312, '[unused307]'),\n",
              "             (313, '[unused308]'),\n",
              "             (314, '[unused309]'),\n",
              "             (315, '[unused310]'),\n",
              "             (316, '[unused311]'),\n",
              "             (317, '[unused312]'),\n",
              "             (318, '[unused313]'),\n",
              "             (319, '[unused314]'),\n",
              "             (320, '[unused315]'),\n",
              "             (321, '[unused316]'),\n",
              "             (322, '[unused317]'),\n",
              "             (323, '[unused318]'),\n",
              "             (324, '[unused319]'),\n",
              "             (325, '[unused320]'),\n",
              "             (326, '[unused321]'),\n",
              "             (327, '[unused322]'),\n",
              "             (328, '[unused323]'),\n",
              "             (329, '[unused324]'),\n",
              "             (330, '[unused325]'),\n",
              "             (331, '[unused326]'),\n",
              "             (332, '[unused327]'),\n",
              "             (333, '[unused328]'),\n",
              "             (334, '[unused329]'),\n",
              "             (335, '[unused330]'),\n",
              "             (336, '[unused331]'),\n",
              "             (337, '[unused332]'),\n",
              "             (338, '[unused333]'),\n",
              "             (339, '[unused334]'),\n",
              "             (340, '[unused335]'),\n",
              "             (341, '[unused336]'),\n",
              "             (342, '[unused337]'),\n",
              "             (343, '[unused338]'),\n",
              "             (344, '[unused339]'),\n",
              "             (345, '[unused340]'),\n",
              "             (346, '[unused341]'),\n",
              "             (347, '[unused342]'),\n",
              "             (348, '[unused343]'),\n",
              "             (349, '[unused344]'),\n",
              "             (350, '[unused345]'),\n",
              "             (351, '[unused346]'),\n",
              "             (352, '[unused347]'),\n",
              "             (353, '[unused348]'),\n",
              "             (354, '[unused349]'),\n",
              "             (355, '[unused350]'),\n",
              "             (356, '[unused351]'),\n",
              "             (357, '[unused352]'),\n",
              "             (358, '[unused353]'),\n",
              "             (359, '[unused354]'),\n",
              "             (360, '[unused355]'),\n",
              "             (361, '[unused356]'),\n",
              "             (362, '[unused357]'),\n",
              "             (363, '[unused358]'),\n",
              "             (364, '[unused359]'),\n",
              "             (365, '[unused360]'),\n",
              "             (366, '[unused361]'),\n",
              "             (367, '[unused362]'),\n",
              "             (368, '[unused363]'),\n",
              "             (369, '[unused364]'),\n",
              "             (370, '[unused365]'),\n",
              "             (371, '[unused366]'),\n",
              "             (372, '[unused367]'),\n",
              "             (373, '[unused368]'),\n",
              "             (374, '[unused369]'),\n",
              "             (375, '[unused370]'),\n",
              "             (376, '[unused371]'),\n",
              "             (377, '[unused372]'),\n",
              "             (378, '[unused373]'),\n",
              "             (379, '[unused374]'),\n",
              "             (380, '[unused375]'),\n",
              "             (381, '[unused376]'),\n",
              "             (382, '[unused377]'),\n",
              "             (383, '[unused378]'),\n",
              "             (384, '[unused379]'),\n",
              "             (385, '[unused380]'),\n",
              "             (386, '[unused381]'),\n",
              "             (387, '[unused382]'),\n",
              "             (388, '[unused383]'),\n",
              "             (389, '[unused384]'),\n",
              "             (390, '[unused385]'),\n",
              "             (391, '[unused386]'),\n",
              "             (392, '[unused387]'),\n",
              "             (393, '[unused388]'),\n",
              "             (394, '[unused389]'),\n",
              "             (395, '[unused390]'),\n",
              "             (396, '[unused391]'),\n",
              "             (397, '[unused392]'),\n",
              "             (398, '[unused393]'),\n",
              "             (399, '[unused394]'),\n",
              "             (400, '[unused395]'),\n",
              "             (401, '[unused396]'),\n",
              "             (402, '[unused397]'),\n",
              "             (403, '[unused398]'),\n",
              "             (404, '[unused399]'),\n",
              "             (405, '[unused400]'),\n",
              "             (406, '[unused401]'),\n",
              "             (407, '[unused402]'),\n",
              "             (408, '[unused403]'),\n",
              "             (409, '[unused404]'),\n",
              "             (410, '[unused405]'),\n",
              "             (411, '[unused406]'),\n",
              "             (412, '[unused407]'),\n",
              "             (413, '[unused408]'),\n",
              "             (414, '[unused409]'),\n",
              "             (415, '[unused410]'),\n",
              "             (416, '[unused411]'),\n",
              "             (417, '[unused412]'),\n",
              "             (418, '[unused413]'),\n",
              "             (419, '[unused414]'),\n",
              "             (420, '[unused415]'),\n",
              "             (421, '[unused416]'),\n",
              "             (422, '[unused417]'),\n",
              "             (423, '[unused418]'),\n",
              "             (424, '[unused419]'),\n",
              "             (425, '[unused420]'),\n",
              "             (426, '[unused421]'),\n",
              "             (427, '[unused422]'),\n",
              "             (428, '[unused423]'),\n",
              "             (429, '[unused424]'),\n",
              "             (430, '[unused425]'),\n",
              "             (431, '[unused426]'),\n",
              "             (432, '[unused427]'),\n",
              "             (433, '[unused428]'),\n",
              "             (434, '[unused429]'),\n",
              "             (435, '[unused430]'),\n",
              "             (436, '[unused431]'),\n",
              "             (437, '[unused432]'),\n",
              "             (438, '[unused433]'),\n",
              "             (439, '[unused434]'),\n",
              "             (440, '[unused435]'),\n",
              "             (441, '[unused436]'),\n",
              "             (442, '[unused437]'),\n",
              "             (443, '[unused438]'),\n",
              "             (444, '[unused439]'),\n",
              "             (445, '[unused440]'),\n",
              "             (446, '[unused441]'),\n",
              "             (447, '[unused442]'),\n",
              "             (448, '[unused443]'),\n",
              "             (449, '[unused444]'),\n",
              "             (450, '[unused445]'),\n",
              "             (451, '[unused446]'),\n",
              "             (452, '[unused447]'),\n",
              "             (453, '[unused448]'),\n",
              "             (454, '[unused449]'),\n",
              "             (455, '[unused450]'),\n",
              "             (456, '[unused451]'),\n",
              "             (457, '[unused452]'),\n",
              "             (458, '[unused453]'),\n",
              "             (459, '[unused454]'),\n",
              "             (460, '[unused455]'),\n",
              "             (461, '[unused456]'),\n",
              "             (462, '[unused457]'),\n",
              "             (463, '[unused458]'),\n",
              "             (464, '[unused459]'),\n",
              "             (465, '[unused460]'),\n",
              "             (466, '[unused461]'),\n",
              "             (467, '[unused462]'),\n",
              "             (468, '[unused463]'),\n",
              "             (469, '[unused464]'),\n",
              "             (470, '[unused465]'),\n",
              "             (471, '[unused466]'),\n",
              "             (472, '[unused467]'),\n",
              "             (473, '[unused468]'),\n",
              "             (474, '[unused469]'),\n",
              "             (475, '[unused470]'),\n",
              "             (476, '[unused471]'),\n",
              "             (477, '[unused472]'),\n",
              "             (478, '[unused473]'),\n",
              "             (479, '[unused474]'),\n",
              "             (480, '[unused475]'),\n",
              "             (481, '[unused476]'),\n",
              "             (482, '[unused477]'),\n",
              "             (483, '[unused478]'),\n",
              "             (484, '[unused479]'),\n",
              "             (485, '[unused480]'),\n",
              "             (486, '[unused481]'),\n",
              "             (487, '[unused482]'),\n",
              "             (488, '[unused483]'),\n",
              "             (489, '[unused484]'),\n",
              "             (490, '[unused485]'),\n",
              "             (491, '[unused486]'),\n",
              "             (492, '[unused487]'),\n",
              "             (493, '[unused488]'),\n",
              "             (494, '[unused489]'),\n",
              "             (495, '[unused490]'),\n",
              "             (496, '[unused491]'),\n",
              "             (497, '[unused492]'),\n",
              "             (498, '[unused493]'),\n",
              "             (499, '[unused494]'),\n",
              "             (500, '[unused495]'),\n",
              "             (501, '[unused496]'),\n",
              "             (502, '[unused497]'),\n",
              "             (503, '[unused498]'),\n",
              "             (504, '[unused499]'),\n",
              "             (505, '[unused500]'),\n",
              "             (506, '[unused501]'),\n",
              "             (507, '[unused502]'),\n",
              "             (508, '[unused503]'),\n",
              "             (509, '[unused504]'),\n",
              "             (510, '[unused505]'),\n",
              "             (511, '[unused506]'),\n",
              "             (512, '[unused507]'),\n",
              "             (513, '[unused508]'),\n",
              "             (514, '[unused509]'),\n",
              "             (515, '[unused510]'),\n",
              "             (516, '[unused511]'),\n",
              "             (517, '[unused512]'),\n",
              "             (518, '[unused513]'),\n",
              "             (519, '[unused514]'),\n",
              "             (520, '[unused515]'),\n",
              "             (521, '[unused516]'),\n",
              "             (522, '[unused517]'),\n",
              "             (523, '[unused518]'),\n",
              "             (524, '[unused519]'),\n",
              "             (525, '[unused520]'),\n",
              "             (526, '[unused521]'),\n",
              "             (527, '[unused522]'),\n",
              "             (528, '[unused523]'),\n",
              "             (529, '[unused524]'),\n",
              "             (530, '[unused525]'),\n",
              "             (531, '[unused526]'),\n",
              "             (532, '[unused527]'),\n",
              "             (533, '[unused528]'),\n",
              "             (534, '[unused529]'),\n",
              "             (535, '[unused530]'),\n",
              "             (536, '[unused531]'),\n",
              "             (537, '[unused532]'),\n",
              "             (538, '[unused533]'),\n",
              "             (539, '[unused534]'),\n",
              "             (540, '[unused535]'),\n",
              "             (541, '[unused536]'),\n",
              "             (542, '[unused537]'),\n",
              "             (543, '[unused538]'),\n",
              "             (544, '[unused539]'),\n",
              "             (545, '[unused540]'),\n",
              "             (546, '[unused541]'),\n",
              "             (547, '[unused542]'),\n",
              "             (548, '[unused543]'),\n",
              "             (549, '[unused544]'),\n",
              "             (550, '[unused545]'),\n",
              "             (551, '[unused546]'),\n",
              "             (552, '[unused547]'),\n",
              "             (553, '[unused548]'),\n",
              "             (554, '[unused549]'),\n",
              "             (555, '[unused550]'),\n",
              "             (556, '[unused551]'),\n",
              "             (557, '[unused552]'),\n",
              "             (558, '[unused553]'),\n",
              "             (559, '[unused554]'),\n",
              "             (560, '[unused555]'),\n",
              "             (561, '[unused556]'),\n",
              "             (562, '[unused557]'),\n",
              "             (563, '[unused558]'),\n",
              "             (564, '[unused559]'),\n",
              "             (565, '[unused560]'),\n",
              "             (566, '[unused561]'),\n",
              "             (567, '[unused562]'),\n",
              "             (568, '[unused563]'),\n",
              "             (569, '[unused564]'),\n",
              "             (570, '[unused565]'),\n",
              "             (571, '[unused566]'),\n",
              "             (572, '[unused567]'),\n",
              "             (573, '[unused568]'),\n",
              "             (574, '[unused569]'),\n",
              "             (575, '[unused570]'),\n",
              "             (576, '[unused571]'),\n",
              "             (577, '[unused572]'),\n",
              "             (578, '[unused573]'),\n",
              "             (579, '[unused574]'),\n",
              "             (580, '[unused575]'),\n",
              "             (581, '[unused576]'),\n",
              "             (582, '[unused577]'),\n",
              "             (583, '[unused578]'),\n",
              "             (584, '[unused579]'),\n",
              "             (585, '[unused580]'),\n",
              "             (586, '[unused581]'),\n",
              "             (587, '[unused582]'),\n",
              "             (588, '[unused583]'),\n",
              "             (589, '[unused584]'),\n",
              "             (590, '[unused585]'),\n",
              "             (591, '[unused586]'),\n",
              "             (592, '[unused587]'),\n",
              "             (593, '[unused588]'),\n",
              "             (594, '[unused589]'),\n",
              "             (595, '[unused590]'),\n",
              "             (596, '[unused591]'),\n",
              "             (597, '[unused592]'),\n",
              "             (598, '[unused593]'),\n",
              "             (599, '[unused594]'),\n",
              "             (600, '[unused595]'),\n",
              "             (601, '[unused596]'),\n",
              "             (602, '[unused597]'),\n",
              "             (603, '[unused598]'),\n",
              "             (604, '[unused599]'),\n",
              "             (605, '[unused600]'),\n",
              "             (606, '[unused601]'),\n",
              "             (607, '[unused602]'),\n",
              "             (608, '[unused603]'),\n",
              "             (609, '[unused604]'),\n",
              "             (610, '[unused605]'),\n",
              "             (611, '[unused606]'),\n",
              "             (612, '[unused607]'),\n",
              "             (613, '[unused608]'),\n",
              "             (614, '[unused609]'),\n",
              "             (615, '[unused610]'),\n",
              "             (616, '[unused611]'),\n",
              "             (617, '[unused612]'),\n",
              "             (618, '[unused613]'),\n",
              "             (619, '[unused614]'),\n",
              "             (620, '[unused615]'),\n",
              "             (621, '[unused616]'),\n",
              "             (622, '[unused617]'),\n",
              "             (623, '[unused618]'),\n",
              "             (624, '[unused619]'),\n",
              "             (625, '[unused620]'),\n",
              "             (626, '[unused621]'),\n",
              "             (627, '[unused622]'),\n",
              "             (628, '[unused623]'),\n",
              "             (629, '[unused624]'),\n",
              "             (630, '[unused625]'),\n",
              "             (631, '[unused626]'),\n",
              "             (632, '[unused627]'),\n",
              "             (633, '[unused628]'),\n",
              "             (634, '[unused629]'),\n",
              "             (635, '[unused630]'),\n",
              "             (636, '[unused631]'),\n",
              "             (637, '[unused632]'),\n",
              "             (638, '[unused633]'),\n",
              "             (639, '[unused634]'),\n",
              "             (640, '[unused635]'),\n",
              "             (641, '[unused636]'),\n",
              "             (642, '[unused637]'),\n",
              "             (643, '[unused638]'),\n",
              "             (644, '[unused639]'),\n",
              "             (645, '[unused640]'),\n",
              "             (646, '[unused641]'),\n",
              "             (647, '[unused642]'),\n",
              "             (648, '[unused643]'),\n",
              "             (649, '[unused644]'),\n",
              "             (650, '[unused645]'),\n",
              "             (651, '[unused646]'),\n",
              "             (652, '[unused647]'),\n",
              "             (653, '[unused648]'),\n",
              "             (654, '[unused649]'),\n",
              "             (655, '[unused650]'),\n",
              "             (656, '[unused651]'),\n",
              "             (657, '[unused652]'),\n",
              "             (658, '[unused653]'),\n",
              "             (659, '[unused654]'),\n",
              "             (660, '[unused655]'),\n",
              "             (661, '[unused656]'),\n",
              "             (662, '[unused657]'),\n",
              "             (663, '[unused658]'),\n",
              "             (664, '[unused659]'),\n",
              "             (665, '[unused660]'),\n",
              "             (666, '[unused661]'),\n",
              "             (667, '[unused662]'),\n",
              "             (668, '[unused663]'),\n",
              "             (669, '[unused664]'),\n",
              "             (670, '[unused665]'),\n",
              "             (671, '[unused666]'),\n",
              "             (672, '[unused667]'),\n",
              "             (673, '[unused668]'),\n",
              "             (674, '[unused669]'),\n",
              "             (675, '[unused670]'),\n",
              "             (676, '[unused671]'),\n",
              "             (677, '[unused672]'),\n",
              "             (678, '[unused673]'),\n",
              "             (679, '[unused674]'),\n",
              "             (680, '[unused675]'),\n",
              "             (681, '[unused676]'),\n",
              "             (682, '[unused677]'),\n",
              "             (683, '[unused678]'),\n",
              "             (684, '[unused679]'),\n",
              "             (685, '[unused680]'),\n",
              "             (686, '[unused681]'),\n",
              "             (687, '[unused682]'),\n",
              "             (688, '[unused683]'),\n",
              "             (689, '[unused684]'),\n",
              "             (690, '[unused685]'),\n",
              "             (691, '[unused686]'),\n",
              "             (692, '[unused687]'),\n",
              "             (693, '[unused688]'),\n",
              "             (694, '[unused689]'),\n",
              "             (695, '[unused690]'),\n",
              "             (696, '[unused691]'),\n",
              "             (697, '[unused692]'),\n",
              "             (698, '[unused693]'),\n",
              "             (699, '[unused694]'),\n",
              "             (700, '[unused695]'),\n",
              "             (701, '[unused696]'),\n",
              "             (702, '[unused697]'),\n",
              "             (703, '[unused698]'),\n",
              "             (704, '[unused699]'),\n",
              "             (705, '[unused700]'),\n",
              "             (706, '[unused701]'),\n",
              "             (707, '[unused702]'),\n",
              "             (708, '[unused703]'),\n",
              "             (709, '[unused704]'),\n",
              "             (710, '[unused705]'),\n",
              "             (711, '[unused706]'),\n",
              "             (712, '[unused707]'),\n",
              "             (713, '[unused708]'),\n",
              "             (714, '[unused709]'),\n",
              "             (715, '[unused710]'),\n",
              "             (716, '[unused711]'),\n",
              "             (717, '[unused712]'),\n",
              "             (718, '[unused713]'),\n",
              "             (719, '[unused714]'),\n",
              "             (720, '[unused715]'),\n",
              "             (721, '[unused716]'),\n",
              "             (722, '[unused717]'),\n",
              "             (723, '[unused718]'),\n",
              "             (724, '[unused719]'),\n",
              "             (725, '[unused720]'),\n",
              "             (726, '[unused721]'),\n",
              "             (727, '[unused722]'),\n",
              "             (728, '[unused723]'),\n",
              "             (729, '[unused724]'),\n",
              "             (730, '[unused725]'),\n",
              "             (731, '[unused726]'),\n",
              "             (732, '[unused727]'),\n",
              "             (733, '[unused728]'),\n",
              "             (734, '[unused729]'),\n",
              "             (735, '[unused730]'),\n",
              "             (736, '[unused731]'),\n",
              "             (737, '[unused732]'),\n",
              "             (738, '[unused733]'),\n",
              "             (739, '[unused734]'),\n",
              "             (740, '[unused735]'),\n",
              "             (741, '[unused736]'),\n",
              "             (742, '[unused737]'),\n",
              "             (743, '[unused738]'),\n",
              "             (744, '[unused739]'),\n",
              "             (745, '[unused740]'),\n",
              "             (746, '[unused741]'),\n",
              "             (747, '[unused742]'),\n",
              "             (748, '[unused743]'),\n",
              "             (749, '[unused744]'),\n",
              "             (750, '[unused745]'),\n",
              "             (751, '[unused746]'),\n",
              "             (752, '[unused747]'),\n",
              "             (753, '[unused748]'),\n",
              "             (754, '[unused749]'),\n",
              "             (755, '[unused750]'),\n",
              "             (756, '[unused751]'),\n",
              "             (757, '[unused752]'),\n",
              "             (758, '[unused753]'),\n",
              "             (759, '[unused754]'),\n",
              "             (760, '[unused755]'),\n",
              "             (761, '[unused756]'),\n",
              "             (762, '[unused757]'),\n",
              "             (763, '[unused758]'),\n",
              "             (764, '[unused759]'),\n",
              "             (765, '[unused760]'),\n",
              "             (766, '[unused761]'),\n",
              "             (767, '[unused762]'),\n",
              "             (768, '[unused763]'),\n",
              "             (769, '[unused764]'),\n",
              "             (770, '[unused765]'),\n",
              "             (771, '[unused766]'),\n",
              "             (772, '[unused767]'),\n",
              "             (773, '[unused768]'),\n",
              "             (774, '[unused769]'),\n",
              "             (775, '[unused770]'),\n",
              "             (776, '[unused771]'),\n",
              "             (777, '[unused772]'),\n",
              "             (778, '[unused773]'),\n",
              "             (779, '[unused774]'),\n",
              "             (780, '[unused775]'),\n",
              "             (781, '[unused776]'),\n",
              "             (782, '[unused777]'),\n",
              "             (783, '[unused778]'),\n",
              "             (784, '[unused779]'),\n",
              "             (785, '[unused780]'),\n",
              "             (786, '[unused781]'),\n",
              "             (787, '[unused782]'),\n",
              "             (788, '[unused783]'),\n",
              "             (789, '[unused784]'),\n",
              "             (790, '[unused785]'),\n",
              "             (791, '[unused786]'),\n",
              "             (792, '[unused787]'),\n",
              "             (793, '[unused788]'),\n",
              "             (794, '[unused789]'),\n",
              "             (795, '[unused790]'),\n",
              "             (796, '[unused791]'),\n",
              "             (797, '[unused792]'),\n",
              "             (798, '[unused793]'),\n",
              "             (799, '[unused794]'),\n",
              "             (800, '[unused795]'),\n",
              "             (801, '[unused796]'),\n",
              "             (802, '[unused797]'),\n",
              "             (803, '[unused798]'),\n",
              "             (804, '[unused799]'),\n",
              "             (805, '[unused800]'),\n",
              "             (806, '[unused801]'),\n",
              "             (807, '[unused802]'),\n",
              "             (808, '[unused803]'),\n",
              "             (809, '[unused804]'),\n",
              "             (810, '[unused805]'),\n",
              "             (811, '[unused806]'),\n",
              "             (812, '[unused807]'),\n",
              "             (813, '[unused808]'),\n",
              "             (814, '[unused809]'),\n",
              "             (815, '[unused810]'),\n",
              "             (816, '[unused811]'),\n",
              "             (817, '[unused812]'),\n",
              "             (818, '[unused813]'),\n",
              "             (819, '[unused814]'),\n",
              "             (820, '[unused815]'),\n",
              "             (821, '[unused816]'),\n",
              "             (822, '[unused817]'),\n",
              "             (823, '[unused818]'),\n",
              "             (824, '[unused819]'),\n",
              "             (825, '[unused820]'),\n",
              "             (826, '[unused821]'),\n",
              "             (827, '[unused822]'),\n",
              "             (828, '[unused823]'),\n",
              "             (829, '[unused824]'),\n",
              "             (830, '[unused825]'),\n",
              "             (831, '[unused826]'),\n",
              "             (832, '[unused827]'),\n",
              "             (833, '[unused828]'),\n",
              "             (834, '[unused829]'),\n",
              "             (835, '[unused830]'),\n",
              "             (836, '[unused831]'),\n",
              "             (837, '[unused832]'),\n",
              "             (838, '[unused833]'),\n",
              "             (839, '[unused834]'),\n",
              "             (840, '[unused835]'),\n",
              "             (841, '[unused836]'),\n",
              "             (842, '[unused837]'),\n",
              "             (843, '[unused838]'),\n",
              "             (844, '[unused839]'),\n",
              "             (845, '[unused840]'),\n",
              "             (846, '[unused841]'),\n",
              "             (847, '[unused842]'),\n",
              "             (848, '[unused843]'),\n",
              "             (849, '[unused844]'),\n",
              "             (850, '[unused845]'),\n",
              "             (851, '[unused846]'),\n",
              "             (852, '[unused847]'),\n",
              "             (853, '[unused848]'),\n",
              "             (854, '[unused849]'),\n",
              "             (855, '[unused850]'),\n",
              "             (856, '[unused851]'),\n",
              "             (857, '[unused852]'),\n",
              "             (858, '[unused853]'),\n",
              "             (859, '[unused854]'),\n",
              "             (860, '[unused855]'),\n",
              "             (861, '[unused856]'),\n",
              "             (862, '[unused857]'),\n",
              "             (863, '[unused858]'),\n",
              "             (864, '[unused859]'),\n",
              "             (865, '[unused860]'),\n",
              "             (866, '[unused861]'),\n",
              "             (867, '[unused862]'),\n",
              "             (868, '[unused863]'),\n",
              "             (869, '[unused864]'),\n",
              "             (870, '[unused865]'),\n",
              "             (871, '[unused866]'),\n",
              "             (872, '[unused867]'),\n",
              "             (873, '[unused868]'),\n",
              "             (874, '[unused869]'),\n",
              "             (875, '[unused870]'),\n",
              "             (876, '[unused871]'),\n",
              "             (877, '[unused872]'),\n",
              "             (878, '[unused873]'),\n",
              "             (879, '[unused874]'),\n",
              "             (880, '[unused875]'),\n",
              "             (881, '[unused876]'),\n",
              "             (882, '[unused877]'),\n",
              "             (883, '[unused878]'),\n",
              "             (884, '[unused879]'),\n",
              "             (885, '[unused880]'),\n",
              "             (886, '[unused881]'),\n",
              "             (887, '[unused882]'),\n",
              "             (888, '[unused883]'),\n",
              "             (889, '[unused884]'),\n",
              "             (890, '[unused885]'),\n",
              "             (891, '[unused886]'),\n",
              "             (892, '[unused887]'),\n",
              "             (893, '[unused888]'),\n",
              "             (894, '[unused889]'),\n",
              "             (895, '[unused890]'),\n",
              "             (896, '[unused891]'),\n",
              "             (897, '[unused892]'),\n",
              "             (898, '[unused893]'),\n",
              "             (899, '[unused894]'),\n",
              "             (900, '[unused895]'),\n",
              "             (901, '[unused896]'),\n",
              "             (902, '[unused897]'),\n",
              "             (903, '[unused898]'),\n",
              "             (904, '[unused899]'),\n",
              "             (905, '[unused900]'),\n",
              "             (906, '[unused901]'),\n",
              "             (907, '[unused902]'),\n",
              "             (908, '[unused903]'),\n",
              "             (909, '[unused904]'),\n",
              "             (910, '[unused905]'),\n",
              "             (911, '[unused906]'),\n",
              "             (912, '[unused907]'),\n",
              "             (913, '[unused908]'),\n",
              "             (914, '[unused909]'),\n",
              "             (915, '[unused910]'),\n",
              "             (916, '[unused911]'),\n",
              "             (917, '[unused912]'),\n",
              "             (918, '[unused913]'),\n",
              "             (919, '[unused914]'),\n",
              "             (920, '[unused915]'),\n",
              "             (921, '[unused916]'),\n",
              "             (922, '[unused917]'),\n",
              "             (923, '[unused918]'),\n",
              "             (924, '[unused919]'),\n",
              "             (925, '[unused920]'),\n",
              "             (926, '[unused921]'),\n",
              "             (927, '[unused922]'),\n",
              "             (928, '[unused923]'),\n",
              "             (929, '[unused924]'),\n",
              "             (930, '[unused925]'),\n",
              "             (931, '[unused926]'),\n",
              "             (932, '[unused927]'),\n",
              "             (933, '[unused928]'),\n",
              "             (934, '[unused929]'),\n",
              "             (935, '[unused930]'),\n",
              "             (936, '[unused931]'),\n",
              "             (937, '[unused932]'),\n",
              "             (938, '[unused933]'),\n",
              "             (939, '[unused934]'),\n",
              "             (940, '[unused935]'),\n",
              "             (941, '[unused936]'),\n",
              "             (942, '[unused937]'),\n",
              "             (943, '[unused938]'),\n",
              "             (944, '[unused939]'),\n",
              "             (945, '[unused940]'),\n",
              "             (946, '[unused941]'),\n",
              "             (947, '[unused942]'),\n",
              "             (948, '[unused943]'),\n",
              "             (949, '[unused944]'),\n",
              "             (950, '[unused945]'),\n",
              "             (951, '[unused946]'),\n",
              "             (952, '[unused947]'),\n",
              "             (953, '[unused948]'),\n",
              "             (954, '[unused949]'),\n",
              "             (955, '[unused950]'),\n",
              "             (956, '[unused951]'),\n",
              "             (957, '[unused952]'),\n",
              "             (958, '[unused953]'),\n",
              "             (959, '[unused954]'),\n",
              "             (960, '[unused955]'),\n",
              "             (961, '[unused956]'),\n",
              "             (962, '[unused957]'),\n",
              "             (963, '[unused958]'),\n",
              "             (964, '[unused959]'),\n",
              "             (965, '[unused960]'),\n",
              "             (966, '[unused961]'),\n",
              "             (967, '[unused962]'),\n",
              "             (968, '[unused963]'),\n",
              "             (969, '[unused964]'),\n",
              "             (970, '[unused965]'),\n",
              "             (971, '[unused966]'),\n",
              "             (972, '[unused967]'),\n",
              "             (973, '[unused968]'),\n",
              "             (974, '[unused969]'),\n",
              "             (975, '[unused970]'),\n",
              "             (976, '[unused971]'),\n",
              "             (977, '[unused972]'),\n",
              "             (978, '[unused973]'),\n",
              "             (979, '[unused974]'),\n",
              "             (980, '[unused975]'),\n",
              "             (981, '[unused976]'),\n",
              "             (982, '[unused977]'),\n",
              "             (983, '[unused978]'),\n",
              "             (984, '[unused979]'),\n",
              "             (985, '[unused980]'),\n",
              "             (986, '[unused981]'),\n",
              "             (987, '[unused982]'),\n",
              "             (988, '[unused983]'),\n",
              "             (989, '[unused984]'),\n",
              "             (990, '[unused985]'),\n",
              "             (991, '[unused986]'),\n",
              "             (992, '[unused987]'),\n",
              "             (993, '[unused988]'),\n",
              "             (994, '[unused989]'),\n",
              "             (995, '[unused990]'),\n",
              "             (996, '[unused991]'),\n",
              "             (997, '[unused992]'),\n",
              "             (998, '[unused993]'),\n",
              "             (999, '!'),\n",
              "             ...])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "ids_to_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RUVseZQjMkfe"
      },
      "outputs": [],
      "source": [
        "from utils.tokenizer import BasicTokenizer, WordpieceTokenizer\n",
        "\n",
        "class BertTokenizer(object):\n",
        "\n",
        "    def __init__(self, vocab_file, do_lower_case=True):\n",
        "\n",
        "        self.vocab, self.ids_to_tokens = load_vocab(vocab_file)\n",
        "\n",
        "        never_split = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\")\n",
        "\n",
        "        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case,\n",
        "                                              never_split=never_split)\n",
        "        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        split_tokens = []\n",
        "        for token in self.basic_tokenizer.tokenize(text):\n",
        "            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
        "                split_tokens.append(sub_token)\n",
        "        return split_tokens\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        ids = []\n",
        "        for token in tokens:\n",
        "            ids.append(self.vocab[token])\n",
        "\n",
        "        return ids\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        tokens = []\n",
        "        for i in ids:\n",
        "            tokens.append(self.ids_to_tokens[i])\n",
        "        return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "sm6BDVTLMkfe",
        "outputId": "2ed31d88-f1a4-41f6-c59b-de626772664c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'i', 'accessed', 'the', 'bank', 'account', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "text_1 = \"[CLS] I accessed the bank account. [SEP]\"\n",
        "\n",
        "text_2 = \"[CLS] He transferred the deposit money into the bank account. [SEP]\"\n",
        "\n",
        "text_3 = \"[CLS] We play soccer at the bank of the river. [SEP]\"\n",
        "\n",
        "tokenizer = BertTokenizer(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "tokenized_text_1 = tokenizer.tokenize(text_1)\n",
        "tokenized_text_2 = tokenizer.tokenize(text_2)\n",
        "tokenized_text_3 = tokenizer.tokenize(text_3)\n",
        "\n",
        "print(tokenized_text_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dOdLEGtPMkfe",
        "outputId": "54b19821-6e25-4324-a0a0-ee95311ffbf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1045, 11570,  1996,  2924,  4070,  1012,   102]])\n"
          ]
        }
      ],
      "source": [
        "indexed_tokens_1 = tokenizer.convert_tokens_to_ids(tokenized_text_1)\n",
        "indexed_tokens_2 = tokenizer.convert_tokens_to_ids(tokenized_text_2)\n",
        "indexed_tokens_3 = tokenizer.convert_tokens_to_ids(tokenized_text_3)\n",
        "\n",
        "bank_posi_1 = np.where(np.array(tokenized_text_1) == \"bank\")[0][0]  # 4\n",
        "bank_posi_2 = np.where(np.array(tokenized_text_2) == \"bank\")[0][0]  # 8\n",
        "bank_posi_3 = np.where(np.array(tokenized_text_3) == \"bank\")[0][0]  # 6\n",
        "\n",
        "tokens_tensor_1 = torch.tensor([indexed_tokens_1])\n",
        "tokens_tensor_2 = torch.tensor([indexed_tokens_2])\n",
        "tokens_tensor_3 = torch.tensor([indexed_tokens_3])\n",
        "\n",
        "bank_word_id = tokenizer.convert_tokens_to_ids([\"bank\"])[0]\n",
        "\n",
        "print(tokens_tensor_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7SBuiidGMkfe"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    encoded_layers_1, _ = net(tokens_tensor_1, output_all_encoded_layers=True)\n",
        "    encoded_layers_2, _ = net(tokens_tensor_2, output_all_encoded_layers=True)\n",
        "    encoded_layers_3, _ = net(tokens_tensor_3, output_all_encoded_layers=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "l0vZ2BGmMkff"
      },
      "outputs": [],
      "source": [
        "bank_vector_0 = net.embeddings.word_embeddings.weight[bank_word_id]\n",
        "\n",
        "bank_vector_1_1 = encoded_layers_1[0][0, bank_posi_1]\n",
        "\n",
        "bank_vector_1_12 = encoded_layers_1[11][0, bank_posi_1]\n",
        "\n",
        "bank_vector_2_1 = encoded_layers_2[0][0, bank_posi_2]\n",
        "bank_vector_2_12 = encoded_layers_2[11][0, bank_posi_2]\n",
        "bank_vector_3_1 = encoded_layers_3[0][0, bank_posi_3]\n",
        "bank_vector_3_12 = encoded_layers_3[11][0, bank_posi_3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Zigk2F7HMkff",
        "outputId": "3e3a89d3-7f06-477a-a345-54d722f51eaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bank의 초기 벡터와 문장1의 1단 bank의 유사도:  tensor(0.6814, grad_fn=<DivBackward0>)\n",
            "bank의 초기 벡터와 문장1의 12단 bank의 유사도:  tensor(0.2276, grad_fn=<DivBackward0>)\n",
            "문장1의 1층 bank와 문장2의 1단 bank의 유사도:  tensor(0.8968)\n",
            "문장1의 1층 bank와 문장3의 1단 bank의 유사도:  tensor(0.7584)\n",
            "문장1의 12층 bank와 문장2의 12단 bank의 유사도:  tensor(0.8796)\n",
            "문장1의 12층 bank와 문장3의 12단 bank의 유사도:  tensor(0.4814)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"bank의 초기 벡터와 문장1의 1단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_0, bank_vector_1_1, dim=0))\n",
        "print(\"bank의 초기 벡터와 문장1의 12단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_0, bank_vector_1_12, dim=0))\n",
        "\n",
        "print(\"문장1의 1층 bank와 문장2의 1단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_1, bank_vector_2_1, dim=0))\n",
        "print(\"문장1의 1층 bank와 문장3의 1단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_1, bank_vector_3_1, dim=0))\n",
        "\n",
        "print(\"문장1의 12층 bank와 문장2의 12단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_12, bank_vector_2_12, dim=0))\n",
        "print(\"문장1의 12층 bank와 문장3의 12단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_12, bank_vector_3_12, dim=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchtext==0.8.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaybSmRTZ6Ij",
        "outputId": "53bce01a-be86-4881-9090-04a7bfa983c5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.8.1 in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.64.1)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchtext==0.8.1) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EF5lHuFAPINb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch \n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VOw22zp2PINc"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "b1yU2b9mPINd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from utils.bert import BertTokenizer\n",
        "\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "\n",
        "tokenizer_bert = BertTokenizer(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "\n",
        "def tokenizer_with_preprocessing(text, tokenizer=tokenizer_bert.tokenize):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer(text)\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0mMpfLN7PINd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3c959a-9d0b-4c25-97ef-b8969d39173d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "max_length = 256\n",
        "\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"[CLS]\", eos_token=\"[SEP]\", pad_token='[PAD]', unk_token='[UNK]')\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "EfQ3ag6tPINe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a228bd3-8917-4e0a-a1ec-3b41c7141b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ]
        }
      ],
      "source": [
        "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='./data/', train='IMDb_train.tsv',\n",
        "    test='IMDb_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "train_ds, val_ds = train_val_ds.split(\n",
        "    split_ratio=0.8, random_state=random.seed(1234))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BKehPPSaPINe"
      },
      "outputs": [],
      "source": [
        "from utils.bert import BertTokenizer, load_vocab\n",
        "\n",
        "vocab_bert, ids_to_tokens_bert = load_vocab(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\")\n",
        "\n",
        "\n",
        "TEXT.build_vocab(train_ds, min_freq=1)\n",
        "TEXT.vocab.stoi = vocab_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "M2UBL8nwPINf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cecc974a-6ef6-4984-f908-728f011f615b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dl = torchtext.data.Iterator(\n",
        "    train_ds, batch_size=batch_size, train=True)\n",
        "\n",
        "val_dl = torchtext.data.Iterator(\n",
        "    val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "test_dl = torchtext.data.Iterator(\n",
        "    test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "a6abbwRLPINf",
        "outputId": "9b490a0b-4b45-4dba-a5ec-32c73a7e6195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 101, 2061, 2411,  ...,    0,    0,    0],\n",
            "        [ 101, 2043, 1045,  ...,    0,    0,    0],\n",
            "        [ 101, 2023, 3185,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 6203, 2643,  ...,    0,    0,    0],\n",
            "        [ 101, 2023, 2003,  ...,    0,    0,    0],\n",
            "        [ 101, 2116, 2111,  ..., 3496, 2003,  102]]), tensor([147,  77, 175, 138,  49, 232, 231, 142, 165, 232,  17, 232, 161, 230,\n",
            "        175, 256, 152, 256, 204, 256, 129, 221, 166, 149, 211, 256, 201, 161,\n",
            "        256, 148, 196, 256]))\n",
            "tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
            "        0, 1, 1, 1, 0, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(val_dl))\n",
        "print(batch.Text)\n",
        "print(batch.Label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "QlQHCn8lPINg",
        "outputId": "008dc9fc-9438-4c6d-fe9e-c02839f6abb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'when', 'i', 'learned', 'of', 'sir', 'alec', 'guinness', 'death', ',', 'this', 'was', 'the', 'first', 'of', 'his', 'many', 'films', 'i', 'thought', 'of', 're', 'seeing', '.', 'what', 'a', 'wonderful', 'dr', '##oll', 'commentary', 'the', 'film', 'provides', 'even', 'after', 'all', 'these', 'years', '.', 'and', 'guinness', 'helps', 'to', 'weave', 'the', 'charm', 'into', 'every', 'frame', '.', 'his', 'eyes', 'and', 'face', 'are', 'as', 'luminous', 'as', 'that', 'white', 'suit', 'he', 'wears', '.', 'both', 'he', 'and', 'the', 'film', 'have', 'to', 'be', 'considered', 'lifetime', 'favorites', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "text_minibatch_1 = (batch.Text[0][1]).numpy()\n",
        "\n",
        "text = tokenizer_bert.convert_ids_to_tokens(text_minibatch_1)\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "rb5y0-KiPINg",
        "outputId": "63ca5727-face-4d20-d5ea-fc59f92b6313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight→pooler.dense.weight\n",
            "bert.pooler.dense.bias→pooler.dense.bias\n"
          ]
        }
      ],
      "source": [
        "from utils.bert import get_config, BertModel, set_learned_params\n",
        "\n",
        "config = get_config(file_path=\"./weights/bert_config.json\")\n",
        "\n",
        "net_bert = BertModel(config)\n",
        "\n",
        "net_bert = set_learned_params(\n",
        "    net_bert, weights_path=\"./weights/pytorch_model.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dSHHEMgaPINg"
      },
      "outputs": [],
      "source": [
        "class BertForIMDb(nn.Module):\n",
        "\n",
        "    def __init__(self, net_bert):\n",
        "        super(BertForIMDb, self).__init__()\n",
        "\n",
        "        self.bert = net_bert\n",
        "\n",
        "        self.cls = nn.Linear(in_features=768, out_features=2)\n",
        "\n",
        "        nn.init.normal_(self.cls.weight, std=0.02)\n",
        "        nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_flg=False):\n",
        "\n",
        "        if attention_show_flg == True:\n",
        "            encoded_layers, pooled_output, attention_probs = self.bert(\n",
        "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "        elif attention_show_flg == False:\n",
        "            encoded_layers, pooled_output = self.bert(\n",
        "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "\n",
        "        vec_0 = encoded_layers[:, 0, :]\n",
        "        vec_0 = vec_0.view(-1, 768)\n",
        "        out = self.cls(vec_0)\n",
        "\n",
        "        if attention_show_flg == True:\n",
        "            return out, attention_probs\n",
        "        elif attention_show_flg == False:\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "8KEs_ACFPINh",
        "outputId": "c9f6a4f8-3d95-4efd-c1ed-ab7cc09c3a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "네트워크 설정 완료\n"
          ]
        }
      ],
      "source": [
        "net = BertForIMDb(net_bert)\n",
        "\n",
        "net.train()\n",
        "\n",
        "print('네트워크 설정 완료')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NPgUNtERPINh"
      },
      "outputs": [],
      "source": [
        "for name, param in net.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for name, param in net.cls.named_parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "N_Z1QfQ_PINh"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam([\n",
        "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "    {'params': net.cls.parameters(), 'lr': 5e-5}\n",
        "], betas=(0.9, 0.999))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "61NDISi1PINi"
      },
      "outputs": [],
      "source": [
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"사용 장치: \", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()\n",
        "\n",
        "            epoch_loss = 0.0 \n",
        "            epoch_corrects = 0  \n",
        "            iteration = 1\n",
        "\n",
        "            t_epoch_start = time.time()\n",
        "            t_iter_start = time.time()\n",
        "\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "\n",
        "                inputs = batch.Text[0].to(device)  \n",
        "                labels = batch.Label.to(device)  \n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    outputs = net(inputs, token_type_ids=None, attention_mask=None,\n",
        "                                  output_all_encoded_layers=False, attention_show_flg=False)\n",
        "\n",
        "                    loss = criterion(outputs, labels)  \n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  \n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0): \n",
        "                            t_iter_finish = time.time()\n",
        "                            duration = t_iter_finish - t_iter_start\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            print('반복 {} || Loss: {:.4f} || 10iter: {:.4f} sec. || 이 반복의 정답률: {}'.format(\n",
        "                                iteration, loss.item(), duration, acc))\n",
        "                            t_iter_start = time.time()\n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            t_epoch_finish = time.time()\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "            t_epoch_start = time.time()\n",
        "\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1IHJyECPPINi",
        "outputId": "4ac18daf-293e-47e0-e513-783756c29217",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 장치:  cuda:0\n",
            "-----start-------\n",
            "반복 10 || Loss: 0.7150 || 10iter: 5.4590 sec. || 이 반복의 정답률: 0.46875\n",
            "반복 20 || Loss: 0.6284 || 10iter: 5.2917 sec. || 이 반복의 정답률: 0.625\n",
            "반복 30 || Loss: 0.6160 || 10iter: 5.3253 sec. || 이 반복의 정답률: 0.78125\n",
            "반복 40 || Loss: 0.6208 || 10iter: 5.3477 sec. || 이 반복의 정답률: 0.71875\n",
            "반복 50 || Loss: 0.5847 || 10iter: 5.4007 sec. || 이 반복의 정답률: 0.6875\n",
            "반복 60 || Loss: 0.5435 || 10iter: 5.4160 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 70 || Loss: 0.5384 || 10iter: 5.4475 sec. || 이 반복의 정답률: 0.75\n",
            "반복 80 || Loss: 0.5156 || 10iter: 5.4738 sec. || 이 반복의 정답률: 0.6875\n",
            "반복 90 || Loss: 0.3153 || 10iter: 5.4967 sec. || 이 반복의 정답률: 0.875\n",
            "반복 100 || Loss: 0.3462 || 10iter: 5.5243 sec. || 이 반복의 정답률: 0.875\n",
            "반복 110 || Loss: 0.3460 || 10iter: 5.5479 sec. || 이 반복의 정답률: 0.875\n",
            "반복 120 || Loss: 0.3068 || 10iter: 5.5873 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 130 || Loss: 0.3210 || 10iter: 5.6514 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 140 || Loss: 0.4766 || 10iter: 5.6657 sec. || 이 반복의 정답률: 0.875\n",
            "반복 150 || Loss: 0.4593 || 10iter: 5.7083 sec. || 이 반복의 정답률: 0.78125\n",
            "반복 160 || Loss: 0.3504 || 10iter: 5.7101 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 170 || Loss: 0.2972 || 10iter: 5.7242 sec. || 이 반복의 정답률: 0.875\n",
            "반복 180 || Loss: 0.3045 || 10iter: 5.7357 sec. || 이 반복의 정답률: 0.875\n",
            "반복 190 || Loss: 0.2338 || 10iter: 5.7809 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 200 || Loss: 0.2445 || 10iter: 5.8524 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 210 || Loss: 0.5735 || 10iter: 5.9577 sec. || 이 반복의 정답률: 0.75\n",
            "반복 220 || Loss: 0.2621 || 10iter: 5.9880 sec. || 이 반복의 정답률: 0.875\n",
            "반복 230 || Loss: 0.2030 || 10iter: 5.9689 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 240 || Loss: 0.2172 || 10iter: 5.9637 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 250 || Loss: 0.1829 || 10iter: 5.9894 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 260 || Loss: 0.3514 || 10iter: 6.0367 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 270 || Loss: 0.3614 || 10iter: 6.1223 sec. || 이 반복의 정답률: 0.875\n",
            "반복 280 || Loss: 0.3363 || 10iter: 6.2502 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 290 || Loss: 0.2515 || 10iter: 6.2339 sec. || 이 반복의 정답률: 0.875\n",
            "반복 300 || Loss: 0.1627 || 10iter: 6.1887 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 310 || Loss: 0.1387 || 10iter: 6.1366 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 320 || Loss: 0.6190 || 10iter: 6.1475 sec. || 이 반복의 정답률: 0.6875\n",
            "반복 330 || Loss: 0.4295 || 10iter: 6.2058 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 340 || Loss: 0.1699 || 10iter: 6.2755 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 350 || Loss: 0.2808 || 10iter: 6.3457 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 360 || Loss: 0.3367 || 10iter: 6.3402 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 370 || Loss: 0.2366 || 10iter: 6.2519 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 380 || Loss: 0.1829 || 10iter: 6.2347 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 390 || Loss: 0.2638 || 10iter: 6.2713 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 400 || Loss: 0.4159 || 10iter: 6.3539 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 410 || Loss: 0.2309 || 10iter: 6.4645 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 420 || Loss: 0.3861 || 10iter: 6.5114 sec. || 이 반복의 정답률: 0.875\n",
            "반복 430 || Loss: 0.3525 || 10iter: 6.4225 sec. || 이 반복의 정답률: 0.875\n",
            "반복 440 || Loss: 0.4484 || 10iter: 6.3992 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 450 || Loss: 0.3913 || 10iter: 6.3871 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 460 || Loss: 0.2273 || 10iter: 6.4309 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 470 || Loss: 0.2065 || 10iter: 6.5196 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 480 || Loss: 0.2450 || 10iter: 6.6060 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 490 || Loss: 0.5578 || 10iter: 6.5876 sec. || 이 반복의 정답률: 0.75\n",
            "반복 500 || Loss: 0.2815 || 10iter: 6.5254 sec. || 이 반복의 정답률: 0.875\n",
            "반복 510 || Loss: 0.2411 || 10iter: 6.4854 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 520 || Loss: 0.4090 || 10iter: 6.4819 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 530 || Loss: 0.2436 || 10iter: 6.5051 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 540 || Loss: 0.2440 || 10iter: 6.5892 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 550 || Loss: 0.1653 || 10iter: 6.6058 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 560 || Loss: 0.1268 || 10iter: 6.6036 sec. || 이 반복의 정답률: 1.0\n",
            "반복 570 || Loss: 0.1435 || 10iter: 6.6118 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 580 || Loss: 0.3617 || 10iter: 6.5931 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 590 || Loss: 0.3126 || 10iter: 6.5973 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 600 || Loss: 0.2793 || 10iter: 6.6002 sec. || 이 반복의 정답률: 0.875\n",
            "반복 610 || Loss: 0.2072 || 10iter: 6.6051 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 620 || Loss: 0.2768 || 10iter: 6.6048 sec. || 이 반복의 정답률: 0.90625\n",
            "Epoch 1/2 | train |  Loss: 0.3475 Acc: 0.8451\n",
            "Epoch 1/2 |  val  |  Loss: 0.2544 Acc: 0.9008\n",
            "반복 10 || Loss: 0.2307 || 10iter: 6.6020 sec. || 이 반복의 정답률: 0.875\n",
            "반복 20 || Loss: 0.2763 || 10iter: 6.5964 sec. || 이 반복의 정답률: 0.875\n",
            "반복 30 || Loss: 0.1958 || 10iter: 6.6109 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 40 || Loss: 0.2947 || 10iter: 6.6093 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 50 || Loss: 0.4280 || 10iter: 6.6014 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 60 || Loss: 0.1991 || 10iter: 6.5955 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 70 || Loss: 0.3075 || 10iter: 6.5932 sec. || 이 반복의 정답률: 0.875\n",
            "반복 80 || Loss: 0.2339 || 10iter: 6.5998 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 90 || Loss: 0.3435 || 10iter: 6.6035 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 100 || Loss: 0.3377 || 10iter: 6.5992 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 110 || Loss: 0.4049 || 10iter: 6.5916 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 120 || Loss: 0.1955 || 10iter: 6.6116 sec. || 이 반복의 정답률: 0.875\n",
            "반복 130 || Loss: 0.0853 || 10iter: 6.6063 sec. || 이 반복의 정답률: 1.0\n",
            "반복 140 || Loss: 0.1790 || 10iter: 6.6066 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 150 || Loss: 0.1971 || 10iter: 6.5979 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 160 || Loss: 0.2993 || 10iter: 6.6055 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 170 || Loss: 0.1527 || 10iter: 6.5952 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 180 || Loss: 0.0902 || 10iter: 6.5947 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 190 || Loss: 0.2599 || 10iter: 6.5934 sec. || 이 반복의 정답률: 0.875\n",
            "반복 200 || Loss: 0.3092 || 10iter: 6.5897 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 210 || Loss: 0.1121 || 10iter: 6.6104 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 220 || Loss: 0.2813 || 10iter: 6.6105 sec. || 이 반복의 정답률: 0.875\n",
            "반복 230 || Loss: 0.1722 || 10iter: 6.6043 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 240 || Loss: 0.3570 || 10iter: 6.5941 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 250 || Loss: 0.4162 || 10iter: 6.5944 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 260 || Loss: 0.4022 || 10iter: 6.5966 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 270 || Loss: 0.2105 || 10iter: 6.5940 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 280 || Loss: 0.1459 || 10iter: 6.6014 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 290 || Loss: 0.3920 || 10iter: 6.5973 sec. || 이 반복의 정답률: 0.875\n",
            "반복 300 || Loss: 0.1981 || 10iter: 6.6004 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 310 || Loss: 0.4112 || 10iter: 6.6037 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 320 || Loss: 0.1545 || 10iter: 6.6108 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 330 || Loss: 0.1690 || 10iter: 6.5957 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 340 || Loss: 0.3591 || 10iter: 6.6029 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 350 || Loss: 0.1885 || 10iter: 6.5953 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 360 || Loss: 0.2023 || 10iter: 6.5949 sec. || 이 반복의 정답률: 0.875\n",
            "반복 370 || Loss: 0.1350 || 10iter: 6.5952 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 380 || Loss: 0.1552 || 10iter: 6.6021 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 390 || Loss: 0.1754 || 10iter: 6.5930 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 400 || Loss: 0.2296 || 10iter: 6.6165 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 410 || Loss: 0.1820 || 10iter: 6.6106 sec. || 이 반복의 정답률: 0.875\n",
            "반복 420 || Loss: 0.2530 || 10iter: 6.5992 sec. || 이 반복의 정답률: 0.875\n",
            "반복 430 || Loss: 0.3251 || 10iter: 6.5942 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 440 || Loss: 0.2586 || 10iter: 6.5980 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 450 || Loss: 0.1538 || 10iter: 6.6054 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 460 || Loss: 0.2481 || 10iter: 6.5957 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 470 || Loss: 0.1975 || 10iter: 6.6034 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 480 || Loss: 0.1744 || 10iter: 6.5978 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 490 || Loss: 0.3289 || 10iter: 6.6083 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 500 || Loss: 0.1304 || 10iter: 6.6064 sec. || 이 반복의 정답률: 0.96875\n",
            "반복 510 || Loss: 0.3239 || 10iter: 6.6026 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 520 || Loss: 0.1773 || 10iter: 6.5975 sec. || 이 반복의 정답률: 0.90625\n",
            "반복 530 || Loss: 0.3921 || 10iter: 6.5958 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 540 || Loss: 0.3305 || 10iter: 6.5994 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 550 || Loss: 0.3512 || 10iter: 6.5931 sec. || 이 반복의 정답률: 0.84375\n",
            "반복 560 || Loss: 0.4151 || 10iter: 6.5956 sec. || 이 반복의 정답률: 0.8125\n",
            "반복 570 || Loss: 0.2428 || 10iter: 6.6021 sec. || 이 반복의 정답률: 0.875\n",
            "반복 580 || Loss: 0.0941 || 10iter: 6.6050 sec. || 이 반복의 정답률: 1.0\n",
            "반복 590 || Loss: 0.3550 || 10iter: 6.6123 sec. || 이 반복의 정답률: 0.875\n",
            "반복 600 || Loss: 0.2031 || 10iter: 6.6071 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 610 || Loss: 0.1780 || 10iter: 6.5954 sec. || 이 반복의 정답률: 0.9375\n",
            "반복 620 || Loss: 0.3165 || 10iter: 6.5980 sec. || 이 반복의 정답률: 0.8125\n",
            "Epoch 2/2 | train |  Loss: 0.2606 Acc: 0.8936\n",
            "Epoch 2/2 |  val  |  Loss: 0.2558 Acc: 0.9016\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 2\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "YBMQfm_VPINi"
      },
      "outputs": [],
      "source": [
        "save_path = './weights/bert_fine_tuning_IMDb.pth'\n",
        "torch.save(net_trained.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "KWHk_HDMPINi",
        "outputId": "e8fe6b1c-a5c0-488d-81a8-145e3ce095ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [08:14<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 25000개에서 정답률: 0.8999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()\n",
        "net_trained.to(device) \n",
        "\n",
        "epoch_corrects = 0\n",
        "\n",
        "for batch in tqdm(test_dl):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = batch.Text[0].to(device) \n",
        "    labels = batch.Label.to(device)  \n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        outputs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
        "                              output_all_encoded_layers=False, attention_show_flg=False)\n",
        "\n",
        "        loss = criterion(outputs, labels)  \n",
        "        _, preds = torch.max(outputs, 1)  \n",
        "        epoch_corrects += torch.sum(preds == labels.data) \n",
        "\n",
        "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
        "\n",
        "print('테스트 데이터 {}개에서 정답률: {:.4f}'.format(len(test_dl.dataset), epoch_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "QVGpwlsCPINj"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "test_dl = torchtext.data.Iterator(\n",
        "    test_ds, batch_size=batch_size, train=False, sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "L2YlzTdlPINj"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(test_dl))\n",
        "\n",
        "inputs = batch.Text[0].to(device)  \n",
        "labels = batch.Label.to(device)  \n",
        "\n",
        "outputs, attention_probs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
        "                                       output_all_encoded_layers=False, attention_show_flg=True)\n",
        "\n",
        "_, preds = torch.max(outputs, 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "XppbpW7PPINj"
      },
      "outputs": [],
      "source": [
        "def highlight(word, attn):\n",
        "    \"Attention 값이 크면 문자 배경을 진한 빨간색으로 하는 html을 출력하는 함수\"\n",
        "\n",
        "    html_color = '#%02X%02X%02X' % (\n",
        "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
        "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
        "\n",
        "\n",
        "def mk_html(index, batch, preds, normlized_weights, TEXT):\n",
        "    \"HTML 데이터를 작성한다\"\n",
        "\n",
        "    sentence = batch.Text[0][index]  \n",
        "    label = batch.Label[index]  \n",
        "    pred = preds[index]  \n",
        "\n",
        "    if label == 0:\n",
        "        label_str = \"Negative\"\n",
        "    else:\n",
        "        label_str = \"Positive\"\n",
        "\n",
        "    if pred == 0:\n",
        "        pred_str = \"Negative\"\n",
        "    else:\n",
        "        pred_str = \"Positive\"\n",
        "\n",
        "    html = '정답 라벨: {}<br>추론 라벨: {}<br><br>'.format(label_str, pred_str)\n",
        "\n",
        "    for i in range(12):\n",
        "\n",
        "        attens = normlized_weights[index, i, 0, :]\n",
        "        attens /= attens.max()\n",
        "\n",
        "        html += '[BERT의 Attention을 시각화_' + str(i+1) + ']<br>'\n",
        "        for word, attn in zip(sentence, attens):\n",
        "\n",
        "            if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "                break\n",
        "\n",
        "            html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
        "                [word.numpy().tolist()])[0], attn)\n",
        "        html += \"<br><br>\"\n",
        "\n",
        "    all_attens = attens*0\n",
        "    for i in range(12):\n",
        "        attens += normlized_weights[index, i, 0, :]\n",
        "    attens /= attens.max()\n",
        "\n",
        "    html += '[BERT의 Attention을 시각화_ALL]<br>'\n",
        "    for word, attn in zip(sentence, attens):\n",
        "\n",
        "        if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "            break\n",
        "\n",
        "        html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
        "            [word.numpy().tolist()])[0], attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    return html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "n8bZtNywPINj",
        "outputId": "9053868d-11a1-4e24-edd5-1e45315e1868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "정답 라벨: Positive<br>추론 라벨: Positive<br><br>[BERT의 Attention을 시각화_1]<br><span style=\"background-color: #FFFCFC\"> [CLS]</span><span style=\"background-color: #FFF7F7\"> i</span><span style=\"background-color: #FFD5D5\"> got</span><span style=\"background-color: #FF6969\"> this</span><span style=\"background-color: #FFE4E4\"> movie</span><span style=\"background-color: #FFFBFB\"> from</span><span style=\"background-color: #FFFBFB\"> e</span><span style=\"background-color: #FFB7B7\"> ##bay</span><span style=\"background-color: #FFFAFA\"> mainly</span><span style=\"background-color: #FFF9F9\"> because</span><span style=\"background-color: #FFF8F8\"> i</span><span style=\"background-color: #FFF9F9\"> m</span><span style=\"background-color: #FFFAFA\"> gay</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFD4D4\"> love</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFC7C7\"> .</span><span style=\"background-color: #FFFBFB\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF9F9\"> it</span><span style=\"background-color: #FFF6F6\"> s</span><span style=\"background-color: #FFFAFA\"> one</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFAFA\"> those</span><span style=\"background-color: #FFF6F6\"> movies</span><span style=\"background-color: #FFF9F9\"> that</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFCFC\"> you</span><span style=\"background-color: #FFCACA\"> watch</span><span style=\"background-color: #FFEBEB\"> it</span><span style=\"background-color: #FFFBFB\"> a</span><span style=\"background-color: #FFF3F3\"> second</span><span style=\"background-color: #FFF9F9\"> time</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFCFC\"> you</span><span style=\"background-color: #FFF9F9\"> never</span><span style=\"background-color: #FFADAD\"> say</span><span style=\"background-color: #FFC4C4\"> to</span><span style=\"background-color: #FFFBFB\"> yourself</span><span style=\"background-color: #FFECEC\"> ,</span><span style=\"background-color: #FFCECE\"> hmm</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FF5151\"> forgot</span><span style=\"background-color: #FFECEC\"> about</span><span style=\"background-color: #FFB3B3\"> this</span><span style=\"background-color: #FF0000\"> boring</span><span style=\"background-color: #FFCCCC\"> part</span><span style=\"background-color: #FFF9F9\"> .</span><span style=\"background-color: #FFF7F7\"> i</span><span style=\"background-color: #FFFAFA\"> ll</span><span style=\"background-color: #FFFBFB\"> go</span><span style=\"background-color: #FFF2F2\"> make</span><span style=\"background-color: #FFF4F4\"> popcorn</span><span style=\"background-color: #FFFAFA\"> .</span><span style=\"background-color: #FFE7E7\"> it</span><span style=\"background-color: #FFF3F3\"> doesn</span><span style=\"background-color: #FFEDED\"> t</span><span style=\"background-color: #FFD6D6\"> have</span><span style=\"background-color: #FFE6E6\"> that</span><span style=\"background-color: #FFE1E1\"> part</span><span style=\"background-color: #FFD0D0\"> .</span><span style=\"background-color: #FFEFEF\"> it</span><span style=\"background-color: #FFD3D3\"> s</span><span style=\"background-color: #FFF1F1\"> a</span><span style=\"background-color: #FFF8F8\"> very</span><span style=\"background-color: #FFF4F4\"> fluid</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFB6B6\"> constantly</span><span style=\"background-color: #FF7272\"> interesting</span><span style=\"background-color: #FFF3F3\"> film</span><span style=\"background-color: #FFCBCB\"> .</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFF1F1\"> yes</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFFCFC\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFD6D6\"> is</span><span style=\"background-color: #FFBFBF\"> worth</span><span style=\"background-color: #FFE0E0\"> it</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFF7F7\"> if</span><span style=\"background-color: #FFF9F9\"> nothing</span><span style=\"background-color: #FFF2F2\"> else</span><span style=\"background-color: #FFC5C5\"> .</span><span style=\"background-color: #FFE1E1\"> but</span><span style=\"background-color: #FFF8F8\"> ,</span><span style=\"background-color: #FFE5E5\"> it</span><span style=\"background-color: #FFD8D8\"> s</span><span style=\"background-color: #FFEAEA\"> a</span><span style=\"background-color: #FFF9F9\"> great</span><span style=\"background-color: #FFF2F2\"> movie</span><span style=\"background-color: #FFF1F1\"> even</span><span style=\"background-color: #FFF7F7\"> for</span><span style=\"background-color: #FFFCFC\"> straight</span><span style=\"background-color: #FFF9F9\"> guys</span><span style=\"background-color: #FFC5C5\"> .</span><br><br>[BERT의 Attention을 시각화_2]<br><span style=\"background-color: #FFC3C3\"> [CLS]</span><span style=\"background-color: #FFF6F6\"> i</span><span style=\"background-color: #FFF3F3\"> got</span><span style=\"background-color: #FFF6F6\"> this</span><span style=\"background-color: #FFEBEB\"> movie</span><span style=\"background-color: #FFF7F7\"> from</span><span style=\"background-color: #FFFAFA\"> e</span><span style=\"background-color: #FFFAFA\"> ##bay</span><span style=\"background-color: #FFFDFD\"> mainly</span><span style=\"background-color: #FFFAFA\"> because</span><span style=\"background-color: #FFF6F6\"> i</span><span style=\"background-color: #FFF7F7\"> m</span><span style=\"background-color: #FFCCCC\"> gay</span><span style=\"background-color: #FFF8F8\"> and</span><span style=\"background-color: #FFF9F9\"> i</span><span style=\"background-color: #FFF0F0\"> love</span><span style=\"background-color: #FFF2F2\"> til</span><span style=\"background-color: #FFFAFA\"> sc</span><span style=\"background-color: #FFFCFC\"> ##h</span><span style=\"background-color: #FFFCFC\"> ##weig</span><span style=\"background-color: #FFF8F8\"> ##er</span><span style=\"background-color: #FF3D3D\"> .</span><span style=\"background-color: #FFFEFE\"> however</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFF6F6\"> s</span><span style=\"background-color: #FFFAFA\"> one</span><span style=\"background-color: #FFFCFC\"> of</span><span style=\"background-color: #FFFBFB\"> those</span><span style=\"background-color: #FFE5E5\"> movies</span><span style=\"background-color: #FFFBFB\"> that</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFF5F5\"> when</span><span style=\"background-color: #FFE9E9\"> you</span><span style=\"background-color: #FFDBDB\"> watch</span><span style=\"background-color: #FFFAFA\"> it</span><span style=\"background-color: #FFF7F7\"> a</span><span style=\"background-color: #FFF2F2\"> second</span><span style=\"background-color: #FFF3F3\"> time</span><span style=\"background-color: #FFF8F8\"> ,</span><span style=\"background-color: #FFE5E5\"> you</span><span style=\"background-color: #FFECEC\"> never</span><span style=\"background-color: #FFF8F8\"> say</span><span style=\"background-color: #FFF3F3\"> to</span><span style=\"background-color: #FFF4F4\"> yourself</span><span style=\"background-color: #FFE9E9\"> ,</span><span style=\"background-color: #FFFDFD\"> hmm</span><span style=\"background-color: #FFF5F5\"> .</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFAFA\"> forgot</span><span style=\"background-color: #FFFCFC\"> about</span><span style=\"background-color: #FFF2F2\"> this</span><span style=\"background-color: #FFD8D8\"> boring</span><span style=\"background-color: #FFE1E1\"> part</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFF8F8\"> i</span><span style=\"background-color: #FFF8F8\"> ll</span><span style=\"background-color: #FFF1F1\"> go</span><span style=\"background-color: #FFEBEB\"> make</span><span style=\"background-color: #FFF4F4\"> popcorn</span><span style=\"background-color: #FFF9F9\"> .</span><span style=\"background-color: #FFF2F2\"> it</span><span style=\"background-color: #FFFEFE\"> doesn</span><span style=\"background-color: #FFFEFE\"> t</span><span style=\"background-color: #FFEEEE\"> have</span><span style=\"background-color: #FFFAFA\"> that</span><span style=\"background-color: #FFEEEE\"> part</span><span style=\"background-color: #FF6565\"> .</span><span style=\"background-color: #FFF6F6\"> it</span><span style=\"background-color: #FFF8F8\"> s</span><span style=\"background-color: #FFF2F2\"> a</span><span style=\"background-color: #FFF3F3\"> very</span><span style=\"background-color: #FFCCCC\"> fluid</span><span style=\"background-color: #FFD6D6\"> and</span><span style=\"background-color: #FFE5E5\"> constantly</span><span style=\"background-color: #FFB1B1\"> interesting</span><span style=\"background-color: #FFCDCD\"> film</span><span style=\"background-color: #FF4F4F\"> .</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFF5F5\"> ,</span><span style=\"background-color: #FFFCFC\"> yes</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFDADA\"> til</span><span style=\"background-color: #FFE7E7\"> sc</span><span style=\"background-color: #FFF6F6\"> ##h</span><span style=\"background-color: #FFF8F8\"> ##weig</span><span style=\"background-color: #FFEEEE\"> ##er</span><span style=\"background-color: #FFF9F9\"> is</span><span style=\"background-color: #FFECEC\"> worth</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFDFD\"> if</span><span style=\"background-color: #FFFEFE\"> nothing</span><span style=\"background-color: #FFFDFD\"> else</span><span style=\"background-color: #FF3434\"> .</span><span style=\"background-color: #FFFBFB\"> but</span><span style=\"background-color: #FFE2E2\"> ,</span><span style=\"background-color: #FFF0F0\"> it</span><span style=\"background-color: #FFF2F2\"> s</span><span style=\"background-color: #FFF2F2\"> a</span><span style=\"background-color: #FFF9F9\"> great</span><span style=\"background-color: #FFD4D4\"> movie</span><span style=\"background-color: #FFFBFB\"> even</span><span style=\"background-color: #FFEAEA\"> for</span><span style=\"background-color: #FF0000\"> straight</span><span style=\"background-color: #FF2727\"> guys</span><span style=\"background-color: #FF3232\"> .</span><br><br>[BERT의 Attention을 시각화_3]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFAFA\"> i</span><span style=\"background-color: #FFFCFC\"> got</span><span style=\"background-color: #FFD8D8\"> this</span><span style=\"background-color: #FFFCFC\"> movie</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> e</span><span style=\"background-color: #FFFEFE\"> ##bay</span><span style=\"background-color: #FFFDFD\"> mainly</span><span style=\"background-color: #FFF7F7\"> because</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFFCFC\"> m</span><span style=\"background-color: #FFFDFD\"> gay</span><span style=\"background-color: #FFF9F9\"> and</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFE3E3\"> love</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFCFC\"> ##er</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFF9F9\"> s</span><span style=\"background-color: #FF9D9D\"> one</span><span style=\"background-color: #FFF7F7\"> of</span><span style=\"background-color: #FFFDFD\"> those</span><span style=\"background-color: #FFFBFB\"> movies</span><span style=\"background-color: #FFEFEF\"> that</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> watch</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFCFC\"> a</span><span style=\"background-color: #FFFDFD\"> second</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFBFB\"> you</span><span style=\"background-color: #FFFBFB\"> never</span><span style=\"background-color: #FFFCFC\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> yourself</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFDFD\"> hmm</span><span style=\"background-color: #FFFBFB\"> .</span><span style=\"background-color: #FFF6F6\"> i</span><span style=\"background-color: #FFFEFE\"> forgot</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFBEBE\"> this</span><span style=\"background-color: #FFF6F6\"> boring</span><span style=\"background-color: #FFFAFA\"> part</span><span style=\"background-color: #FFFBFB\"> .</span><span style=\"background-color: #FFEBEB\"> i</span><span style=\"background-color: #FFF6F6\"> ll</span><span style=\"background-color: #FFB2B2\"> go</span><span style=\"background-color: #FFF2F2\"> make</span><span style=\"background-color: #FFF9F9\"> popcorn</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFFAFA\"> it</span><span style=\"background-color: #FFFDFD\"> doesn</span><span style=\"background-color: #FFFEFE\"> t</span><span style=\"background-color: #FFF4F4\"> have</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFFDFD\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF0F0\"> it</span><span style=\"background-color: #FFF4F4\"> s</span><span style=\"background-color: #FF3939\"> a</span><span style=\"background-color: #FFF8F8\"> very</span><span style=\"background-color: #FFD1D1\"> fluid</span><span style=\"background-color: #FF9595\"> and</span><span style=\"background-color: #FFF4F4\"> constantly</span><span style=\"background-color: #FFD2D2\"> interesting</span><span style=\"background-color: #FFECEC\"> film</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFD1D1\"> and</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFFDFD\"> yes</span><span style=\"background-color: #FFF5F5\"> ,</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFBFB\"> ##er</span><span style=\"background-color: #FFA2A2\"> is</span><span style=\"background-color: #FF8585\"> worth</span><span style=\"background-color: #FFEEEE\"> it</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFCFC\"> if</span><span style=\"background-color: #FFFEFE\"> nothing</span><span style=\"background-color: #FFFEFE\"> else</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF9F9\"> but</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFE9E9\"> it</span><span style=\"background-color: #FFF2F2\"> s</span><span style=\"background-color: #FF0000\"> a</span><span style=\"background-color: #FFD2D2\"> great</span><span style=\"background-color: #FFEDED\"> movie</span><span style=\"background-color: #FFFBFB\"> even</span><span style=\"background-color: #FFF2F2\"> for</span><span style=\"background-color: #FFFCFC\"> straight</span><span style=\"background-color: #FFFCFC\"> guys</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_4]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFFCFC\"> got</span><span style=\"background-color: #FFC0C0\"> this</span><span style=\"background-color: #FFC9C9\"> movie</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFDFD\"> e</span><span style=\"background-color: #FFFCFC\"> ##bay</span><span style=\"background-color: #FFFEFE\"> mainly</span><span style=\"background-color: #FFFEFE\"> because</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFFCFC\"> m</span><span style=\"background-color: #FFFCFC\"> gay</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFCFC\"> love</span><span style=\"background-color: #FFEDED\"> til</span><span style=\"background-color: #FFF5F5\"> sc</span><span style=\"background-color: #FFFDFD\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFBFB\"> ##er</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFAFA\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FF7E7E\"> it</span><span style=\"background-color: #FFEAEA\"> s</span><span style=\"background-color: #FFE8E8\"> one</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFFEFE\"> those</span><span style=\"background-color: #FFD8D8\"> movies</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFF4F4\"> watch</span><span style=\"background-color: #FF7979\"> it</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> second</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> never</span><span style=\"background-color: #FFFEFE\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> yourself</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFF7F7\"> hmm</span><span style=\"background-color: #FFFAFA\"> .</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFDFD\"> forgot</span><span style=\"background-color: #FFFDFD\"> about</span><span style=\"background-color: #FFFAFA\"> this</span><span style=\"background-color: #FFF8F8\"> boring</span><span style=\"background-color: #FFF4F4\"> part</span><span style=\"background-color: #FFFAFA\"> .</span><span style=\"background-color: #FFFAFA\"> i</span><span style=\"background-color: #FFF4F4\"> ll</span><span style=\"background-color: #FFFBFB\"> go</span><span style=\"background-color: #FFFBFB\"> make</span><span style=\"background-color: #FFF8F8\"> popcorn</span><span style=\"background-color: #FFFBFB\"> .</span><span style=\"background-color: #FFECEC\"> it</span><span style=\"background-color: #FFFDFD\"> doesn</span><span style=\"background-color: #FFFDFD\"> t</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFDFD\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFB2B2\"> it</span><span style=\"background-color: #FFEEEE\"> s</span><span style=\"background-color: #FFB3B3\"> a</span><span style=\"background-color: #FFFBFB\"> very</span><span style=\"background-color: #FFF6F6\"> fluid</span><span style=\"background-color: #FFF8F8\"> and</span><span style=\"background-color: #FFFDFD\"> constantly</span><span style=\"background-color: #FFFAFA\"> interesting</span><span style=\"background-color: #FFD0D0\"> film</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFE2E2\"> and</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFF9F9\"> yes</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFF4F4\"> til</span><span style=\"background-color: #FFFBFB\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFDFD\"> ##er</span><span style=\"background-color: #FF9696\"> is</span><span style=\"background-color: #FFD3D3\"> worth</span><span style=\"background-color: #FFEDED\"> it</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFF9F9\"> if</span><span style=\"background-color: #FFFEFE\"> nothing</span><span style=\"background-color: #FFFEFE\"> else</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFCFC\"> but</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FF0000\"> it</span><span style=\"background-color: #FFE6E6\"> s</span><span style=\"background-color: #FF7373\"> a</span><span style=\"background-color: #FFF8F8\"> great</span><span style=\"background-color: #FFD9D9\"> movie</span><span style=\"background-color: #FFFEFE\"> even</span><span style=\"background-color: #FFFDFD\"> for</span><span style=\"background-color: #FFFDFD\"> straight</span><span style=\"background-color: #FFFEFE\"> guys</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_5]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFCFC\"> got</span><span style=\"background-color: #FFF9F9\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> e</span><span style=\"background-color: #FFFEFE\"> ##bay</span><span style=\"background-color: #FFFCFC\"> mainly</span><span style=\"background-color: #FFFEFE\"> because</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFDFD\"> m</span><span style=\"background-color: #FFFEFE\"> gay</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFECEC\"> love</span><span style=\"background-color: #FFFCFC\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFDFD\"> ##er</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF7F7\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFF6F6\"> s</span><span style=\"background-color: #FFF8F8\"> one</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFBFB\"> those</span><span style=\"background-color: #FFFDFD\"> movies</span><span style=\"background-color: #FFF7F7\"> that</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> watch</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> second</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFDFD\"> never</span><span style=\"background-color: #FFFEFE\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> yourself</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> hmm</span><span style=\"background-color: #FFFBFB\"> .</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFE9E9\"> forgot</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFF3F3\"> this</span><span style=\"background-color: #FF7676\"> boring</span><span style=\"background-color: #FFF7F7\"> part</span><span style=\"background-color: #FFFAFA\"> .</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFF4F4\"> ll</span><span style=\"background-color: #FFF7F7\"> go</span><span style=\"background-color: #FFFCFC\"> make</span><span style=\"background-color: #FFFCFC\"> popcorn</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFF8F8\"> doesn</span><span style=\"background-color: #FFFBFB\"> t</span><span style=\"background-color: #FFFDFD\"> have</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFFCFC\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFAFA\"> it</span><span style=\"background-color: #FFDBDB\"> s</span><span style=\"background-color: #FFEBEB\"> a</span><span style=\"background-color: #FFA9A9\"> very</span><span style=\"background-color: #FF9999\"> fluid</span><span style=\"background-color: #FF5F5F\"> and</span><span style=\"background-color: #FFC8C8\"> constantly</span><span style=\"background-color: #FF8D8D\"> interesting</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF9F9\"> yes</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFBFB\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFDFD\"> ##er</span><span style=\"background-color: #FFE3E3\"> is</span><span style=\"background-color: #FF8686\"> worth</span><span style=\"background-color: #FFF6F6\"> it</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> if</span><span style=\"background-color: #FFFAFA\"> nothing</span><span style=\"background-color: #FFFEFE\"> else</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF2F2\"> but</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFF3F3\"> s</span><span style=\"background-color: #FFF6F6\"> a</span><span style=\"background-color: #FF0000\"> great</span><span style=\"background-color: #FFFDFD\"> movie</span><span style=\"background-color: #FFF7F7\"> even</span><span style=\"background-color: #FFF8F8\"> for</span><span style=\"background-color: #FFFEFE\"> straight</span><span style=\"background-color: #FFFEFE\"> guys</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_6]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFCFC\"> got</span><span style=\"background-color: #FFF2F2\"> this</span><span style=\"background-color: #FFE2E2\"> movie</span><span style=\"background-color: #FFFCFC\"> from</span><span style=\"background-color: #FFEEEE\"> e</span><span style=\"background-color: #FFA2A2\"> ##bay</span><span style=\"background-color: #FFD0D0\"> mainly</span><span style=\"background-color: #FFF2F2\"> because</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFFAFA\"> m</span><span style=\"background-color: #FFF0F0\"> gay</span><span style=\"background-color: #FFF7F7\"> and</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFEBEB\"> love</span><span style=\"background-color: #FFF8F8\"> til</span><span style=\"background-color: #FFFAFA\"> sc</span><span style=\"background-color: #FFF9F9\"> ##h</span><span style=\"background-color: #FFF3F3\"> ##weig</span><span style=\"background-color: #FFEAEA\"> ##er</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFF6F6\"> however</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFF9F9\"> s</span><span style=\"background-color: #FFFCFC\"> one</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFF9F9\"> those</span><span style=\"background-color: #FFC9C9\"> movies</span><span style=\"background-color: #FFF4F4\"> that</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFCFC\"> when</span><span style=\"background-color: #FFFCFC\"> you</span><span style=\"background-color: #FFF2F2\"> watch</span><span style=\"background-color: #FFF9F9\"> it</span><span style=\"background-color: #FFF9F9\"> a</span><span style=\"background-color: #FFDEDE\"> second</span><span style=\"background-color: #FFEAEA\"> time</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF7F7\"> you</span><span style=\"background-color: #FFF3F3\"> never</span><span style=\"background-color: #FFF8F8\"> say</span><span style=\"background-color: #FFF9F9\"> to</span><span style=\"background-color: #FFF5F5\"> yourself</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF6F6\"> hmm</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFF1F1\"> forgot</span><span style=\"background-color: #FFFDFD\"> about</span><span style=\"background-color: #FFE7E7\"> this</span><span style=\"background-color: #FF9898\"> boring</span><span style=\"background-color: #FFDEDE\"> part</span><span style=\"background-color: #FFFAFA\"> .</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFDFD\"> ll</span><span style=\"background-color: #FFFDFD\"> go</span><span style=\"background-color: #FFECEC\"> make</span><span style=\"background-color: #FF0000\"> popcorn</span><span style=\"background-color: #FFF9F9\"> .</span><span style=\"background-color: #FFF0F0\"> it</span><span style=\"background-color: #FFE1E1\"> doesn</span><span style=\"background-color: #FFEDED\"> t</span><span style=\"background-color: #FFDADA\"> have</span><span style=\"background-color: #FFF5F5\"> that</span><span style=\"background-color: #FFDADA\"> part</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFF8F8\"> it</span><span style=\"background-color: #FFFAFA\"> s</span><span style=\"background-color: #FFF2F2\"> a</span><span style=\"background-color: #FFF7F7\"> very</span><span style=\"background-color: #FFDEDE\"> fluid</span><span style=\"background-color: #FFF8F8\"> and</span><span style=\"background-color: #FFF2F2\"> constantly</span><span style=\"background-color: #FFF1F1\"> interesting</span><span style=\"background-color: #FFD3D3\"> film</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF7F7\"> yes</span><span style=\"background-color: #FFF8F8\"> ,</span><span style=\"background-color: #FFEAEA\"> til</span><span style=\"background-color: #FFF7F7\"> sc</span><span style=\"background-color: #FFFBFB\"> ##h</span><span style=\"background-color: #FFF6F6\"> ##weig</span><span style=\"background-color: #FFF0F0\"> ##er</span><span style=\"background-color: #FFEEEE\"> is</span><span style=\"background-color: #FFDFDF\"> worth</span><span style=\"background-color: #FFF7F7\"> it</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFFDFD\"> if</span><span style=\"background-color: #FFFDFD\"> nothing</span><span style=\"background-color: #FFFDFD\"> else</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFEAEA\"> but</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF9F9\"> it</span><span style=\"background-color: #FFFAFA\"> s</span><span style=\"background-color: #FFFBFB\"> a</span><span style=\"background-color: #FFFAFA\"> great</span><span style=\"background-color: #FFF1F1\"> movie</span><span style=\"background-color: #FFEDED\"> even</span><span style=\"background-color: #FFF8F8\"> for</span><span style=\"background-color: #FFF8F8\"> straight</span><span style=\"background-color: #FFF2F2\"> guys</span><span style=\"background-color: #FFFCFC\"> .</span><br><br>[BERT의 Attention을 시각화_7]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFEBEB\"> got</span><span style=\"background-color: #FFE8E8\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> e</span><span style=\"background-color: #FFFEFE\"> ##bay</span><span style=\"background-color: #FFFDFD\"> mainly</span><span style=\"background-color: #FFFEFE\"> because</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFDFD\"> m</span><span style=\"background-color: #FFFEFE\"> gay</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFF5F5\"> love</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF9F9\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFBFB\"> one</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFCFC\"> those</span><span style=\"background-color: #FFFEFE\"> movies</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFDFD\"> watch</span><span style=\"background-color: #FFF7F7\"> it</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> second</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFCFC\"> never</span><span style=\"background-color: #FFFCFC\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFCFC\"> yourself</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFAFA\"> hmm</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFD7D7\"> forgot</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFCFC\"> this</span><span style=\"background-color: #FFECEC\"> boring</span><span style=\"background-color: #FFFDFD\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFDFD\"> ll</span><span style=\"background-color: #FFFEFE\"> go</span><span style=\"background-color: #FFFDFD\"> make</span><span style=\"background-color: #FFFDFD\"> popcorn</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF4F4\"> it</span><span style=\"background-color: #FFFBFB\"> doesn</span><span style=\"background-color: #FFFAFA\"> t</span><span style=\"background-color: #FFFDFD\"> have</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFFDFD\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF8F8\"> it</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFD7D7\"> a</span><span style=\"background-color: #FFE0E0\"> very</span><span style=\"background-color: #FFC5C5\"> fluid</span><span style=\"background-color: #FFF7F7\"> and</span><span style=\"background-color: #FFF3F3\"> constantly</span><span style=\"background-color: #FFD9D9\"> interesting</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF9F9\"> and</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF3F3\"> yes</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFF3F3\"> is</span><span style=\"background-color: #FFEBEB\"> worth</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> if</span><span style=\"background-color: #FFFAFA\"> nothing</span><span style=\"background-color: #FFFEFE\"> else</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFE6E6\"> but</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF8F8\"> it</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFD2D2\"> a</span><span style=\"background-color: #FF0000\"> great</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFF9F9\"> even</span><span style=\"background-color: #FFFCFC\"> for</span><span style=\"background-color: #FFFEFE\"> straight</span><span style=\"background-color: #FFFEFE\"> guys</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_8]<br><span style=\"background-color: #FFFDFD\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> got</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFCFC\"> e</span><span style=\"background-color: #FFFEFE\"> ##bay</span><span style=\"background-color: #FFFEFE\"> mainly</span><span style=\"background-color: #FFFEFE\"> because</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> m</span><span style=\"background-color: #FFFAFA\"> gay</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> love</span><span style=\"background-color: #FFFDFD\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFCFC\"> ##weig</span><span style=\"background-color: #FFFDFD\"> ##er</span><span style=\"background-color: #FF1515\"> .</span><span style=\"background-color: #FFFEFE\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> those</span><span style=\"background-color: #FFFEFE\"> movies</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> watch</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> second</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> never</span><span style=\"background-color: #FFFEFE\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> yourself</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> hmm</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> forgot</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> boring</span><span style=\"background-color: #FFFEFE\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> ll</span><span style=\"background-color: #FFFEFE\"> go</span><span style=\"background-color: #FFFEFE\"> make</span><span style=\"background-color: #FFFEFE\"> popcorn</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> doesn</span><span style=\"background-color: #FFFEFE\"> t</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> part</span><span style=\"background-color: #FF6262\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> very</span><span style=\"background-color: #FFFEFE\"> fluid</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> constantly</span><span style=\"background-color: #FFFEFE\"> interesting</span><span style=\"background-color: #FFFEFE\"> film</span><span style=\"background-color: #FF3E3E\"> .</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> yes</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFDFD\"> sc</span><span style=\"background-color: #FFFCFC\"> ##h</span><span style=\"background-color: #FFFAFA\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> worth</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> if</span><span style=\"background-color: #FFFEFE\"> nothing</span><span style=\"background-color: #FFFEFE\"> else</span><span style=\"background-color: #FF0101\"> .</span><span style=\"background-color: #FFFEFE\"> but</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> great</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFEFE\"> even</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFF3F3\"> straight</span><span style=\"background-color: #FFF8F8\"> guys</span><span style=\"background-color: #FF0000\"> .</span><br><br>[BERT의 Attention을 시각화_9]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFF8F8\"> i</span><span style=\"background-color: #FFF4F4\"> got</span><span style=\"background-color: #FFF4F4\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFDFD\"> from</span><span style=\"background-color: #FFFEFE\"> e</span><span style=\"background-color: #FFFBFB\"> ##bay</span><span style=\"background-color: #FFD7D7\"> mainly</span><span style=\"background-color: #FFF8F8\"> because</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFF6F6\"> m</span><span style=\"background-color: #FFFCFC\"> gay</span><span style=\"background-color: #FFF7F7\"> and</span><span style=\"background-color: #FFF7F7\"> i</span><span style=\"background-color: #FFF9F9\"> love</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFE2E2\"> however</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFAFA\"> s</span><span style=\"background-color: #FFFBFB\"> one</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFF9F9\"> those</span><span style=\"background-color: #FFFEFE\"> movies</span><span style=\"background-color: #FFEFEF\"> that</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> watch</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFDFD\"> second</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFBFB\"> you</span><span style=\"background-color: #FFEBEB\"> never</span><span style=\"background-color: #FFFAFA\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFAFA\"> yourself</span><span style=\"background-color: #FFF6F6\"> ,</span><span style=\"background-color: #FFF1F1\"> hmm</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFF9F9\"> i</span><span style=\"background-color: #FFE9E9\"> forgot</span><span style=\"background-color: #FFF9F9\"> about</span><span style=\"background-color: #FFFAFA\"> this</span><span style=\"background-color: #FFFDFD\"> boring</span><span style=\"background-color: #FFFEFE\"> part</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFFBFB\"> ll</span><span style=\"background-color: #FFFBFB\"> go</span><span style=\"background-color: #FFFCFC\"> make</span><span style=\"background-color: #FFFEFE\"> popcorn</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFD2D2\"> doesn</span><span style=\"background-color: #FFB0B0\"> t</span><span style=\"background-color: #FFDDDD\"> have</span><span style=\"background-color: #FFE0E0\"> that</span><span style=\"background-color: #FFFAFA\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF8F8\"> it</span><span style=\"background-color: #FFD8D8\"> s</span><span style=\"background-color: #FFC6C6\"> a</span><span style=\"background-color: #FF0000\"> very</span><span style=\"background-color: #FFF6F6\"> fluid</span><span style=\"background-color: #FF8484\"> and</span><span style=\"background-color: #FF8181\"> constantly</span><span style=\"background-color: #FFF8F8\"> interesting</span><span style=\"background-color: #FFFEFE\"> film</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFE0E0\"> and</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFE6E6\"> yes</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFF3F3\"> is</span><span style=\"background-color: #FFB7B7\"> worth</span><span style=\"background-color: #FFF4F4\"> it</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFE7E7\"> if</span><span style=\"background-color: #FFE3E3\"> nothing</span><span style=\"background-color: #FFF7F7\"> else</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FF0E0E\"> but</span><span style=\"background-color: #FFF0F0\"> ,</span><span style=\"background-color: #FFF4F4\"> it</span><span style=\"background-color: #FFABAB\"> s</span><span style=\"background-color: #FF6D6D\"> a</span><span style=\"background-color: #FFA0A0\"> great</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFCFCF\"> even</span><span style=\"background-color: #FFF9F9\"> for</span><span style=\"background-color: #FFFDFD\"> straight</span><span style=\"background-color: #FFFEFE\"> guys</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_10]<br><span style=\"background-color: #FFFDFD\"> [CLS]</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFFCFC\"> got</span><span style=\"background-color: #FFFBFB\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> e</span><span style=\"background-color: #FFFEFE\"> ##bay</span><span style=\"background-color: #FFFDFD\"> mainly</span><span style=\"background-color: #FFFEFE\"> because</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> m</span><span style=\"background-color: #FFFEFE\"> gay</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFDFD\"> love</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF9F9\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> those</span><span style=\"background-color: #FFFEFE\"> movies</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> watch</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> second</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> never</span><span style=\"background-color: #FFFEFE\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> yourself</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFDFD\"> hmm</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF9F9\"> i</span><span style=\"background-color: #FF9090\"> forgot</span><span style=\"background-color: #FFFAFA\"> about</span><span style=\"background-color: #FFE9E9\"> this</span><span style=\"background-color: #FFBFBF\"> boring</span><span style=\"background-color: #FFFEFE\"> part</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFF8F8\"> ll</span><span style=\"background-color: #FFFCFC\"> go</span><span style=\"background-color: #FFFEFE\"> make</span><span style=\"background-color: #FFFEFE\"> popcorn</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> doesn</span><span style=\"background-color: #FFFCFC\"> t</span><span style=\"background-color: #FFFDFD\"> have</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> very</span><span style=\"background-color: #FFFEFE\"> fluid</span><span style=\"background-color: #FFF9F9\"> and</span><span style=\"background-color: #FFF1F1\"> constantly</span><span style=\"background-color: #FFFEFE\"> interesting</span><span style=\"background-color: #FFFEFE\"> film</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF6F6\"> and</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFF7F7\"> yes</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFF8F8\"> worth</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> if</span><span style=\"background-color: #FFFDFD\"> nothing</span><span style=\"background-color: #FFFEFE\"> else</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FF0000\"> but</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFCFC\"> great</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFDFD\"> even</span><span style=\"background-color: #FFFCFC\"> for</span><span style=\"background-color: #FFFEFE\"> straight</span><span style=\"background-color: #FFFDFD\"> guys</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_11]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFBEBE\"> got</span><span style=\"background-color: #FFCCCC\"> this</span><span style=\"background-color: #FFFDFD\"> movie</span><span style=\"background-color: #FFFDFD\"> from</span><span style=\"background-color: #FFFEFE\"> e</span><span style=\"background-color: #FFE7E7\"> ##bay</span><span style=\"background-color: #FFDEDE\"> mainly</span><span style=\"background-color: #FFFCFC\"> because</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> m</span><span style=\"background-color: #FFFEFE\"> gay</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFF7F7\"> love</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFDEDE\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFF7F7\"> one</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFFEFE\"> those</span><span style=\"background-color: #FFFEFE\"> movies</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFDFD\"> watch</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFBFB\"> second</span><span style=\"background-color: #FFFCFC\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFDFD\"> never</span><span style=\"background-color: #FFFEFE\"> say</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> yourself</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> hmm</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFAFA\"> i</span><span style=\"background-color: #FFBFBF\"> forgot</span><span style=\"background-color: #FFFDFD\"> about</span><span style=\"background-color: #FFFCFC\"> this</span><span style=\"background-color: #FFEFEF\"> boring</span><span style=\"background-color: #FFF6F6\"> part</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFBFB\"> ll</span><span style=\"background-color: #FFF6F6\"> go</span><span style=\"background-color: #FFF9F9\"> make</span><span style=\"background-color: #FFF6F6\"> popcorn</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFEFEF\"> doesn</span><span style=\"background-color: #FFF0F0\"> t</span><span style=\"background-color: #FFFBFB\"> have</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFF8F8\"> part</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFF8F8\"> a</span><span style=\"background-color: #FFF5F5\"> very</span><span style=\"background-color: #FFC5C5\"> fluid</span><span style=\"background-color: #FFEDED\"> and</span><span style=\"background-color: #FFE3E3\"> constantly</span><span style=\"background-color: #FFE5E5\"> interesting</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF4F4\"> and</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFAFA\"> yes</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFEFE\"> ##h</span><span style=\"background-color: #FFFEFE\"> ##weig</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFD3D3\"> is</span><span style=\"background-color: #FF0000\"> worth</span><span style=\"background-color: #FFC2C2\"> it</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> if</span><span style=\"background-color: #FFCACA\"> nothing</span><span style=\"background-color: #FFFDFD\"> else</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFD0D0\"> but</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFFCFC\"> s</span><span style=\"background-color: #FFF1F1\"> a</span><span style=\"background-color: #FF9C9C\"> great</span><span style=\"background-color: #FFFDFD\"> movie</span><span style=\"background-color: #FFF2F2\"> even</span><span style=\"background-color: #FFD8D8\"> for</span><span style=\"background-color: #FFFEFE\"> straight</span><span style=\"background-color: #FFFEFE\"> guys</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_12]<br><span style=\"background-color: #FFECEC\"> [CLS]</span><span style=\"background-color: #FFB3B3\"> i</span><span style=\"background-color: #FFA9A9\"> got</span><span style=\"background-color: #FF9898\"> this</span><span style=\"background-color: #FFF0F0\"> movie</span><span style=\"background-color: #FFF0F0\"> from</span><span style=\"background-color: #FFFBFB\"> e</span><span style=\"background-color: #FFF0F0\"> ##bay</span><span style=\"background-color: #FFEAEA\"> mainly</span><span style=\"background-color: #FFC3C3\"> because</span><span style=\"background-color: #FFDDDD\"> i</span><span style=\"background-color: #FFDFDF\"> m</span><span style=\"background-color: #FFC6C6\"> gay</span><span style=\"background-color: #FFDBDB\"> and</span><span style=\"background-color: #FFE4E4\"> i</span><span style=\"background-color: #FFBCBC\"> love</span><span style=\"background-color: #FFFEFE\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFCFC\"> ##h</span><span style=\"background-color: #FFFDFD\"> ##weig</span><span style=\"background-color: #FFFCFC\"> ##er</span><span style=\"background-color: #FFC5C5\"> .</span><span style=\"background-color: #FFCCCC\"> however</span><span style=\"background-color: #FFE3E3\"> ,</span><span style=\"background-color: #FFF9F9\"> it</span><span style=\"background-color: #FFF6F6\"> s</span><span style=\"background-color: #FFE8E8\"> one</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFE6E6\"> those</span><span style=\"background-color: #FFE5E5\"> movies</span><span style=\"background-color: #FFDCDC\"> that</span><span style=\"background-color: #FFE4E4\"> ,</span><span style=\"background-color: #FFDADA\"> when</span><span style=\"background-color: #FFD8D8\"> you</span><span style=\"background-color: #FFCACA\"> watch</span><span style=\"background-color: #FFF5F5\"> it</span><span style=\"background-color: #FF9090\"> a</span><span style=\"background-color: #FF9A9A\"> second</span><span style=\"background-color: #FFE3E3\"> time</span><span style=\"background-color: #FFDEDE\"> ,</span><span style=\"background-color: #FFCECE\"> you</span><span style=\"background-color: #FFE1E1\"> never</span><span style=\"background-color: #FFDDDD\"> say</span><span style=\"background-color: #FFDDDD\"> to</span><span style=\"background-color: #FFE5E5\"> yourself</span><span style=\"background-color: #FFF2F2\"> ,</span><span style=\"background-color: #FFF7F7\"> hmm</span><span style=\"background-color: #FFF6F6\"> .</span><span style=\"background-color: #FFE5E5\"> i</span><span style=\"background-color: #FFE2E2\"> forgot</span><span style=\"background-color: #FFEDED\"> about</span><span style=\"background-color: #FFD3D3\"> this</span><span style=\"background-color: #FFC0C0\"> boring</span><span style=\"background-color: #FFD7D7\"> part</span><span style=\"background-color: #FFEEEE\"> .</span><span style=\"background-color: #FFE0E0\"> i</span><span style=\"background-color: #FFB7B7\"> ll</span><span style=\"background-color: #FFDEDE\"> go</span><span style=\"background-color: #FFCBCB\"> make</span><span style=\"background-color: #FFD7D7\"> popcorn</span><span style=\"background-color: #FFE7E7\"> .</span><span style=\"background-color: #FFF2F2\"> it</span><span style=\"background-color: #FFF1F1\"> doesn</span><span style=\"background-color: #FFF0F0\"> t</span><span style=\"background-color: #FFC9C9\"> have</span><span style=\"background-color: #FFC9C9\"> that</span><span style=\"background-color: #FFCCCC\"> part</span><span style=\"background-color: #FFC9C9\"> .</span><span style=\"background-color: #FFF7F7\"> it</span><span style=\"background-color: #FFFCFC\"> s</span><span style=\"background-color: #FFE8E8\"> a</span><span style=\"background-color: #FFF7F7\"> very</span><span style=\"background-color: #FF0505\"> fluid</span><span style=\"background-color: #FFF2F2\"> and</span><span style=\"background-color: #FFD2D2\"> constantly</span><span style=\"background-color: #FF6C6C\"> interesting</span><span style=\"background-color: #FFE2E2\"> film</span><span style=\"background-color: #FFC7C7\"> .</span><span style=\"background-color: #FFE6E6\"> and</span><span style=\"background-color: #FFEEEE\"> ,</span><span style=\"background-color: #FFF8F8\"> yes</span><span style=\"background-color: #FFEDED\"> ,</span><span style=\"background-color: #FFFDFD\"> til</span><span style=\"background-color: #FFFEFE\"> sc</span><span style=\"background-color: #FFFDFD\"> ##h</span><span style=\"background-color: #FFFDFD\"> ##weig</span><span style=\"background-color: #FFFDFD\"> ##er</span><span style=\"background-color: #FFF4F4\"> is</span><span style=\"background-color: #FFE6E6\"> worth</span><span style=\"background-color: #FFE8E8\"> it</span><span style=\"background-color: #FFE2E2\"> ,</span><span style=\"background-color: #FFF2F2\"> if</span><span style=\"background-color: #FFDFDF\"> nothing</span><span style=\"background-color: #FFDCDC\"> else</span><span style=\"background-color: #FFC4C4\"> .</span><span style=\"background-color: #FF9B9B\"> but</span><span style=\"background-color: #FFD7D7\"> ,</span><span style=\"background-color: #FFF1F1\"> it</span><span style=\"background-color: #FFF6F6\"> s</span><span style=\"background-color: #FFD7D7\"> a</span><span style=\"background-color: #FFB4B4\"> great</span><span style=\"background-color: #FFE2E2\"> movie</span><span style=\"background-color: #FFC4C4\"> even</span><span style=\"background-color: #FF9393\"> for</span><span style=\"background-color: #FF0000\"> straight</span><span style=\"background-color: #FF4545\"> guys</span><span style=\"background-color: #FFC3C3\"> .</span><br><br>[BERT의 Attention을 시각화_ALL]<br><span style=\"background-color: #FFE4E4\"> [CLS]</span><span style=\"background-color: #FFDCDC\"> i</span><span style=\"background-color: #FFB5B5\"> got</span><span style=\"background-color: #FF7272\"> this</span><span style=\"background-color: #FFD2D2\"> movie</span><span style=\"background-color: #FFF5F5\"> from</span><span style=\"background-color: #FFF5F5\"> e</span><span style=\"background-color: #FFBEBE\"> ##bay</span><span style=\"background-color: #FFD1D1\"> mainly</span><span style=\"background-color: #FFE0E0\"> because</span><span style=\"background-color: #FFEBEB\"> i</span><span style=\"background-color: #FFEBEB\"> m</span><span style=\"background-color: #FFD5D5\"> gay</span><span style=\"background-color: #FFE9E9\"> and</span><span style=\"background-color: #FFEFEF\"> i</span><span style=\"background-color: #FFBEBE\"> love</span><span style=\"background-color: #FFF2F2\"> til</span><span style=\"background-color: #FFF8F8\"> sc</span><span style=\"background-color: #FFFAFA\"> ##h</span><span style=\"background-color: #FFF9F9\"> ##weig</span><span style=\"background-color: #FFF3F3\"> ##er</span><span style=\"background-color: #FF5A5A\"> .</span><span style=\"background-color: #FFD1D1\"> however</span><span style=\"background-color: #FFF3F3\"> ,</span><span style=\"background-color: #FFD1D1\"> it</span><span style=\"background-color: #FFE9E9\"> s</span><span style=\"background-color: #FFCACA\"> one</span><span style=\"background-color: #FFF4F4\"> of</span><span style=\"background-color: #FFEFEF\"> those</span><span style=\"background-color: #FFCFCF\"> movies</span><span style=\"background-color: #FFE2E2\"> that</span><span style=\"background-color: #FFEEEE\"> ,</span><span style=\"background-color: #FFEEEE\"> when</span><span style=\"background-color: #FFEAEA\"> you</span><span style=\"background-color: #FFCCCC\"> watch</span><span style=\"background-color: #FFC7C7\"> it</span><span style=\"background-color: #FFD6D6\"> a</span><span style=\"background-color: #FFCCCC\"> second</span><span style=\"background-color: #FFE9E9\"> time</span><span style=\"background-color: #FFEFEF\"> ,</span><span style=\"background-color: #FFE2E2\"> you</span><span style=\"background-color: #FFE2E2\"> never</span><span style=\"background-color: #FFD5D5\"> say</span><span style=\"background-color: #FFDCDC\"> to</span><span style=\"background-color: #FFEDED\"> yourself</span><span style=\"background-color: #FFE9E9\"> ,</span><span style=\"background-color: #FFE1E1\"> hmm</span><span style=\"background-color: #FFF4F4\"> .</span><span style=\"background-color: #FFEBEB\"> i</span><span style=\"background-color: #FF6F6F\"> forgot</span><span style=\"background-color: #FFEFEF\"> about</span><span style=\"background-color: #FFAFAF\"> this</span><span style=\"background-color: #FF2929\"> boring</span><span style=\"background-color: #FFC7C7\"> part</span><span style=\"background-color: #FFEEEE\"> .</span><span style=\"background-color: #FFE7E7\"> i</span><span style=\"background-color: #FFD8D8\"> ll</span><span style=\"background-color: #FFD1D1\"> go</span><span style=\"background-color: #FFD7D7\"> make</span><span style=\"background-color: #FF9797\"> popcorn</span><span style=\"background-color: #FFEEEE\"> .</span><span style=\"background-color: #FFE0E0\"> it</span><span style=\"background-color: #FFD8D8\"> doesn</span><span style=\"background-color: #FFD0D0\"> t</span><span style=\"background-color: #FFC3C3\"> have</span><span style=\"background-color: #FFD8D8\"> that</span><span style=\"background-color: #FFD1D1\"> part</span><span style=\"background-color: #FF8282\"> .</span><span style=\"background-color: #FFD2D2\"> it</span><span style=\"background-color: #FFCECE\"> s</span><span style=\"background-color: #FF7575\"> a</span><span style=\"background-color: #FF7E7E\"> very</span><span style=\"background-color: #FF4343\"> fluid</span><span style=\"background-color: #FF6B6B\"> and</span><span style=\"background-color: #FF8686\"> constantly</span><span style=\"background-color: #FF4646\"> interesting</span><span style=\"background-color: #FFC1C1\"> film</span><span style=\"background-color: #FF6E6E\"> .</span><span style=\"background-color: #FFCBCB\"> and</span><span style=\"background-color: #FFF0F0\"> ,</span><span style=\"background-color: #FFE4E4\"> yes</span><span style=\"background-color: #FFEBEB\"> ,</span><span style=\"background-color: #FFE7E7\"> til</span><span style=\"background-color: #FFF3F3\"> sc</span><span style=\"background-color: #FFF9F9\"> ##h</span><span style=\"background-color: #FFF8F8\"> ##weig</span><span style=\"background-color: #FFF2F2\"> ##er</span><span style=\"background-color: #FF9191\"> is</span><span style=\"background-color: #FF1515\"> worth</span><span style=\"background-color: #FFC8C8\"> it</span><span style=\"background-color: #FFEFEF\"> ,</span><span style=\"background-color: #FFEDED\"> if</span><span style=\"background-color: #FFD7D7\"> nothing</span><span style=\"background-color: #FFECEC\"> else</span><span style=\"background-color: #FF5151\"> .</span><span style=\"background-color: #FF1F1F\"> but</span><span style=\"background-color: #FFE0E0\"> ,</span><span style=\"background-color: #FF9292\"> it</span><span style=\"background-color: #FFC2C2\"> s</span><span style=\"background-color: #FF3131\"> a</span><span style=\"background-color: #FF0000\"> great</span><span style=\"background-color: #FFD0D0\"> movie</span><span style=\"background-color: #FFCBCB\"> even</span><span style=\"background-color: #FFBFBF\"> for</span><span style=\"background-color: #FF5D5D\"> straight</span><span style=\"background-color: #FF7D7D\"> guys</span><span style=\"background-color: #FF5050\"> .</span><br><br>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "index = 3 \n",
        "html_output = mk_html(index, batch, preds, attention_probs, TEXT) \n",
        "HTML(html_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "f3MylE8xPINj",
        "outputId": "f533f0ea-4bbc-4460-ba7b-fa8a4381c0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "정답 라벨: Positive<br>추론 라벨: Positive<br><br>[BERT의 Attention을 시각화_1]<br><span style=\"background-color: #FFEEEE\"> [CLS]</span><span style=\"background-color: #FFE4E4\"> this</span><span style=\"background-color: #FFE1E1\"> is</span><span style=\"background-color: #FFEDED\"> the</span><span style=\"background-color: #FFC9C9\"> best</span><span style=\"background-color: #FFFBFB\"> comedy</span><span style=\"background-color: #FFECEC\"> period</span><span style=\"background-color: #FFC3C3\"> .</span><span style=\"background-color: #FFEDED\"> it</span><span style=\"background-color: #FF6969\"> is</span><span style=\"background-color: #FFEAEA\"> so</span><span style=\"background-color: #FFFAFA\"> under</span><span style=\"background-color: #FFEEEE\"> ##rated</span><span style=\"background-color: #FFF9F9\"> clever</span><span style=\"background-color: #FFEDED\"> witty</span><span style=\"background-color: #FFD1D1\"> humor</span><span style=\"background-color: #FFEFEF\"> ,</span><span style=\"background-color: #FFBCBC\"> great</span><span style=\"background-color: #FF0000\"> casting</span><span style=\"background-color: #FFFEFE\"> jerry</span><span style=\"background-color: #FFFEFE\"> still</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFB5B5\"> is</span><span style=\"background-color: #FFF8F8\"> the</span><span style=\"background-color: #FFFBFB\"> jewel</span><span style=\"background-color: #FFF9F9\"> in</span><span style=\"background-color: #FFFBFB\"> the</span><span style=\"background-color: #FFFCFC\"> show</span><span style=\"background-color: #FFF0F0\"> ,</span><span style=\"background-color: #FFFCFC\"> he</span><span style=\"background-color: #FFB9B9\"> is</span><span style=\"background-color: #FFF6F6\"> so</span><span style=\"background-color: #FFFCFC\"> incredibly</span><span style=\"background-color: #FFE6E6\"> funny</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFFDFD\"> qui</span><span style=\"background-color: #FFF9F9\"> ##rky</span><span style=\"background-color: #FFF6F6\"> ,</span><span style=\"background-color: #FFE9E9\"> simply</span><span style=\"background-color: #FFF3F3\"> a</span><span style=\"background-color: #FFEAEA\"> comical</span><span style=\"background-color: #FFDBDB\"> genius</span><span style=\"background-color: #FFFEFE\"> doug</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFEFE\"> carrie</span><span style=\"background-color: #FFEFEF\"> have</span><span style=\"background-color: #FFF2F2\"> great</span><span style=\"background-color: #FF3939\"> chemistry</span><span style=\"background-color: #FFFAFA\"> i</span><span style=\"background-color: #FFFBFB\"> so</span><span style=\"background-color: #FFCCCC\"> do</span><span style=\"background-color: #FFF4F4\"> not</span><span style=\"background-color: #FFCECE\"> see</span><span style=\"background-color: #FFF2F2\"> what</span><span style=\"background-color: #FFF8F8\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFCFC\"> ##ype</span><span style=\"background-color: #FFE5E5\"> is</span><span style=\"background-color: #FFFCFC\"> about</span><span style=\"background-color: #FFFBFB\"> when</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFE2E2\"> comes</span><span style=\"background-color: #FFFAFA\"> to</span><span style=\"background-color: #FFFCFC\"> everybody</span><span style=\"background-color: #FFFDFD\"> loves</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FF8B8B\"> is</span><span style=\"background-color: #FFF8F8\"> so</span><span style=\"background-color: #FFFCFC\"> over</span><span style=\"background-color: #FFE1E1\"> ##rated</span><span style=\"background-color: #FFF2F2\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFF6F6\"> jokes</span><span style=\"background-color: #FFF8F8\"> mostly</span><span style=\"background-color: #FFFDFD\"> forced</span><span style=\"background-color: #FFD6D6\"> humor</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFDFDF\"> just</span><span style=\"background-color: #FFF1F1\"> not</span><span style=\"background-color: #FFD6D6\"> the</span><span style=\"background-color: #FFB2B2\"> witty</span><span style=\"background-color: #FFC4C4\"> show</span><span style=\"background-color: #FFF1F1\"> ,</span><span style=\"background-color: #FFFAFA\"> i</span><span style=\"background-color: #FFF0F0\"> can</span><span style=\"background-color: #FFF7F7\"> t</span><span style=\"background-color: #FFF1F1\"> remember</span><span style=\"background-color: #FFBFBF\"> laughing</span><span style=\"background-color: #FFF5F5\"> in</span><span style=\"background-color: #FFF8F8\"> more</span><span style=\"background-color: #FFFBFB\"> than</span><span style=\"background-color: #FFF6F6\"> 1</span><span style=\"background-color: #FFFAFA\"> episode</span><span style=\"background-color: #FFC1C1\"> .</span><span style=\"background-color: #FFFEFE\"> king</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> queens</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFF9F9\"> a</span><span style=\"background-color: #FFFBFB\"> rare</span><span style=\"background-color: #FFF8F8\"> comedy</span><span style=\"background-color: #FFF0F0\"> that</span><span style=\"background-color: #FFF1F1\"> has</span><span style=\"background-color: #FFF6F6\"> all</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFE9E9\"> right</span><span style=\"background-color: #FFBDBD\"> ingredients</span><span style=\"background-color: #FFF5F5\"> to</span><span style=\"background-color: #FFFBFB\"> give</span><span style=\"background-color: #FFF5F5\"> you</span><span style=\"background-color: #FFF7F7\"> serious</span><span style=\"background-color: #FFFDFD\"> belly</span><span style=\"background-color: #FFFAFA\"> laughs</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFF0F0\"> caused</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFEFE\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFFAFA\"> i</span><span style=\"background-color: #FFDFDF\"> think</span><span style=\"background-color: #FFFBFB\"> its</span><span style=\"background-color: #FFE4E4\"> about</span><span style=\"background-color: #FFE5E5\"> time</span><span style=\"background-color: #FFE9E9\"> this</span><span style=\"background-color: #FFF0F0\"> comedy</span><span style=\"background-color: #FFA5A5\"> gets</span><span style=\"background-color: #FFF2F2\"> the</span><span style=\"background-color: #FFDFDF\"> h</span><span style=\"background-color: #FF7D7D\"> ##ype</span><span style=\"background-color: #FFEBEB\"> it</span><span style=\"background-color: #FFE7E7\"> deserves</span><span style=\"background-color: #FFF6F6\"> and</span><span style=\"background-color: #FFE2E2\"> not</span><span style=\"background-color: #FFEAEA\"> the</span><span style=\"background-color: #FFEAEA\"> lame</span><span style=\"background-color: #FFF9F9\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_2]<br><span style=\"background-color: #FF7171\"> [CLS]</span><span style=\"background-color: #FFFAFA\"> this</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFF6F6\"> the</span><span style=\"background-color: #FFFAFA\"> best</span><span style=\"background-color: #FFC1C1\"> comedy</span><span style=\"background-color: #FFE5E5\"> period</span><span style=\"background-color: #FF1010\"> .</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFDFD\"> under</span><span style=\"background-color: #FFFEFE\"> ##rated</span><span style=\"background-color: #FFFEFE\"> clever</span><span style=\"background-color: #FFFAFA\"> witty</span><span style=\"background-color: #FFF5F5\"> humor</span><span style=\"background-color: #FFF4F4\"> ,</span><span style=\"background-color: #FFFCFC\"> great</span><span style=\"background-color: #FFD8D8\"> casting</span><span style=\"background-color: #FFF9F9\"> jerry</span><span style=\"background-color: #FFF5F5\"> still</span><span style=\"background-color: #FFF9F9\"> ##er</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFAFA\"> the</span><span style=\"background-color: #FFF4F4\"> jewel</span><span style=\"background-color: #FFF1F1\"> in</span><span style=\"background-color: #FFF2F2\"> the</span><span style=\"background-color: #FFA8A8\"> show</span><span style=\"background-color: #FFF5F5\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFDFD\"> incredibly</span><span style=\"background-color: #FFF5F5\"> funny</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFEFE\"> ##rky</span><span style=\"background-color: #FFF4F4\"> ,</span><span style=\"background-color: #FFFBFB\"> simply</span><span style=\"background-color: #FFFCFC\"> a</span><span style=\"background-color: #FFF1F1\"> comical</span><span style=\"background-color: #FFFAFA\"> genius</span><span style=\"background-color: #FFF1F1\"> doug</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFEEEE\"> carrie</span><span style=\"background-color: #FFFBFB\"> have</span><span style=\"background-color: #FFFEFE\"> great</span><span style=\"background-color: #FFEFEF\"> chemistry</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFCFC\"> do</span><span style=\"background-color: #FFFDFD\"> not</span><span style=\"background-color: #FFFBFB\"> see</span><span style=\"background-color: #FFFDFD\"> what</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFDFD\"> ##ype</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFDFD\"> about</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFAFA\"> it</span><span style=\"background-color: #FFFCFC\"> comes</span><span style=\"background-color: #FFDDDD\"> to</span><span style=\"background-color: #FFDADA\"> everybody</span><span style=\"background-color: #FFF7F7\"> loves</span><span style=\"background-color: #FFFAFA\"> raymond</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFEFE\"> ##rated</span><span style=\"background-color: #FFFDFD\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFBFB\"> jokes</span><span style=\"background-color: #FFFAFA\"> mostly</span><span style=\"background-color: #FFF3F3\"> forced</span><span style=\"background-color: #FFF8F8\"> humor</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFFDFD\"> just</span><span style=\"background-color: #FFFCFC\"> not</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFF0F0\"> witty</span><span style=\"background-color: #FFCDCD\"> show</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFEFE\"> can</span><span style=\"background-color: #FFFEFE\"> t</span><span style=\"background-color: #FFFAFA\"> remember</span><span style=\"background-color: #FFF2F2\"> laughing</span><span style=\"background-color: #FFFCFC\"> in</span><span style=\"background-color: #FFFEFE\"> more</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFAFA\"> 1</span><span style=\"background-color: #FFC6C6\"> episode</span><span style=\"background-color: #FF0101\"> .</span><span style=\"background-color: #FFCECE\"> king</span><span style=\"background-color: #FF5959\"> of</span><span style=\"background-color: #FFE7E7\"> queens</span><span style=\"background-color: #FFF5F5\"> is</span><span style=\"background-color: #FFF4F4\"> a</span><span style=\"background-color: #FFB7B7\"> rare</span><span style=\"background-color: #FF3939\"> comedy</span><span style=\"background-color: #FFF1F1\"> that</span><span style=\"background-color: #FFE9E9\"> has</span><span style=\"background-color: #FFEAEA\"> all</span><span style=\"background-color: #FFEAEA\"> the</span><span style=\"background-color: #FFCDCD\"> right</span><span style=\"background-color: #FFCACA\"> ingredients</span><span style=\"background-color: #FFE6E6\"> to</span><span style=\"background-color: #FFE7E7\"> give</span><span style=\"background-color: #FFDADA\"> you</span><span style=\"background-color: #FFD2D2\"> serious</span><span style=\"background-color: #FFE5E5\"> belly</span><span style=\"background-color: #FFDCDC\"> laughs</span><span style=\"background-color: #FFEAEA\"> which</span><span style=\"background-color: #FFF9F9\"> is</span><span style=\"background-color: #FFF8F8\"> normally</span><span style=\"background-color: #FFF4F4\"> caused</span><span style=\"background-color: #FFDADA\"> by</span><span style=\"background-color: #FFECEC\"> arthur</span><span style=\"background-color: #FFFCFC\"> spoon</span><span style=\"background-color: #FFE9E9\"> ##er</span><span style=\"background-color: #FF9090\"> ,</span><span style=\"background-color: #FFEFEF\"> i</span><span style=\"background-color: #FFF9F9\"> think</span><span style=\"background-color: #FFF8F8\"> its</span><span style=\"background-color: #FFDFDF\"> about</span><span style=\"background-color: #FFF0F0\"> time</span><span style=\"background-color: #FFE7E7\"> this</span><span style=\"background-color: #FF4141\"> comedy</span><span style=\"background-color: #FFE7E7\"> gets</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFF7F7\"> h</span><span style=\"background-color: #FFF6F6\"> ##ype</span><span style=\"background-color: #FFF6F6\"> it</span><span style=\"background-color: #FFFCFC\"> deserves</span><span style=\"background-color: #FFF0F0\"> and</span><span style=\"background-color: #FFEFEF\"> not</span><span style=\"background-color: #FFF3F3\"> the</span><span style=\"background-color: #FFF9F9\"> lame</span><span style=\"background-color: #FFCDCD\"> raymond</span><span style=\"background-color: #FFF8F8\"> co</span><span style=\"background-color: #FFF6F6\"> .</span><br><br>[BERT의 Attention을 시각화_3]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFCFCF\"> this</span><span style=\"background-color: #FFE1E1\"> is</span><span style=\"background-color: #FFE1E1\"> the</span><span style=\"background-color: #FFEBEB\"> best</span><span style=\"background-color: #FFF1F1\"> comedy</span><span style=\"background-color: #FFFAFA\"> period</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF0F0\"> it</span><span style=\"background-color: #FFD5D5\"> is</span><span style=\"background-color: #FFF3F3\"> so</span><span style=\"background-color: #FFFBFB\"> under</span><span style=\"background-color: #FFFAFA\"> ##rated</span><span style=\"background-color: #FFF3F3\"> clever</span><span style=\"background-color: #FFF6F6\"> witty</span><span style=\"background-color: #FFF1F1\"> humor</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFE0E0\"> great</span><span style=\"background-color: #FFFCFC\"> casting</span><span style=\"background-color: #FFFDFD\"> jerry</span><span style=\"background-color: #FFFEFE\"> still</span><span style=\"background-color: #FFFCFC\"> ##er</span><span style=\"background-color: #FFF4F4\"> is</span><span style=\"background-color: #FFEEEE\"> the</span><span style=\"background-color: #FFFBFB\"> jewel</span><span style=\"background-color: #FFFBFB\"> in</span><span style=\"background-color: #FFDEDE\"> the</span><span style=\"background-color: #FFEDED\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> he</span><span style=\"background-color: #FFEBEB\"> is</span><span style=\"background-color: #FFF6F6\"> so</span><span style=\"background-color: #FFEBEB\"> incredibly</span><span style=\"background-color: #FFF6F6\"> funny</span><span style=\"background-color: #FFE8E8\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFCFC\"> ##rky</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFEDED\"> simply</span><span style=\"background-color: #FFE1E1\"> a</span><span style=\"background-color: #FFF8F8\"> comical</span><span style=\"background-color: #FFFEFE\"> genius</span><span style=\"background-color: #FFFEFE\"> doug</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFDFD\"> carrie</span><span style=\"background-color: #FFECEC\"> have</span><span style=\"background-color: #FFF8F8\"> great</span><span style=\"background-color: #FFF7F7\"> chemistry</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFFDFD\"> so</span><span style=\"background-color: #FFFBFB\"> do</span><span style=\"background-color: #FFFDFD\"> not</span><span style=\"background-color: #FFFBFB\"> see</span><span style=\"background-color: #FFF5F5\"> what</span><span style=\"background-color: #FFF9F9\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFCFC\"> ##ype</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFF6F6\"> about</span><span style=\"background-color: #FFFCFC\"> when</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFCFC\"> to</span><span style=\"background-color: #FFFCFC\"> everybody</span><span style=\"background-color: #FFFDFD\"> loves</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFAFA\"> it</span><span style=\"background-color: #FFF5F5\"> is</span><span style=\"background-color: #FFFCFC\"> so</span><span style=\"background-color: #FFFDFD\"> over</span><span style=\"background-color: #FFF6F6\"> ##rated</span><span style=\"background-color: #FFEEEE\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFBFB\"> jokes</span><span style=\"background-color: #FFF7F7\"> mostly</span><span style=\"background-color: #FFFAFA\"> forced</span><span style=\"background-color: #FFFAFA\"> humor</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFCFC\"> just</span><span style=\"background-color: #FFFBFB\"> not</span><span style=\"background-color: #FFF1F1\"> the</span><span style=\"background-color: #FFF4F4\"> witty</span><span style=\"background-color: #FFF2F2\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF5F5\"> i</span><span style=\"background-color: #FFFEFE\"> can</span><span style=\"background-color: #FFFEFE\"> t</span><span style=\"background-color: #FFFEFE\"> remember</span><span style=\"background-color: #FFF4F4\"> laughing</span><span style=\"background-color: #FFFBFB\"> in</span><span style=\"background-color: #FFFDFD\"> more</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFDFD\"> 1</span><span style=\"background-color: #FFFDFD\"> episode</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> king</span><span style=\"background-color: #FFFAFA\"> of</span><span style=\"background-color: #FFFEFE\"> queens</span><span style=\"background-color: #FFF5F5\"> is</span><span style=\"background-color: #FFCCCC\"> a</span><span style=\"background-color: #FFF4F4\"> rare</span><span style=\"background-color: #FFF0F0\"> comedy</span><span style=\"background-color: #FFF7F7\"> that</span><span style=\"background-color: #FFEEEE\"> has</span><span style=\"background-color: #FFFDFD\"> all</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFFDFD\"> right</span><span style=\"background-color: #FFFDFD\"> ingredients</span><span style=\"background-color: #FFFCFC\"> to</span><span style=\"background-color: #FFF9F9\"> give</span><span style=\"background-color: #FFFDFD\"> you</span><span style=\"background-color: #FFE0E0\"> serious</span><span style=\"background-color: #FFFCFC\"> belly</span><span style=\"background-color: #FFF2F2\"> laughs</span><span style=\"background-color: #FFFDFD\"> which</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFF9F9\"> caused</span><span style=\"background-color: #FFFBFB\"> by</span><span style=\"background-color: #FFFEFE\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF9F9\"> i</span><span style=\"background-color: #FFFDFD\"> think</span><span style=\"background-color: #FFFDFD\"> its</span><span style=\"background-color: #FFF4F4\"> about</span><span style=\"background-color: #FFFAFA\"> time</span><span style=\"background-color: #FF0000\"> this</span><span style=\"background-color: #FFF0F0\"> comedy</span><span style=\"background-color: #FFF9F9\"> gets</span><span style=\"background-color: #FFF8F8\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFAFA\"> it</span><span style=\"background-color: #FFFDFD\"> deserves</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFBFB\"> not</span><span style=\"background-color: #FFF5F5\"> the</span><span style=\"background-color: #FFFDFD\"> lame</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFDFD\"> .</span><br><br>[BERT의 Attention을 시각화_4]<br><span style=\"background-color: #FFFBFB\"> [CLS]</span><span style=\"background-color: #FFC7C7\"> this</span><span style=\"background-color: #FFB3B3\"> is</span><span style=\"background-color: #FF9F9F\"> the</span><span style=\"background-color: #FFD2D2\"> best</span><span style=\"background-color: #FFCDCD\"> comedy</span><span style=\"background-color: #FFF3F3\"> period</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FF3939\"> it</span><span style=\"background-color: #FFC2C2\"> is</span><span style=\"background-color: #FFF4F4\"> so</span><span style=\"background-color: #FFFEFE\"> under</span><span style=\"background-color: #FFFCFC\"> ##rated</span><span style=\"background-color: #FFFAFA\"> clever</span><span style=\"background-color: #FFFCFC\"> witty</span><span style=\"background-color: #FFDDDD\"> humor</span><span style=\"background-color: #FFF6F6\"> ,</span><span style=\"background-color: #FFEBEB\"> great</span><span style=\"background-color: #FFF9F9\"> casting</span><span style=\"background-color: #FFFDFD\"> jerry</span><span style=\"background-color: #FFFDFD\"> still</span><span style=\"background-color: #FFFCFC\"> ##er</span><span style=\"background-color: #FFE1E1\"> is</span><span style=\"background-color: #FFE3E3\"> the</span><span style=\"background-color: #FFFBFB\"> jewel</span><span style=\"background-color: #FFF7F7\"> in</span><span style=\"background-color: #FFC1C1\"> the</span><span style=\"background-color: #FFBCBC\"> show</span><span style=\"background-color: #FFF4F4\"> ,</span><span style=\"background-color: #FFEEEE\"> he</span><span style=\"background-color: #FFD1D1\"> is</span><span style=\"background-color: #FFF2F2\"> so</span><span style=\"background-color: #FFFBFB\"> incredibly</span><span style=\"background-color: #FFD6D6\"> funny</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFDFD\"> qui</span><span style=\"background-color: #FFFAFA\"> ##rky</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFF8F8\"> simply</span><span style=\"background-color: #FFEEEE\"> a</span><span style=\"background-color: #FFF7F7\"> comical</span><span style=\"background-color: #FFFCFC\"> genius</span><span style=\"background-color: #FFFDFD\"> doug</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> carrie</span><span style=\"background-color: #FFFCFC\"> have</span><span style=\"background-color: #FFFCFC\"> great</span><span style=\"background-color: #FFFAFA\"> chemistry</span><span style=\"background-color: #FFF5F5\"> i</span><span style=\"background-color: #FFF6F6\"> so</span><span style=\"background-color: #FFF0F0\"> do</span><span style=\"background-color: #FFF9F9\"> not</span><span style=\"background-color: #FFFCFC\"> see</span><span style=\"background-color: #FFFBFB\"> what</span><span style=\"background-color: #FFF9F9\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFDFD\"> ##ype</span><span style=\"background-color: #FFF6F6\"> is</span><span style=\"background-color: #FFF9F9\"> about</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFDFD\"> to</span><span style=\"background-color: #FFFEFE\"> everybody</span><span style=\"background-color: #FFF1F1\"> loves</span><span style=\"background-color: #FFF2F2\"> raymond</span><span style=\"background-color: #FFC8C8\"> it</span><span style=\"background-color: #FFD7D7\"> is</span><span style=\"background-color: #FFFCFC\"> so</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFDFD\"> ##rated</span><span style=\"background-color: #FFFCFC\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFF9F9\"> jokes</span><span style=\"background-color: #FFFEFE\"> mostly</span><span style=\"background-color: #FFFEFE\"> forced</span><span style=\"background-color: #FFFAFA\"> humor</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFF7F7\"> just</span><span style=\"background-color: #FFF9F9\"> not</span><span style=\"background-color: #FFE5E5\"> the</span><span style=\"background-color: #FFFAFA\"> witty</span><span style=\"background-color: #FFE5E5\"> show</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFF7F7\"> i</span><span style=\"background-color: #FFF8F8\"> can</span><span style=\"background-color: #FFF9F9\"> t</span><span style=\"background-color: #FFFAFA\"> remember</span><span style=\"background-color: #FFDFDF\"> laughing</span><span style=\"background-color: #FFF2F2\"> in</span><span style=\"background-color: #FFFDFD\"> more</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFDFD\"> 1</span><span style=\"background-color: #FFF6F6\"> episode</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF4F4\"> king</span><span style=\"background-color: #FFD7D7\"> of</span><span style=\"background-color: #FFFCFC\"> queens</span><span style=\"background-color: #FF7070\"> is</span><span style=\"background-color: #FF0000\"> a</span><span style=\"background-color: #FFFBFB\"> rare</span><span style=\"background-color: #FFE5E5\"> comedy</span><span style=\"background-color: #FFDADA\"> that</span><span style=\"background-color: #FFFAFA\"> has</span><span style=\"background-color: #FFF8F8\"> all</span><span style=\"background-color: #FFF0F0\"> the</span><span style=\"background-color: #FFFCFC\"> right</span><span style=\"background-color: #FFFDFD\"> ingredients</span><span style=\"background-color: #FFFDFD\"> to</span><span style=\"background-color: #FFFEFE\"> give</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFDFD\"> serious</span><span style=\"background-color: #FFFDFD\"> belly</span><span style=\"background-color: #FFF4F4\"> laughs</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFFDFD\"> caused</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFDFD\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFDFD\"> ##er</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFFBFB\"> think</span><span style=\"background-color: #FFFBFB\"> its</span><span style=\"background-color: #FFFCFC\"> about</span><span style=\"background-color: #FFFDFD\"> time</span><span style=\"background-color: #FFEAEA\"> this</span><span style=\"background-color: #FFE9E9\"> comedy</span><span style=\"background-color: #FFFEFE\"> gets</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFEEEE\"> it</span><span style=\"background-color: #FFFEFE\"> deserves</span><span style=\"background-color: #FFF9F9\"> and</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFF7F7\"> raymond</span><span style=\"background-color: #FFF9F9\"> co</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_5]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFCFC\"> this</span><span style=\"background-color: #FFF8F8\"> is</span><span style=\"background-color: #FFFAFA\"> the</span><span style=\"background-color: #FF0000\"> best</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFDFD\"> period</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFF3F3\"> is</span><span style=\"background-color: #FFE4E4\"> so</span><span style=\"background-color: #FFFEFE\"> under</span><span style=\"background-color: #FFFDFD\"> ##rated</span><span style=\"background-color: #FFFDFD\"> clever</span><span style=\"background-color: #FFFEFE\"> witty</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF4F4\"> great</span><span style=\"background-color: #FFFEFE\"> casting</span><span style=\"background-color: #FFFEFE\"> jerry</span><span style=\"background-color: #FFFEFE\"> still</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> jewel</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFF7F7\"> so</span><span style=\"background-color: #FFF7F7\"> incredibly</span><span style=\"background-color: #FFFEFE\"> funny</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFEFE\"> ##rky</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> simply</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> comical</span><span style=\"background-color: #FFFEFE\"> genius</span><span style=\"background-color: #FFFEFE\"> doug</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> carrie</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFDFD\"> great</span><span style=\"background-color: #FFFEFE\"> chemistry</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFF8F8\"> so</span><span style=\"background-color: #FFFEFE\"> do</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> see</span><span style=\"background-color: #FFFEFE\"> what</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> everybody</span><span style=\"background-color: #FFFEFE\"> loves</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFF1F1\"> is</span><span style=\"background-color: #FFF8F8\"> so</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFF4F4\"> ##rated</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFEFE\"> jokes</span><span style=\"background-color: #FFFCFC\"> mostly</span><span style=\"background-color: #FFFCFC\"> forced</span><span style=\"background-color: #FFFDFD\"> humor</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF6F6\"> just</span><span style=\"background-color: #FFFAFA\"> not</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> witty</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> can</span><span style=\"background-color: #FFFDFD\"> t</span><span style=\"background-color: #FFFEFE\"> remember</span><span style=\"background-color: #FFFCFC\"> laughing</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> more</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFEFE\"> 1</span><span style=\"background-color: #FFFEFE\"> episode</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> king</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> queens</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> rare</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> has</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> right</span><span style=\"background-color: #FFFEFE\"> ingredients</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> give</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> serious</span><span style=\"background-color: #FFFEFE\"> belly</span><span style=\"background-color: #FFFEFE\"> laughs</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFFEFE\"> caused</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> think</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> gets</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> deserves</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_6]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFEBEB\"> this</span><span style=\"background-color: #FFF9F9\"> is</span><span style=\"background-color: #FFF2F2\"> the</span><span style=\"background-color: #FFEBEB\"> best</span><span style=\"background-color: #FF9393\"> comedy</span><span style=\"background-color: #FFCECE\"> period</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFF8F8\"> it</span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFDFD\"> under</span><span style=\"background-color: #FFFAFA\"> ##rated</span><span style=\"background-color: #FFF8F8\"> clever</span><span style=\"background-color: #FFF4F4\"> witty</span><span style=\"background-color: #FFA4A4\"> humor</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFEFE\"> great</span><span style=\"background-color: #FFEFEF\"> casting</span><span style=\"background-color: #FFF5F5\"> jerry</span><span style=\"background-color: #FFFBFB\"> still</span><span style=\"background-color: #FFDEDE\"> ##er</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFFCFC\"> jewel</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFF3F3\"> the</span><span style=\"background-color: #FF8989\"> show</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFFDFD\"> so</span><span style=\"background-color: #FFFBFB\"> incredibly</span><span style=\"background-color: #FFF9F9\"> funny</span><span style=\"background-color: #FFF9F9\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFAFA\"> ##rky</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFBFB\"> simply</span><span style=\"background-color: #FFFAFA\"> a</span><span style=\"background-color: #FFECEC\"> comical</span><span style=\"background-color: #FFDDDD\"> genius</span><span style=\"background-color: #FFF6F6\"> doug</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFF8F8\"> carrie</span><span style=\"background-color: #FFFDFD\"> have</span><span style=\"background-color: #FFFDFD\"> great</span><span style=\"background-color: #FFE3E3\"> chemistry</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFF3F3\"> so</span><span style=\"background-color: #FFFDFD\"> do</span><span style=\"background-color: #FFF8F8\"> not</span><span style=\"background-color: #FFFDFD\"> see</span><span style=\"background-color: #FFFDFD\"> what</span><span style=\"background-color: #FFF1F1\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFCFC\"> ##ype</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFCFC\"> when</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFDFD\"> comes</span><span style=\"background-color: #FFEFEF\"> to</span><span style=\"background-color: #FFF3F3\"> everybody</span><span style=\"background-color: #FFF9F9\"> loves</span><span style=\"background-color: #FFF4F4\"> raymond</span><span style=\"background-color: #FFF9F9\"> it</span><span style=\"background-color: #FFF8F8\"> is</span><span style=\"background-color: #FFFDFD\"> so</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFCFC\"> ##rated</span><span style=\"background-color: #FFF7F7\"> with</span><span style=\"background-color: #FFFDFD\"> lame</span><span style=\"background-color: #FFF0F0\"> jokes</span><span style=\"background-color: #FFF8F8\"> mostly</span><span style=\"background-color: #FFE8E8\"> forced</span><span style=\"background-color: #FFCFCF\"> humor</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFDFD\"> just</span><span style=\"background-color: #FFFCFC\"> not</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFF2F2\"> witty</span><span style=\"background-color: #FF0000\"> show</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFDFD\"> can</span><span style=\"background-color: #FFFAFA\"> t</span><span style=\"background-color: #FFF6F6\"> remember</span><span style=\"background-color: #FFC9C9\"> laughing</span><span style=\"background-color: #FFF3F3\"> in</span><span style=\"background-color: #FFF1F1\"> more</span><span style=\"background-color: #FFF9F9\"> than</span><span style=\"background-color: #FFFDFD\"> 1</span><span style=\"background-color: #FFA5A5\"> episode</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> king</span><span style=\"background-color: #FFFAFA\"> of</span><span style=\"background-color: #FFFDFD\"> queens</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFF9F9\"> a</span><span style=\"background-color: #FFFCFC\"> rare</span><span style=\"background-color: #FFDADA\"> comedy</span><span style=\"background-color: #FFF5F5\"> that</span><span style=\"background-color: #FFF8F8\"> has</span><span style=\"background-color: #FFFCFC\"> all</span><span style=\"background-color: #FFF9F9\"> the</span><span style=\"background-color: #FFFDFD\"> right</span><span style=\"background-color: #FFDEDE\"> ingredients</span><span style=\"background-color: #FFF8F8\"> to</span><span style=\"background-color: #FFFEFE\"> give</span><span style=\"background-color: #FFFAFA\"> you</span><span style=\"background-color: #FFFCFC\"> serious</span><span style=\"background-color: #FFFAFA\"> belly</span><span style=\"background-color: #FFF9F9\"> laughs</span><span style=\"background-color: #FFFCFC\"> which</span><span style=\"background-color: #FFFCFC\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFFCFC\"> caused</span><span style=\"background-color: #FFF8F8\"> by</span><span style=\"background-color: #FFFCFC\"> arthur</span><span style=\"background-color: #FFFDFD\"> spoon</span><span style=\"background-color: #FFF2F2\"> ##er</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> think</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFDFD\"> about</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFE6E6\"> comedy</span><span style=\"background-color: #FFFEFE\"> gets</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFEFE\"> deserves</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFDFD\"> not</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFDFD\"> lame</span><span style=\"background-color: #FFFAFA\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_7]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFE9E9\"> this</span><span style=\"background-color: #FFE0E0\"> is</span><span style=\"background-color: #FFEEEE\"> the</span><span style=\"background-color: #FF8686\"> best</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> period</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFECEC\"> it</span><span style=\"background-color: #FFADAD\"> is</span><span style=\"background-color: #FF0000\"> so</span><span style=\"background-color: #FFF4F4\"> under</span><span style=\"background-color: #FFEBEB\"> ##rated</span><span style=\"background-color: #FFF3F3\"> clever</span><span style=\"background-color: #FFF0F0\"> witty</span><span style=\"background-color: #FFFBFB\"> humor</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FF3D3D\"> great</span><span style=\"background-color: #FFFAFA\"> casting</span><span style=\"background-color: #FFFEFE\"> jerry</span><span style=\"background-color: #FFFEFE\"> still</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFEAEA\"> is</span><span style=\"background-color: #FFF8F8\"> the</span><span style=\"background-color: #FFFCFC\"> jewel</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFBFB\"> the</span><span style=\"background-color: #FFFDFD\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> he</span><span style=\"background-color: #FFD6D6\"> is</span><span style=\"background-color: #FF7777\"> so</span><span style=\"background-color: #FFDBDB\"> incredibly</span><span style=\"background-color: #FFE3E3\"> funny</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFFDFD\"> qui</span><span style=\"background-color: #FFEFEF\"> ##rky</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFCBCB\"> simply</span><span style=\"background-color: #FFFAFA\"> a</span><span style=\"background-color: #FFFEFE\"> comical</span><span style=\"background-color: #FFFDFD\"> genius</span><span style=\"background-color: #FFFEFE\"> doug</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> carrie</span><span style=\"background-color: #FFF1F1\"> have</span><span style=\"background-color: #FFC9C9\"> great</span><span style=\"background-color: #FFF5F5\"> chemistry</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFEDED\"> so</span><span style=\"background-color: #FFD4D4\"> do</span><span style=\"background-color: #FFE7E7\"> not</span><span style=\"background-color: #FFF9F9\"> see</span><span style=\"background-color: #FFFCFC\"> what</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> everybody</span><span style=\"background-color: #FFFCFC\"> loves</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFDADA\"> is</span><span style=\"background-color: #FFD7D7\"> so</span><span style=\"background-color: #FFFBFB\"> over</span><span style=\"background-color: #FF9C9C\"> ##rated</span><span style=\"background-color: #FFEEEE\"> with</span><span style=\"background-color: #FFFBFB\"> lame</span><span style=\"background-color: #FFFDFD\"> jokes</span><span style=\"background-color: #FFF9F9\"> mostly</span><span style=\"background-color: #FFF8F8\"> forced</span><span style=\"background-color: #FFF5F5\"> humor</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFDFDF\"> just</span><span style=\"background-color: #FFEAEA\"> not</span><span style=\"background-color: #FFF5F5\"> the</span><span style=\"background-color: #FFE7E7\"> witty</span><span style=\"background-color: #FFFCFC\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> i</span><span style=\"background-color: #FFF5F5\"> can</span><span style=\"background-color: #FFF7F7\"> t</span><span style=\"background-color: #FFFBFB\"> remember</span><span style=\"background-color: #FFF7F7\"> laughing</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFDFD\"> more</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFEFE\"> 1</span><span style=\"background-color: #FFFEFE\"> episode</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> king</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> queens</span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFEDED\"> a</span><span style=\"background-color: #FFF2F2\"> rare</span><span style=\"background-color: #FFFDFD\"> comedy</span><span style=\"background-color: #FFFAFA\"> that</span><span style=\"background-color: #FFFBFB\"> has</span><span style=\"background-color: #FFFCFC\"> all</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFFCFC\"> right</span><span style=\"background-color: #FFFEFE\"> ingredients</span><span style=\"background-color: #FFFBFB\"> to</span><span style=\"background-color: #FFFBFB\"> give</span><span style=\"background-color: #FFFDFD\"> you</span><span style=\"background-color: #FFF0F0\"> serious</span><span style=\"background-color: #FFFDFD\"> belly</span><span style=\"background-color: #FFFCFC\"> laughs</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFDFD\"> normally</span><span style=\"background-color: #FFF5F5\"> caused</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFEFE\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFF6F6\"> think</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFDFD\"> about</span><span style=\"background-color: #FFFBFB\"> time</span><span style=\"background-color: #FFEBEB\"> this</span><span style=\"background-color: #FFFBFB\"> comedy</span><span style=\"background-color: #FFF7F7\"> gets</span><span style=\"background-color: #FFF8F8\"> the</span><span style=\"background-color: #FFFDFD\"> h</span><span style=\"background-color: #FFFDFD\"> ##ype</span><span style=\"background-color: #FFFBFB\"> it</span><span style=\"background-color: #FFF9F9\"> deserves</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFF5F5\"> not</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFF3F3\"> lame</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_8]<br><span style=\"background-color: #FFF6F6\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> best</span><span style=\"background-color: #FFFDFD\"> comedy</span><span style=\"background-color: #FFFDFD\"> period</span><span style=\"background-color: #FF1111\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> under</span><span style=\"background-color: #FFFEFE\"> ##rated</span><span style=\"background-color: #FFFEFE\"> clever</span><span style=\"background-color: #FFFEFE\"> witty</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> great</span><span style=\"background-color: #FFFEFE\"> casting</span><span style=\"background-color: #FFFDFD\"> jerry</span><span style=\"background-color: #FFEAEA\"> still</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> jewel</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> incredibly</span><span style=\"background-color: #FFFEFE\"> funny</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFEFE\"> ##rky</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> simply</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> comical</span><span style=\"background-color: #FFFEFE\"> genius</span><span style=\"background-color: #FFFBFB\"> doug</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFCFC\"> carrie</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> great</span><span style=\"background-color: #FFFEFE\"> chemistry</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> do</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> see</span><span style=\"background-color: #FFFEFE\"> what</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> everybody</span><span style=\"background-color: #FFFEFE\"> loves</span><span style=\"background-color: #FFFBFB\"> raymond</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFEFE\"> ##rated</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFEFE\"> jokes</span><span style=\"background-color: #FFFEFE\"> mostly</span><span style=\"background-color: #FFFEFE\"> forced</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> just</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> witty</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> can</span><span style=\"background-color: #FFFEFE\"> t</span><span style=\"background-color: #FFFEFE\"> remember</span><span style=\"background-color: #FFFEFE\"> laughing</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> more</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFEFE\"> 1</span><span style=\"background-color: #FFFBFB\"> episode</span><span style=\"background-color: #FF0000\"> .</span><span style=\"background-color: #FFFDFD\"> king</span><span style=\"background-color: #FFF9F9\"> of</span><span style=\"background-color: #FFDDDD\"> queens</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> rare</span><span style=\"background-color: #FFFDFD\"> comedy</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> has</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> right</span><span style=\"background-color: #FFFEFE\"> ingredients</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> give</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFEFE\"> serious</span><span style=\"background-color: #FFFEFE\"> belly</span><span style=\"background-color: #FFFEFE\"> laughs</span><span style=\"background-color: #FFFDFD\"> which</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFFEFE\"> caused</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFBFB\"> arthur</span><span style=\"background-color: #FFEBEB\"> spoon</span><span style=\"background-color: #FFF8F8\"> ##er</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> think</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFEFE\"> about</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> gets</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> deserves</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFF8F8\"> raymond</span><span style=\"background-color: #FFFDFD\"> co</span><span style=\"background-color: #FFFDFD\"> .</span><br><br>[BERT의 Attention을 시각화_9]<br><span style=\"background-color: #FFFDFD\"> [CLS]</span><span style=\"background-color: #FFFCFC\"> this</span><span style=\"background-color: #FFF5F5\"> is</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFF8F8\"> best</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> period</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFD4D4\"> is</span><span style=\"background-color: #FF0000\"> so</span><span style=\"background-color: #FFF8F8\"> under</span><span style=\"background-color: #FFF6F6\"> ##rated</span><span style=\"background-color: #FFFBFB\"> clever</span><span style=\"background-color: #FFFDFD\"> witty</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFD9D9\"> great</span><span style=\"background-color: #FFFEFE\"> casting</span><span style=\"background-color: #FFFEFE\"> jerry</span><span style=\"background-color: #FFFEFE\"> still</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFC3C3\"> is</span><span style=\"background-color: #FFF8F8\"> the</span><span style=\"background-color: #FFFDFD\"> jewel</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFBFB\"> he</span><span style=\"background-color: #FFCCCC\"> is</span><span style=\"background-color: #FF6464\"> so</span><span style=\"background-color: #FFDFDF\"> incredibly</span><span style=\"background-color: #FFFBFB\"> funny</span><span style=\"background-color: #FFF7F7\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFCFC\"> ##rky</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFBFBF\"> simply</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> comical</span><span style=\"background-color: #FFFEFE\"> genius</span><span style=\"background-color: #FFFEFE\"> doug</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> carrie</span><span style=\"background-color: #FFF5F5\"> have</span><span style=\"background-color: #FFC8C8\"> great</span><span style=\"background-color: #FFFCFC\"> chemistry</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFE9E9\"> so</span><span style=\"background-color: #FFDFDF\"> do</span><span style=\"background-color: #FFDCDC\"> not</span><span style=\"background-color: #FFF9F9\"> see</span><span style=\"background-color: #FFFAFA\"> what</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFBFB\"> ##ype</span><span style=\"background-color: #FFEAEA\"> is</span><span style=\"background-color: #FFFCFC\"> about</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> everybody</span><span style=\"background-color: #FFFEFE\"> loves</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFF0F0\"> is</span><span style=\"background-color: #FFD7D7\"> so</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFF7F7\"> ##rated</span><span style=\"background-color: #FFFCFC\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFEFE\"> jokes</span><span style=\"background-color: #FFFBFB\"> mostly</span><span style=\"background-color: #FFFEFE\"> forced</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFF8F8\"> and</span><span style=\"background-color: #FF7C7C\"> just</span><span style=\"background-color: #FFD4D4\"> not</span><span style=\"background-color: #FFFAFA\"> the</span><span style=\"background-color: #FFFDFD\"> witty</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFBFB\"> i</span><span style=\"background-color: #FFE7E7\"> can</span><span style=\"background-color: #FFE8E8\"> t</span><span style=\"background-color: #FFFCFC\"> remember</span><span style=\"background-color: #FFFBFB\"> laughing</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFF9F9\"> more</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFDFD\"> 1</span><span style=\"background-color: #FFFEFE\"> episode</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> king</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> queens</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFCFC\"> a</span><span style=\"background-color: #FFFCFC\"> rare</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFF0F0\"> that</span><span style=\"background-color: #FFDDDD\"> has</span><span style=\"background-color: #FF5858\"> all</span><span style=\"background-color: #FFEDED\"> the</span><span style=\"background-color: #FFDADA\"> right</span><span style=\"background-color: #FFFDFD\"> ingredients</span><span style=\"background-color: #FFD4D4\"> to</span><span style=\"background-color: #FFFDFD\"> give</span><span style=\"background-color: #FFFDFD\"> you</span><span style=\"background-color: #FFFBFB\"> serious</span><span style=\"background-color: #FFFEFE\"> belly</span><span style=\"background-color: #FFFDFD\"> laughs</span><span style=\"background-color: #FFFCFC\"> which</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFFCFC\"> normally</span><span style=\"background-color: #FFFEFE\"> caused</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFEFE\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFF9F9\"> i</span><span style=\"background-color: #FFAAAA\"> think</span><span style=\"background-color: #FFFDFD\"> its</span><span style=\"background-color: #FFF3F3\"> about</span><span style=\"background-color: #FFF9F9\"> time</span><span style=\"background-color: #FFF7F7\"> this</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFAFA\"> gets</span><span style=\"background-color: #FFF9F9\"> the</span><span style=\"background-color: #FFFCFC\"> h</span><span style=\"background-color: #FFFCFC\"> ##ype</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFF9F9\"> deserves</span><span style=\"background-color: #FFA5A5\"> and</span><span style=\"background-color: #FF5E5E\"> not</span><span style=\"background-color: #FFFAFA\"> the</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFDFD\"> .</span><br><br>[BERT의 Attention을 시각화_10]<br><span style=\"background-color: #FFFCFC\"> [CLS]</span><span style=\"background-color: #FFEAEA\"> this</span><span style=\"background-color: #FFF8F8\"> is</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFF9F9\"> best</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> period</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFF9F9\"> so</span><span style=\"background-color: #FFFEFE\"> under</span><span style=\"background-color: #FFFCFC\"> ##rated</span><span style=\"background-color: #FFFBFB\"> clever</span><span style=\"background-color: #FFFEFE\"> witty</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFCFC\"> great</span><span style=\"background-color: #FFFEFE\"> casting</span><span style=\"background-color: #FFFCFC\"> jerry</span><span style=\"background-color: #FFFBFB\"> still</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> jewel</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFDBDB\"> so</span><span style=\"background-color: #FFF6F6\"> incredibly</span><span style=\"background-color: #FFFEFE\"> funny</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFDFD\"> ##rky</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFA3A3\"> simply</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> comical</span><span style=\"background-color: #FFFEFE\"> genius</span><span style=\"background-color: #FFFEFE\"> doug</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> carrie</span><span style=\"background-color: #FFFBFB\"> have</span><span style=\"background-color: #FFF6F6\"> great</span><span style=\"background-color: #FFFDFD\"> chemistry</span><span style=\"background-color: #FFF1F1\"> i</span><span style=\"background-color: #FF4A4A\"> so</span><span style=\"background-color: #FF5F5F\"> do</span><span style=\"background-color: #FFE3E3\"> not</span><span style=\"background-color: #FFADAD\"> see</span><span style=\"background-color: #FFF7F7\"> what</span><span style=\"background-color: #FFF6F6\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFCFC\"> is</span><span style=\"background-color: #FFF9F9\"> about</span><span style=\"background-color: #FFFAFA\"> when</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFCFC\"> to</span><span style=\"background-color: #FFFBFB\"> everybody</span><span style=\"background-color: #FFFEFE\"> loves</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFF8F8\"> so</span><span style=\"background-color: #FFFDFD\"> over</span><span style=\"background-color: #FFFAFA\"> ##rated</span><span style=\"background-color: #FFF3F3\"> with</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFEFE\"> jokes</span><span style=\"background-color: #FFF9F9\"> mostly</span><span style=\"background-color: #FFFDFD\"> forced</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FF5353\"> just</span><span style=\"background-color: #FFFCFC\"> not</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> witty</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFE5E5\"> i</span><span style=\"background-color: #FFE7E7\"> can</span><span style=\"background-color: #FFF4F4\"> t</span><span style=\"background-color: #FFFDFD\"> remember</span><span style=\"background-color: #FFFAFA\"> laughing</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFDFD\"> more</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFEFE\"> 1</span><span style=\"background-color: #FFFEFE\"> episode</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> king</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> queens</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> rare</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> has</span><span style=\"background-color: #FFF9F9\"> all</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFAFA\"> right</span><span style=\"background-color: #FFFEFE\"> ingredients</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> give</span><span style=\"background-color: #FFFDFD\"> you</span><span style=\"background-color: #FFE2E2\"> serious</span><span style=\"background-color: #FFFEFE\"> belly</span><span style=\"background-color: #FFFEFE\"> laughs</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFFDFD\"> caused</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFD5D5\"> i</span><span style=\"background-color: #FF0000\"> think</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFDDDD\"> about</span><span style=\"background-color: #FFF3F3\"> time</span><span style=\"background-color: #FFECEC\"> this</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFBFB\"> gets</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> deserves</span><span style=\"background-color: #FFEBEB\"> and</span><span style=\"background-color: #FFF9F9\"> not</span><span style=\"background-color: #FFFBFB\"> the</span><span style=\"background-color: #FFF9F9\"> lame</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_11]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFCFC\"> this</span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFFAFA\"> the</span><span style=\"background-color: #FF0000\"> best</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFD4D4\"> period</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFEFEF\"> is</span><span style=\"background-color: #FFFDFD\"> so</span><span style=\"background-color: #FFFCFC\"> under</span><span style=\"background-color: #FFFCFC\"> ##rated</span><span style=\"background-color: #FFF9F9\"> clever</span><span style=\"background-color: #FFFEFE\"> witty</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFF1F1\"> great</span><span style=\"background-color: #FFFEFE\"> casting</span><span style=\"background-color: #FFFEFE\"> jerry</span><span style=\"background-color: #FFFEFE\"> still</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFCFC\"> is</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFAFA\"> jewel</span><span style=\"background-color: #FFFAFA\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFAFA\"> incredibly</span><span style=\"background-color: #FFFEFE\"> funny</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> qui</span><span style=\"background-color: #FFFEFE\"> ##rky</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFBFB\"> simply</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> comical</span><span style=\"background-color: #FFFDFD\"> genius</span><span style=\"background-color: #FFFEFE\"> doug</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> carrie</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> great</span><span style=\"background-color: #FFFEFE\"> chemistry</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFBFB\"> so</span><span style=\"background-color: #FFFDFD\"> do</span><span style=\"background-color: #FFF5F5\"> not</span><span style=\"background-color: #FFFCFC\"> see</span><span style=\"background-color: #FFFEFE\"> what</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFDFD\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFDFD\"> about</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> everybody</span><span style=\"background-color: #FFFEFE\"> loves</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFEBEB\"> is</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFDFD\"> ##rated</span><span style=\"background-color: #FFFCFC\"> with</span><span style=\"background-color: #FFFDFD\"> lame</span><span style=\"background-color: #FFFEFE\"> jokes</span><span style=\"background-color: #FFFEFE\"> mostly</span><span style=\"background-color: #FFFEFE\"> forced</span><span style=\"background-color: #FFFEFE\"> humor</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> just</span><span style=\"background-color: #FFFDFD\"> not</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> witty</span><span style=\"background-color: #FFFEFE\"> show</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFEFE\"> can</span><span style=\"background-color: #FFF9F9\"> t</span><span style=\"background-color: #FFFEFE\"> remember</span><span style=\"background-color: #FFF5F5\"> laughing</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFDFD\"> more</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFEFE\"> 1</span><span style=\"background-color: #FFFEFE\"> episode</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> king</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> queens</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFBFB\"> rare</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFCFC\"> has</span><span style=\"background-color: #FFF9F9\"> all</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> right</span><span style=\"background-color: #FFFEFE\"> ingredients</span><span style=\"background-color: #FFFDFD\"> to</span><span style=\"background-color: #FFFEFE\"> give</span><span style=\"background-color: #FFFEFE\"> you</span><span style=\"background-color: #FFFAFA\"> serious</span><span style=\"background-color: #FFFEFE\"> belly</span><span style=\"background-color: #FFFEFE\"> laughs</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> normally</span><span style=\"background-color: #FFFEFE\"> caused</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> arthur</span><span style=\"background-color: #FFFEFE\"> spoon</span><span style=\"background-color: #FFFEFE\"> ##er</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> i</span><span style=\"background-color: #FFFEFE\"> think</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFF9F9\"> about</span><span style=\"background-color: #FFFCFC\"> time</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFFEFE\"> comedy</span><span style=\"background-color: #FFFDFD\"> gets</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFFEFE\"> ##ype</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFFAFA\"> deserves</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> not</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> lame</span><span style=\"background-color: #FFFEFE\"> raymond</span><span style=\"background-color: #FFFEFE\"> co</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERT의 Attention을 시각화_12]<br><span style=\"background-color: #FFF7F7\"> [CLS]</span><span style=\"background-color: #FFC8C8\"> this</span><span style=\"background-color: #FFE2E2\"> is</span><span style=\"background-color: #FFB4B4\"> the</span><span style=\"background-color: #FF4040\"> best</span><span style=\"background-color: #FF0000\"> comedy</span><span style=\"background-color: #FFD2D2\"> period</span><span style=\"background-color: #FFE1E1\"> .</span><span style=\"background-color: #FFEAEA\"> it</span><span style=\"background-color: #FFF0F0\"> is</span><span style=\"background-color: #FFF2F2\"> so</span><span style=\"background-color: #FFEDED\"> under</span><span style=\"background-color: #FFFAFA\"> ##rated</span><span style=\"background-color: #FFFAFA\"> clever</span><span style=\"background-color: #FFF9F9\"> witty</span><span style=\"background-color: #FFE5E5\"> humor</span><span style=\"background-color: #FFF0F0\"> ,</span><span style=\"background-color: #FFF3F3\"> great</span><span style=\"background-color: #FFEFEF\"> casting</span><span style=\"background-color: #FFF9F9\"> jerry</span><span style=\"background-color: #FFF9F9\"> still</span><span style=\"background-color: #FFEEEE\"> ##er</span><span style=\"background-color: #FFF4F4\"> is</span><span style=\"background-color: #FFD7D7\"> the</span><span style=\"background-color: #FFF5F5\"> jewel</span><span style=\"background-color: #FFE9E9\"> in</span><span style=\"background-color: #FF6D6D\"> the</span><span style=\"background-color: #FF6B6B\"> show</span><span style=\"background-color: #FFE1E1\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFF6F6\"> so</span><span style=\"background-color: #FFF4F4\"> incredibly</span><span style=\"background-color: #FFEFEF\"> funny</span><span style=\"background-color: #FFF4F4\"> and</span><span style=\"background-color: #FFFCFC\"> qui</span><span style=\"background-color: #FFF5F5\"> ##rky</span><span style=\"background-color: #FFEEEE\"> ,</span><span style=\"background-color: #FFF7F7\"> simply</span><span style=\"background-color: #FFF3F3\"> a</span><span style=\"background-color: #FFE7E7\"> comical</span><span style=\"background-color: #FFFCFC\"> genius</span><span style=\"background-color: #FFFCFC\"> doug</span><span style=\"background-color: #FFF2F2\"> and</span><span style=\"background-color: #FFFAFA\"> carrie</span><span style=\"background-color: #FFF9F9\"> have</span><span style=\"background-color: #FFFCFC\"> great</span><span style=\"background-color: #FFD9D9\"> chemistry</span><span style=\"background-color: #FFECEC\"> i</span><span style=\"background-color: #FFF3F3\"> so</span><span style=\"background-color: #FFBBBB\"> do</span><span style=\"background-color: #FFF3F3\"> not</span><span style=\"background-color: #FFB5B5\"> see</span><span style=\"background-color: #FFE1E1\"> what</span><span style=\"background-color: #FFC9C9\"> the</span><span style=\"background-color: #FFEFEF\"> h</span><span style=\"background-color: #FFE9E9\"> ##ype</span><span style=\"background-color: #FFF6F6\"> is</span><span style=\"background-color: #FFF8F8\"> about</span><span style=\"background-color: #FFCDCD\"> when</span><span style=\"background-color: #FFD9D9\"> it</span><span style=\"background-color: #FFF7F7\"> comes</span><span style=\"background-color: #FFC0C0\"> to</span><span style=\"background-color: #FFF2F2\"> everybody</span><span style=\"background-color: #FFDBDB\"> loves</span><span style=\"background-color: #FFFCFC\"> raymond</span><span style=\"background-color: #FFF1F1\"> it</span><span style=\"background-color: #FFF5F5\"> is</span><span style=\"background-color: #FFFBFB\"> so</span><span style=\"background-color: #FFF4F4\"> over</span><span style=\"background-color: #FFF3F3\"> ##rated</span><span style=\"background-color: #FFF9F9\"> with</span><span style=\"background-color: #FFF4F4\"> lame</span><span style=\"background-color: #FFF1F1\"> jokes</span><span style=\"background-color: #FFF6F6\"> mostly</span><span style=\"background-color: #FFF1F1\"> forced</span><span style=\"background-color: #FFE7E7\"> humor</span><span style=\"background-color: #FFF9F9\"> and</span><span style=\"background-color: #FFF8F8\"> just</span><span style=\"background-color: #FFF7F7\"> not</span><span style=\"background-color: #FFECEC\"> the</span><span style=\"background-color: #FFDFDF\"> witty</span><span style=\"background-color: #FFF9F9\"> show</span><span style=\"background-color: #FFCACA\"> ,</span><span style=\"background-color: #FFC6C6\"> i</span><span style=\"background-color: #FFC6C6\"> can</span><span style=\"background-color: #FFF2F2\"> t</span><span style=\"background-color: #FFADAD\"> remember</span><span style=\"background-color: #FF5959\"> laughing</span><span style=\"background-color: #FFA2A2\"> in</span><span style=\"background-color: #FFEDED\"> more</span><span style=\"background-color: #FFECEC\"> than</span><span style=\"background-color: #FFEFEF\"> 1</span><span style=\"background-color: #FFD2D2\"> episode</span><span style=\"background-color: #FFE1E1\"> .</span><span style=\"background-color: #FFF5F5\"> king</span><span style=\"background-color: #FFE9E9\"> of</span><span style=\"background-color: #FFF2F2\"> queens</span><span style=\"background-color: #FFF0F0\"> is</span><span style=\"background-color: #FFD1D1\"> a</span><span style=\"background-color: #FFC9C9\"> rare</span><span style=\"background-color: #FF8C8C\"> comedy</span><span style=\"background-color: #FFCACA\"> that</span><span style=\"background-color: #FFDFDF\"> has</span><span style=\"background-color: #FFE7E7\"> all</span><span style=\"background-color: #FFA8A8\"> the</span><span style=\"background-color: #FF8B8B\"> right</span><span style=\"background-color: #FF7C7C\"> ingredients</span><span style=\"background-color: #FFD0D0\"> to</span><span style=\"background-color: #FFF1F1\"> give</span><span style=\"background-color: #FF5C5C\"> you</span><span style=\"background-color: #FF9E9E\"> serious</span><span style=\"background-color: #FFD7D7\"> belly</span><span style=\"background-color: #FFC8C8\"> laughs</span><span style=\"background-color: #FFF1F1\"> which</span><span style=\"background-color: #FFEFEF\"> is</span><span style=\"background-color: #FFF4F4\"> normally</span><span style=\"background-color: #FFECEC\"> caused</span><span style=\"background-color: #FFE2E2\"> by</span><span style=\"background-color: #FFF9F9\"> arthur</span><span style=\"background-color: #FFFCFC\"> spoon</span><span style=\"background-color: #FFFCFC\"> ##er</span><span style=\"background-color: #FFC1C1\"> ,</span><span style=\"background-color: #FFCBCB\"> i</span><span style=\"background-color: #FFF4F4\"> think</span><span style=\"background-color: #FFEDED\"> its</span><span style=\"background-color: #FFEEEE\"> about</span><span style=\"background-color: #FFF5F5\"> time</span><span style=\"background-color: #FF7373\"> this</span><span style=\"background-color: #FF9C9C\"> comedy</span><span style=\"background-color: #FFF8F8\"> gets</span><span style=\"background-color: #FFEDED\"> the</span><span style=\"background-color: #FFFEFE\"> h</span><span style=\"background-color: #FFEBEB\"> ##ype</span><span style=\"background-color: #FFF1F1\"> it</span><span style=\"background-color: #FFD9D9\"> deserves</span><span style=\"background-color: #FFE8E8\"> and</span><span style=\"background-color: #FFF1F1\"> not</span><span style=\"background-color: #FFEAEA\"> the</span><span style=\"background-color: #FFF4F4\"> lame</span><span style=\"background-color: #FFFAFA\"> raymond</span><span style=\"background-color: #FFFBFB\"> co</span><span style=\"background-color: #FFE0E0\"> .</span><br><br>[BERT의 Attention을 시각화_ALL]<br><span style=\"background-color: #FFCECE\"> [CLS]</span><span style=\"background-color: #FFBBBB\"> this</span><span style=\"background-color: #FFC3C3\"> is</span><span style=\"background-color: #FFB8B8\"> the</span><span style=\"background-color: #FF0000\"> best</span><span style=\"background-color: #FF7D7D\"> comedy</span><span style=\"background-color: #FFCACA\"> period</span><span style=\"background-color: #FF6A6A\"> .</span><span style=\"background-color: #FFB5B5\"> it</span><span style=\"background-color: #FF8F8F\"> is</span><span style=\"background-color: #FF6161\"> so</span><span style=\"background-color: #FFF2F2\"> under</span><span style=\"background-color: #FFEDED\"> ##rated</span><span style=\"background-color: #FFEFEF\"> clever</span><span style=\"background-color: #FFEDED\"> witty</span><span style=\"background-color: #FFC4C4\"> humor</span><span style=\"background-color: #FFEDED\"> ,</span><span style=\"background-color: #FF9999\"> great</span><span style=\"background-color: #FFA6A6\"> casting</span><span style=\"background-color: #FFF7F7\"> jerry</span><span style=\"background-color: #FFF2F2\"> still</span><span style=\"background-color: #FFEEEE\"> ##er</span><span style=\"background-color: #FFC7C7\"> is</span><span style=\"background-color: #FFE1E1\"> the</span><span style=\"background-color: #FFF3F3\"> jewel</span><span style=\"background-color: #FFEFEF\"> in</span><span style=\"background-color: #FFB7B7\"> the</span><span style=\"background-color: #FF8B8B\"> show</span><span style=\"background-color: #FFEAEA\"> ,</span><span style=\"background-color: #FFF7F7\"> he</span><span style=\"background-color: #FFBFBF\"> is</span><span style=\"background-color: #FF9D9D\"> so</span><span style=\"background-color: #FFDDDD\"> incredibly</span><span style=\"background-color: #FFDBDB\"> funny</span><span style=\"background-color: #FFEDED\"> and</span><span style=\"background-color: #FFFCFC\"> qui</span><span style=\"background-color: #FFF2F2\"> ##rky</span><span style=\"background-color: #FFF1F1\"> ,</span><span style=\"background-color: #FFB7B7\"> simply</span><span style=\"background-color: #FFE9E9\"> a</span><span style=\"background-color: #FFE7E7\"> comical</span><span style=\"background-color: #FFE8E8\"> genius</span><span style=\"background-color: #FFF6F6\"> doug</span><span style=\"background-color: #FFF7F7\"> and</span><span style=\"background-color: #FFF6F6\"> carrie</span><span style=\"background-color: #FFEBEB\"> have</span><span style=\"background-color: #FFD8D8\"> great</span><span style=\"background-color: #FFAFAF\"> chemistry</span><span style=\"background-color: #FFEFEF\"> i</span><span style=\"background-color: #FFB8B8\"> so</span><span style=\"background-color: #FF9C9C\"> do</span><span style=\"background-color: #FFDCDC\"> not</span><span style=\"background-color: #FFC3C3\"> see</span><span style=\"background-color: #FFECEC\"> what</span><span style=\"background-color: #FFE5E5\"> the</span><span style=\"background-color: #FFF9F9\"> h</span><span style=\"background-color: #FFF5F5\"> ##ype</span><span style=\"background-color: #FFEBEB\"> is</span><span style=\"background-color: #FFF5F5\"> about</span><span style=\"background-color: #FFEDED\"> when</span><span style=\"background-color: #FFF0F0\"> it</span><span style=\"background-color: #FFF3F3\"> comes</span><span style=\"background-color: #FFDEDE\"> to</span><span style=\"background-color: #FFECEC\"> everybody</span><span style=\"background-color: #FFECEC\"> loves</span><span style=\"background-color: #FFF5F5\"> raymond</span><span style=\"background-color: #FFE8E8\"> it</span><span style=\"background-color: #FFB8B8\"> is</span><span style=\"background-color: #FFE2E2\"> so</span><span style=\"background-color: #FFF8F8\"> over</span><span style=\"background-color: #FFD0D0\"> ##rated</span><span style=\"background-color: #FFEAEA\"> with</span><span style=\"background-color: #FFF9F9\"> lame</span><span style=\"background-color: #FFF1F1\"> jokes</span><span style=\"background-color: #FFF1F1\"> mostly</span><span style=\"background-color: #FFEDED\"> forced</span><span style=\"background-color: #FFDADA\"> humor</span><span style=\"background-color: #FFF5F5\"> and</span><span style=\"background-color: #FF9797\"> just</span><span style=\"background-color: #FFE3E3\"> not</span><span style=\"background-color: #FFDFDF\"> the</span><span style=\"background-color: #FFD0D0\"> witty</span><span style=\"background-color: #FF9393\"> show</span><span style=\"background-color: #FFE6E6\"> ,</span><span style=\"background-color: #FFE1E1\"> i</span><span style=\"background-color: #FFDBDB\"> can</span><span style=\"background-color: #FFEAEA\"> t</span><span style=\"background-color: #FFDEDE\"> remember</span><span style=\"background-color: #FFA0A0\"> laughing</span><span style=\"background-color: #FFDCDC\"> in</span><span style=\"background-color: #FFF1F1\"> more</span><span style=\"background-color: #FFF5F5\"> than</span><span style=\"background-color: #FFF5F5\"> 1</span><span style=\"background-color: #FFC8C8\"> episode</span><span style=\"background-color: #FF6161\"> .</span><span style=\"background-color: #FFEBEB\"> king</span><span style=\"background-color: #FFBFBF\"> of</span><span style=\"background-color: #FFEBEB\"> queens</span><span style=\"background-color: #FFCDCD\"> is</span><span style=\"background-color: #FF9898\"> a</span><span style=\"background-color: #FFD3D3\"> rare</span><span style=\"background-color: #FF9696\"> comedy</span><span style=\"background-color: #FFD6D6\"> that</span><span style=\"background-color: #FFDCDC\"> has</span><span style=\"background-color: #FFBFBF\"> all</span><span style=\"background-color: #FFD6D6\"> the</span><span style=\"background-color: #FFC1C1\"> right</span><span style=\"background-color: #FFB3B3\"> ingredients</span><span style=\"background-color: #FFDADA\"> to</span><span style=\"background-color: #FFF1F1\"> give</span><span style=\"background-color: #FFC6C6\"> you</span><span style=\"background-color: #FFC1C1\"> serious</span><span style=\"background-color: #FFEAEA\"> belly</span><span style=\"background-color: #FFDDDD\"> laughs</span><span style=\"background-color: #FFF3F3\"> which</span><span style=\"background-color: #FFF6F6\"> is</span><span style=\"background-color: #FFF8F8\"> normally</span><span style=\"background-color: #FFEEEE\"> caused</span><span style=\"background-color: #FFE9E9\"> by</span><span style=\"background-color: #FFF6F6\"> arthur</span><span style=\"background-color: #FFF7F7\"> spoon</span><span style=\"background-color: #FFF2F2\"> ##er</span><span style=\"background-color: #FFCBCB\"> ,</span><span style=\"background-color: #FFDDDD\"> i</span><span style=\"background-color: #FF9696\"> think</span><span style=\"background-color: #FFF5F5\"> its</span><span style=\"background-color: #FFDADA\"> about</span><span style=\"background-color: #FFEAEA\"> time</span><span style=\"background-color: #FF7979\"> this</span><span style=\"background-color: #FF9E9E\"> comedy</span><span style=\"background-color: #FFD9D9\"> gets</span><span style=\"background-color: #FFF0F0\"> the</span><span style=\"background-color: #FFF3F3\"> h</span><span style=\"background-color: #FFD4D4\"> ##ype</span><span style=\"background-color: #FFECEC\"> it</span><span style=\"background-color: #FFE9E9\"> deserves</span><span style=\"background-color: #FFD2D2\"> and</span><span style=\"background-color: #FFC0C0\"> not</span><span style=\"background-color: #FFEBEB\"> the</span><span style=\"background-color: #FFEFEF\"> lame</span><span style=\"background-color: #FFEAEA\"> raymond</span><span style=\"background-color: #FFF9F9\"> co</span><span style=\"background-color: #FFF3F3\"> .</span><br><br>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "index = 61\n",
        "html_output = mk_html(index, batch, preds, attention_probs, TEXT) \n",
        "HTML(html_output) \n"
      ]
    }
  ]
}